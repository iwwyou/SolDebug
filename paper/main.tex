\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style

% Korean language support
\usepackage[utf8]{inputenc}
%\usepackage{kotex}  % Commented out - package not found

% Math packages first
\usepackage{amsmath}%
\usepackage{amssymb}%
\usepackage{amsfonts}%
\usepackage{amsthm}%
\usepackage{amsopn}%
\usepackage{amstext}%
\usepackage{mathrsfs}%
\usepackage{stmaryrd}% For llbracket, rrbracket

% Graphics and tables
\usepackage{graphicx}%
\DeclareGraphicsExtensions{.png,.pdf,.jpg}% PNG first, then PDF
\usepackage{subcaption}% For subfigure environment
\usepackage{tikz}%
\usetikzlibrary{positioning,shapes,arrows.meta}%
\usepackage{multirow}%
\usepackage{booktabs}%
\usepackage{tabularx}
\usepackage{array}

% Algorithm packages
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%

% Other packages
\usepackage[title]{appendix}%
\usepackage{placeins}% For \FloatBarrier to control figure placement
\usepackage{float}% For [H] option to force exact placement
\usepackage{xcolor}%
\usepackage{textcomp}%
% \usepackage{manyfoot}% Package not available in MiKTeX
\usepackage{listings}%
\usepackage{comment}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}

\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
\newtheorem{proposition}[theorem]{Proposition}% 
\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom

% Using numerical style to match sn-mathphys-num document class
\bibpunct{(}{)}{;}{n}{}{ } % n = numerical citations

\usepackage[hyphens]{url}
\usepackage[colorlinks=true,allcolors=blue]{hyperref}
\Urlmuskip=0mu plus 1mu
\def\UrlBreaks{\do\/\do-\do\_\do\.\do\?\do\&}

\makeatletter
\renewcommand\@biblabel[1]{} % Remove numeric labels like [1]
\makeatother
\setlength{\bibsep}{0.2em}   % Space between bibliography items
\setlength{\bibhang}{2em}

% Custom math commands
\newcommand{\Abort}{\mathsf{Abort}}
\newcommand{\Norm}{\mathsf{Norm}}
\newcommand{\Ret}{\mathsf{Ret}}

\begin{document}

\title[Article Title]{SolQDebug: Debug Solidity Quickly for Interactive Immediacy in Smart Contract
Development}

\author[1]{\fnm{Inseong} \sur{Jeon}}\email{iwwyou@korea.ac.kr}

\author[1]{\fnm{Sundeuk} \sur{Kim}}\email{sd\_kim@korea.ac.kr}

\author[1]{\fnm{Hyunwoo} \sur{Kim}}\email{khw0809@korea.ac.kr}

\author*[1]{\fnm{Hoh Peter} \sur{In}}\email{hoh\_in@korea.ac.kr}

\affil*[1]{\orgdiv{Department of Computer Science}, \orgname{Korea University},
\orgaddress{\street{145, Anam-ro}, \city{Seonbuk-gu}, \postcode{02841}, \state{Seoul},
\country{Republic of Korea}}}


\abstract{Debugging Solidity contracts remains cumbersome and slow. Even a simple inspection, such
as tracking a variable through a branch, requires full compilation, contract deployment, preparatory
transactions, and step-by-step bytecode tracing. Existing tools operate only after execution and
offer no support while code is under construction. We present \textsc{SolQDebug}, the first
interactive, source-level assistant for Solidity developers that provides millisecond feedback
before compilation or chain interaction. \textsc{SolQDebug} extends the Solidity grammar with
interactive parsing, incrementally maintains a dynamic control-flow graph, and performs
interval-based abstract interpretation guided by inline test annotations, enabling developers to
simulate symbolic inputs and inspect contract behavior as in traditional debugging environments. In
an evaluation on real-world functions, \textsc{SolQDebug} enables low-latency, statement-level
analysis during development without requiring compilation or deployment.}


\keywords{Smart Contract Development, Solidity, Debugging, Abstract Interpretation}

\maketitle

\section{Introduction}\label{sec1}

    Smart contracts are the backbone of decentralized applications, and Solidity has become the
    dominant language for writing them~\citep{smart contract evolution, solidity}. As contracts grow
    more complex and control more assets, developers must reason about correctness throughout the
    development cycle---not just at deployment. Large language models (LLMs) such as ~\citet{gpt} or
    ~\citet{llama} can assist with code generation but offer no guarantees of correctness.
    Ultimately, developers remain responsible for understanding variable interactions, control flow,
    and numeric boundaries during authoring.

    Unfortunately, the debugging workflow for Solidity lags far behind traditional programming
    environments. Even a single inspection requires full compilation, deployment, transaction-based
    state setup, and manual bytecode-level tracing. Tools like ~\citet{remix}, ~\citet{hardhat}, and
    ~\citet{forge} replicate this costly pipeline, providing no live feedback during edits. A prior
    study found that 88.8\% of Solidity developers described debugging as painful, and 69\%
    attributed this to the absence of interactive, source-level tooling~\citet{interview}. Despite
    this widely acknowledged pain point, we find no existing research or tooling that provides
    interactive feedback during Solidity code authoring---a gap that this paper aims to fill.
    
    This paper presents \textsc{SolQDebug}, a source-level interactive Solidity debugger powered by
    abstract interpretation. Rather than replacing runtime debuggers, it complements them by
    enabling symbolic, per-statement inspection during code authoring---before compilation or
    deployment. It targets the Solidity pattern of single-contract, single-transaction execution,
    where each function is isolated and stateless---ideal for static reasoning but difficult to
    simulate manually. To support this, \textsc{SolQDebug} applies interval-based abstract
    interpretation, which generalizes over symbolic inputs, exposes edge-case behaviors, and
    provides sound results with low overhead. This approach gives developers immediate feedback and
    enables them to reason efficiently about how symbolic inputs influence variable behavior.
    Although these inputs enable generalization across multiple cases, certain input configurations
    or control structures may lead to wider output ranges. We evaluate these behaviors empirically
    and propose annotation strategies that help maintain interpretability across typical Solidity
    patterns.
    
    To achieve this goal, \textsc{SolQDebug} builds on two core ideas. First, it extends the
    Solidity grammar with interactive parsing rules and dynamically updates the control-flow graph
    to reflect incremental edits, enabling keystroke-level structural changes during code authoring.
    Second, it performs abstract interpretation seeded by inline annotations. These annotations,
    written directly in the source code, allow developers to specify symbolic values for both
    parameters and storage variables, similar to how traditional debuggers let users configure
    initial states and explore control flow.
    
    We evaluate \textsc{SolQDebug} on real-world functions from ~\citet{dappscan}, demonstrating
    millisecond-scale responsiveness under symbolic input. Beyond latency, we analyze how input
    interval structure affects interpretability in common Solidity patterns, such as
    division-normalized arithmetic.
    
    This paper makes the following contributions:
    
    \begin{itemize}
      \item We identify the main barriers to interactive Solidity debugging: latency from compilation, deployment, and transaction setup, and EVM constraints that prevent lightweight re-execution.
      \item We design an interactive parser and dynamic control-flow graph (CFG) engine that supports live structural updates and syntactic recovery.
      \item We introduce an abstract interpreter that incorporates developer annotations as symbolic input, supporting fast, deployment-free debugging workflows.
      \item We implement and evaluate \textsc{SolQDebug} on real-world contracts, demonstrating its millisecond responsiveness and exploring annotation strategies that maintain interpretability under a range of symbolic input patterns.
    \end{itemize}

\section{Background}\label{sect2}
    \subsection{Structure of Solidity Smart Contract}       
        Solidity smart contracts may declare contracts, interfaces, and libraries. Executable
        business logic typically resides in contracts, and functions serve as transaction entry
        points. Variables are usefully grouped as global (EVM metadata such as msg.sender or block.
        timestamp), state (persistent storage owned by a contract), and local (scoped to a call).
        Types include fixed-width integers, address, booleans, byte arrays, and user-defined structs;
        containers include arrays and mappings. A mapping behaves like an associative array with an
        implicit zero value for unseen keys and is not directly iterable. Storage classes (storage,
        memory, calldata) indicate lifetime and mutability; we mention them only to fix terminology.
        Visibility and mutability qualifiers (public, external, internal, private; pure, view,
        payable) exist but are not central to our single-contract, single-transaction setting.
        Control flow (if/else, while/for/do-while, break/continue, return) follows C/Java
        conventions.

        \begin{lstlisting}[language=Solidity, numbers=left, basicstyle=\ttfamily\small, caption={Minimal example used to illustrate grammar elements relevant to our analysis}, label={lst:grammar-min}] 
contract Example {
    address public owner;
    uint256 public totalSupply = 1000;
    mapping(address => uint256) private balances;

    modifier onlyOwner() {
        require(msg.sender == owner, "not owner");
        _;
    }

    function burn(uint256 amount) public onlyOwner {
        uint256 bal = balances[msg.sender];
        uint256 delta;
        if (bal >= amount) {
            balances[msg.sender] = bal - amount;
            delta = amount;
        } 
        else {            
            delta = 0;
        }
        totalSupply -= delta;
    }
}
        \end{lstlisting}

        The example highlights the specific features we rely on later. State variables include
        general types (owner, totalSupply) and a mapping from addresses to balances; global
        variables appear implicitly in guards via msg.sender. The function burn introduces
        parameters and a local variable (bal). The modifier onlyOwner performs a precondition check
        before the function body executes; the placeholder underscore marks where the original body
        is inserted when the modifier is inlined. In analysis, such modifiers are expanded at their
        precise positions around the function body in the control-flow graph.
        
        These grammar elements connect directly to our semantics. Guards such as require narrow
        feasible ranges along taken branches. Modifiers are inlined so that their precondition
        checks are analyzed in sequence with the function body. Containers like mappings remain
        symbolic until a concrete key is accessed, at which point an abstract value is materialized
        for that access. This level of detail suffices for our abstract interpretation in the
        single-contract, single-transaction scope without introducing parts of the language that our
        evaluation does not exercise.

    \subsection{Solidity Execution Model}
        To execute a Solidity contract on the blockchain, it must first be deployed. Deployment
        occurs through a one-time transaction that stores the compiled bytecode on-chain and invokes
        the constructor exactly once. After deployment, all subsequent interactions are message-call
        transactions. In these, the caller specifies a public function along with encoded calldata.
        Once the transaction is mined into a block, the Ethereum Virtual Machine (EVM) jumps to the
        designated entry point and executes the corresponding function sequentially. At runtime,
        Solidity variables fall into three distinct storage classes~\cite{solidity}:
    
        \begin{itemize}
          \item \textbf{Global variables} represent implicit, read-only metadata provided by the EVM, such as \texttt{block.timestamp}, \texttt{msg.sender}, and \texttt{msg.value}.
          \item \textbf{State variables} store persistent data within the contract and retain their values across transactions.
          \item \textbf{Local variables} include function parameters and temporary values scoped to a single execution context.
        \end{itemize}
    
        These three classes share a unified type system comprising primitive types like \texttt{uint}
        , \texttt{int}, \texttt{bool}, and \texttt{address}, as well as composite types such as
        arrays, mappings, and structs. Composite values can be nested to arbitrary depth using field
        access (\texttt{.}) or indexing (\texttt{[\,]}). Control flow follows familiar C-style
        constructs such as \texttt{if}/\texttt{else}, \texttt{while}, \texttt{for}, and
        \texttt{return}, alongside Solidity-specific statements like \texttt{emit} and
        \texttt{revert}.
        
        As a result, debuggers must resolve potentially complex, multi-step expressions to analyze
        deeply nested elements within the contract state.

\begin{figure*}[!t]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{1. Compile.png}
    \caption{Compile}
    \label{fig:step-compile}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{2. Deploy.png}
    \caption{Deploy related contracts}
    \label{fig:step-deploy}
  \end{subfigure}

  \vspace{1em}

  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{3. Execution.png}
    \caption{Send preparatory transactions}
    \label{fig:step-init}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{4. Debug.png}
    \caption{Bytecode-level debugging}
    \label{fig:step-debug}
  \end{subfigure}

  \caption{Traditional Solidity debugging workflow}
  \label{fig:legacy-debug-grid}
\end{figure*}
       

    \subsection{Root Causes of the Solidity-Debugging Bottleneck}
        Debugging Solidity programs remains significantly slower than traditional application
        development workflows due to two orthogonal obstacles.
        
        \smallskip
        \noindent\textbf{(1) Environmental disconnect.}
        Unlike conventional IDEs such as PyCharm~\cite{pycharm} or Visual Studio~\cite{visual},
        where the source editor and execution engine run in the same process, Solidity development
        involves external coordination with a blockchain node at every stage of the workflow. Even a
        single debugging cycle must pass through four sequential stages (see Fig.1). First, the
        contract must be compiled. Then, the bytecode is deployed to a local or test chain. Next,
        developers must manually initialize the on-chain state by sending setup transactions.
        Finally, the target function is invoked, and its execution is traced step by step at the
        bytecode level.
        
        This workflow introduces several seconds to minutes of latency per iteration, fundamentally
        breaking the fast "type-and-inspect" feedback cycle expected in modern development tools. To
        mitigate this friction, developers often rely on \texttt{emit} logs or event outputs to
        observe intermediate values. However, such instrumentation provides only runtime snapshots
        and lacks the structural insight needed to understand symbolic variation or control-flow
        behavior. Moreover, modifying the expression of interest typically requires recompilation
        and redeployment, compounding latency and disrupting iteration. The final stage---tracing raw
        EVM opcodes---is particularly costly, as developers are forced to mentally reconstruct
        source-level semantics. This not only adds execution overhead but also imposes significant
        cognitive burden during fault localization and fix validation.
    
        \smallskip
        \noindent\textbf{(2) Architectural limitations of the EVM.}
        The Ethereum Virtual Machine (EVM) is a state-based execution engine in which each
        transaction mutates a globally persistent storage. Once a function executes, its side
        effects are irreversible unless external intervention is performed. Re-executing the same
        function along the same control path is nontrivial: developers must either redeploy the
        entire contract to restore the initial state, or manually reconstruct the required
        preconditions via preparatory transactions---both of which incur significant overhead.
        
        Additionally, if a function includes conditional guards that depend on the current
        state---such as account balances or counters---then any debugging session must first ensure that
        those conditions are satisfied. Fig. 2 illustrates this challenge: the debug target function
        enforces a check on \texttt{\_balances[account]}, requiring developers to manually assign a
        sufficient balance before they can observe the downstream effects on \texttt{\_totalSupply}.
        Without such setup, the function exits early, preventing inspection of the intended
        execution path.
        
        In short, these constraints make repeated debugging iterations costly and fragile. According
        to a developer study~\cite{interview}, 88.8\% of Solidity practitioners reported frustration
        with current debugging workflows, with 69\% attributing this to the lack of interactive,
        state-aware tooling.

    \subsection{Proposed Methodology and Technical Challenges}

    \textsc{SolQDebug} addresses the two root causes of Solidity's debugging bottleneck---external
    latency from blockchain round trips, and internal opacity due to storage-based semantics---through
    a pair of lightweight but complementary techniques.
    
    \smallskip
    \noindent\textbf{(1) Eliminating blockchain latency via in-editor interpretation.}
    The traditional debugging workflow requires compilation, deployment, transaction-based state
    setup, and bytecode tracing---each incurring significant latency. \textsc{SolQDebug} replaces this
    round trip by performing both parsing and abstract interpretation directly inside the Solidity
    Editor. To support live editing, we extend the Solidity grammar with interactive parsing rules
    tailored for isolated statements, expressions, and control-flow blocks. When the developer types
    or edits code, only the affected region is reparsed using a reduced grammar.
    
    Each parsed statement is inserted into a dynamic control-flow graph (CFG), and abstract
    interpretation resumes from the edit point. The interpreter uses an interval lattice, assigning
    each variable a conservative range $[l, h]$ to expose edge conditions (e.g., overflows or
    failing guards) and to approximate groups of concrete executions that follow the same path. This
    enables millisecond-scale feedback on code structure and control flow without compilation or
    chain interaction.
    
    \smallskip
    \noindent\textbf{(2) Re-instantiating symbolic state without redeployment.}
    The EVM does not support reverting to a prior state without redeploying the contract or
    replaying transactions---both of which disrupt iteration. \textsc{SolQDebug} introduces batch
    annotations as a lightweight mechanism for symbolic state injection. In essence, this reflects a
    core debugging activity: varying inputs or contract state to observe control-flow outcomes.
    Rather than reconstructing such conditions through live transactions, developers can write
    annotations at the top of the function to define initial abstract values. These values are
    injected before analysis begins and rolled back afterward, ensuring test-case isolation.
    
    This approach brings the debugging workflow closer to the source by making state manipulation
    explicit and reproducible within the code itself. Developers can explore alternative execution
    paths by editing annotations alone---without modifying the contract logic or incurring compilation
    and deployment overhead. It effectively decouples symbolic input configuration from the analysis
    cycle, while preserving the intuitive debugging process developers already follow.

\begin{figure*}[t]
  \centering
  \includegraphics[
    width=0.95\textwidth,
    height=0.35\textheight,
    keepaspectratio
  ]{5. Architecture.png}
  \caption{\textsc{SolQDebug} architecture}
  \label{fig:solqdebug-arch}
\end{figure*}

\section{The design of SolQDebug}
    \textsc{SolQDebug} processes code incrementally as developers write it, building up
    an abstract interpretation of the program. The system operates as follows. First, each
    incoming statement or annotation is interpreted under abstract semantics. Second, the
    corresponding construct is stored in a CFG node that is inserted at a semantically valid
    location, determined from the surrounding context and the existing control flow. Third,
    when batch debug annotations are present, the system reinterprets the function with the
    annotated values.
    The following subsections describe the architecture and core mechanisms that enable this incremental analysis.

    \subsection{System Architecture}
        The system accepts either single Solidity statements or batch debug annotations as input.
        These inputs are processed through two main modules:

        \textbf{(1) Parsing Module.}
        Each incoming edit passes through the \textit{Context Analyzer}, which extracts the
        surrounding source context needed to parse the partial statement or annotation. The
        \textit{Interactive Parser}, built on \citet{antlr}, applies an extended grammar that adds
        seven reduction rules to the standard Solidity grammar, enabling it to parse partial
        constructs that would normally fail to compile. Although the extended grammar can parse
        partial constructs, the system still validates the complete reconstructed source using the
        official Solidity compiler before proceeding to analysis. This validation ensures semantic
        consistency and rejects malformed input early.

        \textbf{(2) Analysis Module.}
        The Analysis Module operates through three coordinated components. The \textit{Dynamic CFG
        Builder} maintains an incremental control-flow graph that is updated as new statements are
        added: it creates corresponding nodes for each statement and rewires control edges to reflect
        the updated program structure. The \textit{Abstract Interpreter} incrementally analyzes the
        updated CFG, reusing previous results and computing abstract values only for affected program
        points using a combination of interval and set domains. The \textit{Snapshot Manager} ensures
        that each debug annotation execution starts from a clean state by preserving and restoring
        the abstract memory, allowing annotations to be modified and re-executed without side effects
        from previous runs.

        \textbf{(3) Line-Level Output.}
        Following analysis, the system produces a per-statement summary showing the computed intervals
        for variables affected by each statement---including declarations, assignments, and return values.
        All outputs are mapped to their corresponding source line numbers and displayed inline within
        the editor, providing immediate feedback as developers write and modify code.
    
    \subsection{Running Example}

    To illustrate how the proposed architecture functions in practice, we present
    a concrete example using the \texttt{burn} function from Listing~\ref{lst:grammar-min}.
    This example demonstrates two key analysis modes: incremental edits (\S{}3.2.1)
    and batch annotations (\S{}3.2.2).

        \subsubsection{Incremental Source Code Analysis}

\begin{table}[t!]
  \caption{Incremental inputs for the running example}
  \label{tab:input_code}
  \centering
  \setlength{\tabcolsep}{4pt}
  \renewcommand{\arraystretch}{1.05}
  \ttfamily\footnotesize
  \begin{tabularx}{\columnwidth}{@{}c c X@{}}
    \toprule
    \textbf{Step} & \textbf{Lines of Input Fragment} & \textbf{Fragment} \\
    \midrule
    1 & 11--12 &
      \begin{tabular}[t]{@{}l@{}}
        function burn(uint256 amount) public onlyOwner \{\\
        \}
      \end{tabular} \\
    2 & 12 & uint256 bal = balances[msg.sender]; \\
    3 & 13 & uint256 delta; \\
    4 & 14--15 &
      \begin{tabular}[t]{@{}l@{}}
        if (bal >= amount) \{\\
        \}
      \end{tabular} \\
    5 & 15 & balances[msg.sender] = bal - amount; \\
    6 & 16 & delta = amount; \\
    7 & 18--19 &
      \begin{tabular}[t]{@{}l@{}}
        else \{\\
        \}
      \end{tabular} \\
    8 & 19 & delta = 0; \\
    9 & 21 & totalSupply -= delta; // new input \\
    \bottomrule
  \end{tabularx}
  \rmfamily
\end{table}

As shown in Table~\ref{tab:input_code}, the developer incrementally constructs the \texttt{burn}
function through nine distinct input steps, each introducing a new code fragment.
\textsc{SolQDebug} accepts two kinds of fragments:

\begin{itemize}
  \item \textbf{Block fragments} such as function headers or if/else blocks.
        When the developer types an opening `\{', most editors auto-insert the closing `\}',
        so the complete block arrives at once and may span multiple lines
        (e.g., Step 1 in lines 11--12 of Listing~\ref{lst:grammar-min}).

  \item \textbf{Single statements} ending with semicolons
        (e.g., Steps 2, 3, 5, 6, 8, and 9).
\end{itemize}

\begin{figure*}[!htbp]
  \centering
  \begin{tikzpicture}[scale=0.85, transform shape,
    node distance=1.5cm and 2.5cm,
    block/.style={rectangle, draw, thick, minimum width=3cm, minimum height=1cm, align=center, font=\footnotesize},
    cond/.style={diamond, draw, thick, aspect=2, minimum width=2cm, minimum height=1cm, align=center, font=\footnotesize},
    join/.style={rectangle, draw, thick, fill=yellow!20, minimum width=2.5cm, minimum height=0.6cm, align=center, font=\footnotesize},
    empty/.style={circle, draw, thick, minimum size=0.8cm, font=\large}
  ]

  % Entry and declarations
  \node[block] (entry) {ENTRY};
  \node[block, below=1cm of entry] (decl) {Declarations\\bal, delta\\env: \{bal: $\top$, delta: $\top$\}};

  % Condition node
  \node[cond, below=1.2cm of decl] (cond) {$bal \geq amount$};

  % Branch paths (simplified)
  \node[block, below left=1.5cm and 2cm of cond] (true) {... intermediate nodes ...\\(Steps 5--6)};
  \node[block, below right=1.5cm and 2cm of cond] (false) {... intermediate nodes ...\\(Step 8)};

  % Leaf nodes
  \node[block, below=1cm of true] (leaf_t) {[Leaf T]\\delta = amount\\env: \{bal:$\top$,\\delta:$\top$\}};
  \node[block, below=1cm of false] (leaf_f) {[Leaf F]\\delta = 0\\env: \{bal:$\top$,\\delta:[0,0]\}};

  % Join point
  \node[block, below=2cm of cond, yshift=-2.5cm, fill=yellow!20] (join) {$\sqcup$ Join Node\\env: \{bal:$\top$,\\delta:$\top$\}};

  % New node with Step 9
  \node[block, below=1cm of join, fill=green!15] (step9) {[New Node]\\totalSupply -= delta\\env: \{totalSupply:$\top$\}};

  % Exit
  \node[block, below=1cm of step9] (exit) {EXIT};

  % Edges
  \draw[->, thick] (entry) -- (decl);
  \draw[->, thick] (decl) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {True} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {False} (false);
  \draw[->, thick] (true) -- (leaf_t);
  \draw[->, thick] (false) -- (leaf_f);
  \draw[->, thick] (leaf_t) -| (join);
  \draw[->, thick] (leaf_f) -| (join);
  \draw[->, thick] (join) -- node[right] {Step 9 inserted} (step9);
  \draw[->, thick] (step9) -- (exit);

  \end{tikzpicture}
  \caption{CFG structure showing Step 9 insertion. Each statement occupies a separate basic node; intermediate nodes along each branch are omitted, showing only the leaf nodes before the join point. The join point node computes the least upper bound of environments from both branches}
  \label{fig:solqdebug-cfg}
\end{figure*}

As the developer types each fragment, \textsc{SolQDebug} incrementally extends the CFG
and recomputes abstract values only for affected program points.
Figure~\ref{fig:solqdebug-cfg} visualizes the CFG structure after Steps 1--8 have been integrated.
We focus on Step~9 (\texttt{totalSupply -= delta;}), which illustrates how the system handles CFG
insertion after a conditional branch merge. When Step~9 arrives, \textsc{SolQDebug} processes it
as follows:

\begin{enumerate}
  \item The interactive parser recognizes \texttt{totalSupply -= delta;} as an assignment.
  \item \textsc{SolQDebug} determines the insertion point by examining the edit context and existing CFG.
        In this case, the insertion point is after the join node that merges the if/else branches.
  \item A new CFG node is created for the assignment, and edges are rewired: the join node now
        flows into this new node, which in turn connects to the exit.
  \item The new node receives the environment from the join node, which holds the least upper
        bound (\(\sqcup\)) of environments from both branches.
  \item \textsc{SolQDebug} reinterprets the new node and all reachable nodes to propagate the
        updated environment throughout the CFG.
\end{enumerate}

This reinterpretation maintains soundness: it ensures that all affected nodes reflect the
updated environment, allowing subsequent edits to directly reuse the computed abstract values
without re-analyzing the entire program.

        \subsubsection{Batch Annotation Analysis}

While incremental analysis supports the write-compile-debug cycle, developers often need
to explore how different input ranges affect program behavior. This includes verifying price
calculations in decentralized exchanges, balance constraints in token transfers, or liquidity
ratios in automated market makers.
Batch annotations enable this by letting developers specify initial states declaratively and
obtain line-level results in a single analysis pass, reusing the CFG constructed during
incremental edits.

Listing~\ref{lst:grammar-batch} shows the \texttt{burn} function with batch annotations.
        Annotation blocks are enclosed by \verb|//@Debugging BEGIN| and \verb|//@Debugging END|.
        Each annotation line specifies a variable type (\texttt{@StateVar} for state variables,
        \texttt{@LocalVar} for local variables) and assigns an interval value---supporting both
        simple variables and nested accesses like \texttt{balances[msg.sender]}.

\begin{lstlisting}[language=Solidity, numbers=left, basicstyle=\ttfamily\small, caption={Burn function with batch annotations}, label={lst:grammar-batch}] 
function burn(uint256 amount) public onlyOwner {
    // @Debugging BEGIN     
    // @StateVar balances[msg.sender] = [100,200]
    // @LocalVar amount = [50,150]
    // @Debugging END         
    uint256 bal = balances[msg.sender];
    uint256 delta;
    if (bal >= amount) {
        balances[msg.sender] = bal - amount;
        delta = amount;
    } 
    else {        
        delta = 0;
    }
    totalSupply -= delta;
}

\end{lstlisting}

In this example, we annotate \texttt{balances[msg.sender]} with the interval \([100,200]\)
        and \texttt{amount} with \([50,150]\) to explore how the \texttt{burn} function behaves
        under different balance and amount scenarios.

        When a batch annotation block is encountered, \textsc{SolQDebug} follows a lightweight pipeline:

\begin{enumerate}
  \item \textbf{Parse and validate.} Each annotation line is parsed, type-checked, and converted
        to the corresponding abstract domain (e.g., intervals for integers).
  \item \textbf{Snapshot and overlay.} The current abstract memory is saved, and the annotated
        values are overlaid onto the initial environment.
  \item \textbf{Single-pass analysis.} \textsc{SolQDebug} re-analyzes the pre-built CFG in a single pass
        using the annotated values as the initial environment.
  \item \textbf{Restore snapshot.} After analysis completes, the snapshot is restored to isolate
        successive annotation runs.
\end{enumerate}

Unlike incremental analysis, batch annotations leave the CFG structure unchanged---only
        the initial environment differs. This makes batch runs lightweight, enabling rapid what-if
        exploration. Variables without annotations remain at \(\top\), making explicit initialization
        essential for meaningful results. Formal details of the interactive parser and CFG construction
        appear in \S{}3.3 and \S{}3.4.

\FloatBarrier
\subsection{Interactive Parser}

The Interactive Parser extends the Solidity language grammar~\citet{solgram} with specialized entry rules
that accept partial code fragments during incremental editing.
The parser defines eight specialized entry rules: seven for partial Solidity constructs
during incremental editing, and one for batch-annotation blocks that enable symbolic input scenarios.

\begin{table}[t]
\centering
\caption{Interactive parser entry rules}
\label{tab:interactive-rules}
\small
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{Entry Rule} & \textbf{Purpose} \\
\midrule
interactiveSourceUnit & Top-level declarations: functions, contracts, interfaces, libraries, state variables, pragmas, imports \\
interactiveEnumUnit & Enum member items added after the enum shell is defined \\
interactiveStructUnit & Struct member declarations added after the struct shell is defined \\
interactiveBlockUnit & Statements and control-flow skeletons inside function bodies \\
interactiveDoWhileUnit & The while tail of a do-while loop \\
interactiveIfElseUnit & else or else-if branches following an if statement \\
interactiveCatchClauseUnit & catch clauses following a try statement \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:interactive-rules} shows the seven rules, divided into two categories.
\textit{Primary rules} (\texttt{interactiveSourceUnit}, \texttt{interactiveBlockUnit})
handle independent constructs, while \textit{continuation rules} complete partially-written
structures by filling enum or struct shells or by appending control-flow branches.
This separation prevents syntactically invalid constructs (e.g., an else-branch without
a preceding if-statement) from being parsed as independent statements.

For concreteness, we refer to the burn function in Listing~\ref{lst:grammar-min}.
The function header triggers \texttt{interactiveSourceUnit}, creating a function
with an empty body.
Each new statement invokes \texttt{interactiveBlockUnit}, which includes productions
for both complete statements and control-flow skeletons (see Appendix~\ref{appendix:interactive-grammar}
for the complete grammar hierarchy).
For instance, typing \texttt{if (condition) \{\,\}} produces a skeletal if-statement.
In the burn function, when the developer adds the \texttt{else} branch,
\texttt{interactiveIfElseUnit} attaches it to the existing if-statement.
This skeleton-based approach allows incremental construction, one construct at a time,
without requiring syntactic completeness.

Beyond these seven interactive rules for Solidity constructs, the parser includes
a specialized \texttt{debugUnit} rule for testing scenarios.
The debugUnit rule parses batch-annotation lines that specify initial abstract values for variables,
enabling symbolic input scenarios without contract deployment.
The grammar defines three annotation types:

\begin{itemize}[itemsep=2pt]
  \item GlobalVar assigns values to global variables such as msg.sender or block.timestamp
  \item StateVar assigns values to contract state variables, supporting nested access patterns like balances[msg.sender] or user.balance
  \item LocalVar assigns values to function parameters and local variables
\end{itemize}

Each annotation accepts an L-value and a value specification.
Supported value formats include integer intervals, symbolic addresses,
boolean values, and symbolic placeholders for bytes and strings.
The parser validates type compatibility and range bounds at parse time,
warning developers if annotated values are incompatible with declared types.

The annotation syntax and validation rules are specified in Appendix~\ref{appendix:interactive-grammar},
with the full ANTLR4 implementation available at~\citet{solqrule}.

\FloatBarrier
    \subsection{Dynamic CFG Construction}

Dynamic CFG construction maintains the control-flow graph incrementally as developers insert new statements.
Rather than rebuilding from scratch, our approach modifies the graph in place.
We proceed in three steps. First, we construct and splice a CFG fragment for each statement form.
Second, we locate where to insert it in the existing graph.
Third, we re-interpret only the affected region to update abstract environments.

Our CFG consists of the following node types:
\begin{itemize}
  \item \textsc{entry node}: The unique function entry point where execution begins.
  \item \textsc{basic node}: Holds exactly one statement (e.g., a variable declaration, an assignment, or a function call).
  \item \textsc{condition node}: Represents branching constructs such as \texttt{if}, \texttt{else if}, \texttt{while}, \texttt{require}/\texttt{assert}, and \texttt{try}.
  \item \textsc{join node}: Merges control flow from multiple branches (e.g., \textsc{if join}, \textsc{else-if join}).
  \item \textsc{fixpoint evaluation node} (\(\phi\)): The loop join point used for widening and narrowing during fixpoint computation.
  \item \textsc{loop exit node}: The false branch that exits a loop when the guard condition fails.
  \item \textsc{return node}: A statement node whose outgoing edge is immediately rewired to the function's unique \textsc{return exit}.
  \item \textsc{error exit}: The function's unique exceptional exit (targets the exceptional path via \texttt{revert}, \texttt{require}, or \texttt{assert} failures).
  \item \textsc{exit node}: The function's unique normal exit point where execution terminates successfully.
\end{itemize}

\subsubsection{Statement-Local, Incremental Construction}

Every insertion operates at the \textsc{current node} without restructuring the rest of the graph. To enable direct insertion, each basic node holds exactly one statement.

Assignments, function calls, and unary operations create a single \textsc{basic node} inserted between the current node and its successors (Figure~\ref{fig:new-simple-statement}). An \texttt{if} statement creates a \textsc{condition node}, true/false \textsc{basic nodes}, and an \textsc{if join} (Figure~\ref{fig:new-if}). An \texttt{else if} replaces the previous false branch with a new condition and its own join, connecting to the outer \textsc{if join} (Figure~\ref{fig:new-else-if}). An \texttt{else} attaches directly to the false branch without creating a new condition node (Figure~\ref{fig:new-else}).

A \texttt{while} loop creates a \textsc{fixpoint evaluation node} $\phi$, a \textsc{condition node}, a loop body node, and a \textsc{loop exit node}. The body connects back to $\phi$ for fixpoint iteration (Figure~\ref{fig:new-while}). A \texttt{for} loop follows the same pattern with additional initialization and increment nodes. A \texttt{do\{\} while} is built incrementally: the body is created first, then the trailing \texttt{while} attaches the $\phi$ and condition nodes.

A \texttt{break} redirects its outgoing edge to the \textsc{loop exit node} (Figure~\ref{fig:new-break}). A \texttt{continue} redirects to the loop's $\phi$ node (Figure~\ref{fig:new-continue}). A \texttt{return} is immediately rewired to the function's unique \textsc{return exit}, detaching its original successors (Figure~\ref{fig:new-return}). \texttt{require} and \texttt{assert} create a \textsc{condition node} with the true edge connecting to a continuation node and the false edge pointing to the \textsc{error exit} (Figure~\ref{fig:new-require}). A \texttt{try\{\} catch\{\}} follows a similar pattern with catch blocks replacing the false edge.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1cm,
  block/.style={rectangle, draw, thick, minimum width=2.5cm, minimum height=0.8cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[block, below=of current, fill=green!15] (new) {New Statement\\Node};
  \node[dots, below=of new] (succ) {...};

  \draw[->, thick] (current) -- node[right] {splice} (new);
  \draw[->, thick] (new) -- node[right] {reconnect} (succ);

  % Before state (left side)
  \node[block, left=3cm of current] (before_cur) {Current Node};
  \node[dots, below=of before_cur] (before_succ) {...};
  \draw[->, thick] (before_cur) -- (before_succ);

  \node[above=0.3cm of before_cur, font=\footnotesize\bfseries] {Before};
  \node[above=0.3cm of current, font=\footnotesize\bfseries] {After};
\end{tikzpicture}
\caption{Simple statement insertion. The builder creates one node and splices it between the current node and the original successors}
\label{fig:new-simple-statement}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1.2cm and 1.5cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  join/.style={rectangle, draw=black, thick, fill=yellow!20, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=of current, fill=green!15] (cond) {guard};
  \node[block, below left=of cond, fill=green!15] (true) {True\\Node};
  \node[block, below right=of cond, fill=green!15] (false) {False\\Node};
  \node[join, draw=black, below=2.5cm of cond, fill=green!15] (join) {If\\{} Join Node};
  \node[dots, below=of join] (succ) {...};

  \draw[->, thick] (current) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (false);
  \draw[->, thick] (true) |- (join);
  \draw[->, thick] (false) |- (join);
  \draw[->, thick] (join) -- (succ);
\end{tikzpicture}
\caption{If statement insertion. The builder creates a \textsc{condition node}, two nodes for true/false arms, and an \textsc{if join}}
\label{fig:new-if}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1.2cm and 2cm,
  block/.style={rectangle, draw, thick, minimum width=1.8cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.3cm, align=center, font=\footnotesize},
  join/.style={rectangle, draw=black, thick, fill=yellow!20, minimum width=1.8cm, minimum height=0.7cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=1cm of current] (if_cond) {if guard};
  \node[block, below left=1.2cm and 2.2cm of if_cond] (if_true) {If True\\Node};
  \node[dots, below=0.6cm of if_true] (if_dots) {...};

  % else-if branch (highlighted)
  \node[cond, below right=1.2cm and 2.2cm of if_cond, fill=green!15] (elif_cond) {else-if\\guard};
  \node[block, below left=1cm and 1.5cm of elif_cond, fill=green!15] (elif_true) {Else-If\\True Node};
  \node[block, below right=1cm and 1.5cm of elif_cond, fill=green!15] (elif_false) {Else-If\\False Node};

  \node[join, draw=black, below=2.5cm of elif_cond, fill=green!15] (elif_join) {Else-If\\{} Join Node};
  \node[join, draw=black, below=5.5cm of if_cond] (if_join) {If\\{} Join Node};
  \node[dots, below=0.6cm of if_join] (succ) {...};

  \draw[->, thick] (current) -- (if_cond);
  \draw[->, thick] (if_cond) -| node[above left, pos=0.25] {T} (if_true);
  \draw[->, thick] (if_cond) -| node[above right, pos=0.25] {F} (elif_cond);
  \draw[->, thick] (elif_cond) -| node[above left, pos=0.25] {T} (elif_true);
  \draw[->, thick] (elif_cond) -| node[above right, pos=0.25] {F} (elif_false);
  \draw[->, thick] (if_dots) -- ++(0,-1.5) -| (if_join);
  \draw[->, thick] (elif_true) |- (elif_join);
  \draw[->, thick] (elif_false) |- (elif_join);
  \draw[->, thick] (elif_join) |- (if_join);
  \draw[->, thick] (if_join) -- (succ);
\end{tikzpicture}
\caption{Else-if statement insertion. The builder replaces the false arm with a new \textsc{condition node}, two nodes, and an \textsc{else-if join}}
\label{fig:new-else-if}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1.2cm and 2cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  join/.style={rectangle, draw=black, thick, fill=yellow!20, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=1cm of current] (cond) {guard};
  \node[block, below left=1.2cm and 2cm of cond] (true) {True\\Node};
  \node[dots, below=0.6cm of true] (true_dots) {...};
  \node[block, below right=1.2cm and 2cm of cond, fill=green!15] (else) {Else\\Node};
  \node[dots, below=0.6cm of else] (else_dots) {...};
  \node[join, draw=black, below=3.5cm of cond] (join) {If\\{} Join Node};
  \node[dots, below=0.6cm of join] (succ) {...};

  \draw[->, thick] (current) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (else);
  \draw[->, thick] (true) -- (true_dots);
  \draw[->, thick] (else) -- (else_dots);
  \draw[->, thick] (true_dots) -- ++(0,-0.5) -| (join);
  \draw[->, thick] (else_dots) -- ++(0,-0.5) -| (join);
  \draw[->, thick] (join) -- (succ);
\end{tikzpicture}
\caption{Else statement insertion. The builder attaches a node to the false branch of the corresponding \texttt{if}/\texttt{else if}, connecting to the \textsc{if join}}
\label{fig:new-else}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1cm and 2.2cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  phi/.style={circle, draw, thick, fill=blue!15, minimum size=1cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[phi, below=1cm of current, fill=green!15] (phi) {$\phi$};
  \node[cond, below=1cm of phi, fill=green!15] (cond) {guard};
  \node[block, below left=1.2cm and 2.2cm of cond, fill=green!15] (body) {Body\\Entry Node};
  \node[block, below right=1.2cm and 2.2cm of cond, fill=green!15] (exit) {Loop\\Exit Node};
  \node[dots, below=0.6cm of exit] (succ) {...};

  \draw[->, thick] (current) -- (phi);
  \draw[->, thick] (phi) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (body);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (exit);
  \draw[->, thick] (body) -- ++(-1.5,0) |- node[above left, pos=0.15] {back edge} (phi);
  \draw[->, thick] (exit) -- (succ);
\end{tikzpicture}
\caption{While loop insertion. The builder creates a \textsc{fixpoint evaluation node} $\phi$, a \textsc{condition node}, a loop body node, and a \textsc{loop exit node}}
\label{fig:new-while}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1cm and 2.5cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.3cm, align=center, font=\footnotesize},
  phi/.style={circle, draw, thick, fill=blue!15, minimum size=0.8cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[phi] (phi) {$\phi$};
  \node[cond, below=0.8cm of phi] (cond) {guard};
  \node[block, below left=1cm and 2cm of cond] (body) {Body Node};
  \node[dots, below=0.5cm of body] (body_dots) {...};
  \node[block, below=0.5cm of body_dots, fill=green!15] (break) {\texttt{break}};
  \node[block, below right=1cm and 2cm of cond] (exit) {Loop\\Exit Node};

  \draw[->, thick] (phi) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.2] {T} (body);
  \draw[->, thick] (cond) -| node[above right, pos=0.2] {F} (exit);
  \draw[->, thick] (body) -- (body_dots);
  \draw[->, thick] (body_dots) -- (break);
  \draw[->, thick] (break) -| node[above right, pos=0.6] {redirect} (exit);
\end{tikzpicture}
\caption{Break statement insertion. The \texttt{break} node's outgoing edge is redirected to the \textsc{loop exit node}}
\label{fig:new-break}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1cm and 2.5cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.3cm, align=center, font=\footnotesize},
  phi/.style={circle, draw, thick, fill=blue!15, minimum size=0.8cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[phi] (phi) {$\phi$};
  \node[cond, below=0.8cm of phi] (cond) {guard};
  \node[block, below left=1cm and 2cm of cond] (body) {Body Node};
  \node[dots, below=0.5cm of body] (body_dots) {...};
  \node[block, below=0.5cm of body_dots, fill=green!15] (continue) {\texttt{continue}};
  \node[block, below right=1cm and 2cm of cond] (exit) {Loop\\Exit Node};

  \draw[->, thick] (phi) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.2] {T} (body);
  \draw[->, thick] (cond) -| node[above right, pos=0.2] {F} (exit);
  \draw[->, thick] (body) -- (body_dots);
  \draw[->, thick] (body_dots) -- (continue);
  \draw[->, thick] (continue) -- ++(-1.5,0) |- node[left, pos=0.25] {redirect} (phi);
\end{tikzpicture}
\caption{Continue statement insertion. The \texttt{continue} node's outgoing edge is redirected to the loop's \textsc{fixpoint evaluation node} $\phi$}
\label{fig:new-continue}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  exit/.style={rectangle, draw, thick, rounded corners, fill=red!15, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[block, below=of current, fill=green!15] (return) {\texttt{return}\\Node};
  \node[exit, below right=0.5cm and 2cm of return] (exit) {RETURN\\EXIT};
  \node[dots, below left=0.5cm and 0.5cm of return] (detached) {...};

  \draw[->, thick] (current) -- (return);
  \draw[->, thick, bend left=15] (return) to node[above right] {rewire} (exit);
  \draw[->, thick, dashed, gray] (return) -- node[left, gray] {detached} (detached);
\end{tikzpicture}
\caption{Return statement insertion. The \texttt{return} node is rewired to the function's unique \textsc{return exit}}
\label{fig:new-return}
\end{figure}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, transform shape,
  node distance=1cm and 2cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  exit/.style={rectangle, draw, thick, rounded corners, fill=red!15, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=of current, fill=green!15] (cond) {predicate};
  \node[block, below left=of cond, fill=green!15] (true) {True\\Node};
  \node[exit, below right=of cond] (error) {ERROR\\EXIT};
  \node[dots, below=of true] (succ) {...};

  \draw[->, thick] (current) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (error);
  \draw[->, thick] (true) -- (succ);
\end{tikzpicture}
\caption{Require/assert statement insertion. The builder creates a \textsc{condition node} with true edge to a node and false edge to the \textsc{error exit}}
\label{fig:new-require}
\end{figure}

\subsubsection{Line-Aware Successor-First Insertion-Site Selection}

We keep a lightweight line--to--node index to make insertion local. Each newly created node is
attached to one or two source lines depending on whether the construct is single-line (terminated by
";") or brace-delimited. This index is used only to locate the insertion site; the algorithm below does not mutate the graph.

\noindent\textbf{Line-to-node index mapping.}
We maintain a line-to-node index that maps source lines to CFG nodes, enabling efficient insertion-site lookup. Each indexed node records a \emph{start line} where the construct begins; brace-delimited constructs additionally record an \emph{end line} at the closing brace. Table~\ref{tab:line-mapping} summarizes how different statement types are indexed. Notably, not all nodes are indexed---only those required for insertion-site selection appear in the index, while auxiliary nodes (e.g., branch blocks, fixpoint join nodes) are omitted to keep the index lightweight.

\begin{table}[t]
\centering
\caption{Line-to-node index mapping by statement type}
\label{tab:line-mapping}
\small
\begin{tabular}{@{}lll|lll@{}}
\toprule
\multicolumn{3}{c|}{\textbf{Semicolon-Terminated Statements}} & \multicolumn{3}{c}{\textbf{Brace-Delimited Constructs}} \\
\textbf{Statement} & \textbf{Start Line} & \textbf{End Line} & \textbf{Statement} & \textbf{Start Line} & \textbf{End Line} \\
\midrule
Variable decl. & statement node & --- & Function def. & \textsc{entry} node & \textsc{exit} node \\
Assignment & statement node & --- & \texttt{if} & condition node & join node \\
Function call & statement node & --- & \texttt{else if} & condition node & local join node \\
Unary ops & statement node & --- & \texttt{else} & else node & (reused join) \\
\texttt{continue} & statement node & --- & \texttt{while} & condition node & exit node \\
\texttt{break} & statement node & --- & \texttt{for} & condition node & exit node \\
\texttt{return} & new statement node & --- & \texttt{do} & do-entry node & --- \\
\texttt{revert} & current node & --- & \texttt{do-while} & condition node & --- \\
\texttt{require} & condition node & --- & \texttt{try} & try condition & --- \\
\texttt{assert} & condition node & --- & \texttt{catch} & catch entry & --- \\
\bottomrule
\end{tabular}
\end{table}

Semicolon-terminated statements are indexed at a single start line with no end line, reflecting their single-line nature. Among these, \texttt{return} creates a new statement node, while \texttt{revert} directly registers the current node---this distinction reflects how \texttt{revert} does not introduce a new control-flow block but terminates the current one.

Brace-delimited constructs span multiple lines: the start line corresponds to the opening keyword (e.g., \texttt{if}, \texttt{while}), and the end line marks the closing brace. Function definitions index the \textsc{entry} node at the opening brace and the \textsc{exit} node at the closing brace. The \texttt{else} branch is an exception---it indexes the else node at the \texttt{else} keyword but reuses the join node from the preceding \texttt{if} or \texttt{else if}, sharing the outer join point. For loops, internal nodes such as the join node (used for fixpoint evaluation) and increment nodes remain unindexed, as they are not required for insertion. The \texttt{do} statement indexes only the entry node, while \texttt{do-while} indexes the condition node; neither registers an exit node in the current implementation. Similarly, branch blocks (e.g., \texttt{if\_true}, \texttt{if\_false}) and auxiliary nodes are excluded from the index.

This lightweight indexing scheme enables the algorithms described below to locate insertion sites efficiently by line number, without requiring full graph traversal.


\begin{algorithm}[!t]
\caption{Branch-Context Insertion-Site Selection (\textsc{GetBranchContext})}
\label{alg:get-branch-context}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$, edit context $\mathit{ctx}\in\{\texttt{else\_if},\texttt{else},\texttt{catch}\}$, current line $L$
\Ensure Condition node $c\in V$ (and optionally outer join $j\in V$ for \texttt{else\_if}/\texttt{else})
\State $N \gets \textsc{NodesAtLine}(L)$ \Comment{all CFG nodes indexed at line $L$}
\If{$N=\emptyset$} \State $N \gets \textsc{NodesAtPreviousLine}(L)$ \Comment{search backward if $L$ is empty} \EndIf
\State $j_{\mathit{outer}} \gets \bot$
\If{$\mathit{ctx}\in\{\texttt{else\_if},\texttt{else}\}$}
  \For{$n\in N$}
    \If{$\mathsf{isJoin}(n)$} \State $j_{\mathit{outer}} \gets n$ \textbf{ break} \Comment{outer join at current line} \EndIf
  \EndFor
\EndIf

\State $\mathit{Queue} \gets N$; $\mathit{Visited} \gets \emptyset$ \Comment{BFS through predecessors}
\While{$\mathit{Queue}\neq\emptyset$}
  \State $n \gets \textsc{Dequeue}(\mathit{Queue})$
  \If{$n\in\mathit{Visited}$} \textbf{continue} \EndIf
  \State $\mathit{Visited} \gets \mathit{Visited}\cup\{n\}$

  \If{$\mathsf{isCond}(n)$}
    \State $\tau \gets \textsc{CondType}(n)$ \Comment{type: \texttt{if}, \texttt{else\_if}, \texttt{try}, etc.}
    \If{$\mathit{ctx}\in\{\texttt{else\_if},\texttt{else}\}$ \textbf{and} $\tau\in\{\texttt{if},\texttt{else\_if}\}$}
      \If{$j_{\mathit{outer}}=\bot$} \State $j_{\mathit{outer}} \gets \textsc{OuterJoinFromGraph}(n)$ \Comment{fallback} \EndIf
      \State \Return $(n,\, j_{\mathit{outer}})$
    \ElsIf{$\mathit{ctx}=\texttt{catch}$ \textbf{and} $\tau=\texttt{try}$}
      \State \Return $n$
    \EndIf
  \EndIf

  \For{$p\in\textsc{Predecessors}(n)$}
    \If{$p\notin\mathit{Visited}$} \State $\textsc{Enqueue}(\mathit{Queue},p)$ \EndIf
  \EndFor
\EndWhile

\State \textbf{error} ``No matching condition node found for context $\mathit{ctx}$''
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!t]
\caption{Successor-First Insertion-Site Selection (\textsc{GetInsertionSite})}
\label{alg:get-insertion-site}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$, edit span ending at line $L$
\Ensure Insertion-site node $A\in V$ (no graph mutation here)
\State $s \gets \textsc{FirstNodeAfter}(L)$ \Comment{scan lines $>L$ until the first indexed node}
\If{$s=\bot$} \State $s\gets \textsf{EXIT}$ \EndIf
\State $\ell \gets \textsc{LineOf}(s)$

\If{$\mathsf{isLoopExit}(s)$} \Comment{closing a loop}
  \State $N_{\mathit{prev}} \gets \textsc{NodesAtPreviousLine}(L)$ \Comment{search backward from $L$ to find previous nodes}
  \If{$N_{\mathit{prev}}\neq\emptyset$}
    \State $c \gets \textsc{LastCondInNodes}(N_{\mathit{prev}})$ \Comment{check if previous line has a condition}
    \If{$c\neq\bot$}
       \State \Return $\textsc{BranchBlock}(c,\mathsf{true})$ \Comment{insert in TRUE branch (loop body)}
    \Else
       \State \Return $\textsc{Last}(N_{\mathit{prev}})$ \Comment{last node of previous line}
    \EndIf
  \Else
    \State \Return $\textsc{FirstPredecessor}(s)$ \Comment{fallback}
  \EndIf

\ElsIf{$\mathsf{isJoin}(s)$} \Comment{closing a selection}
  \State $N_{\mathit{prev}} \gets \textsc{NodesAtPreviousLine}(L)$
  \If{$N_{\mathit{prev}}\neq\emptyset$}
    \State $c \gets \textsc{LastCondInNodes}(N_{\mathit{prev}})$
    \If{$c\neq\bot$}
       \State \Return $\textsc{BranchBlock}(c,\mathsf{true})$ \Comment{default to TRUE branch for \texttt{if}}
    \Else
       \State \Return $\textsc{Last}(N_{\mathit{prev}})$
    \EndIf
  \Else
    \State \Return $\textsc{FirstPredecessor}(s)$
  \EndIf

\Else \Comment{basic successor}
  \State $\mathit{Pred} \gets \textsc{Predecessors}(s)$
  \If{$|\mathit{Pred}|=1$} \State \Return the unique element of $\mathit{Pred}$
  \Else \State \Return $\textsc{NearestByLine}(\mathit{Pred},\,L)$ \Comment{choose closest to current line $L$}
  \EndIf
\EndIf
\end{algorithmic}
\end{algorithm}

We dispatch insertion-site selection based on the edit context:
\begin{itemize}
  \item \textbf{Branch contexts} (\texttt{else}/\texttt{else if}/\texttt{catch}) use Algorithm~\ref{alg:get-branch-context} to find the preceding condition node by traversing predecessors.
  \item \textbf{Regular statements} use Algorithm~\ref{alg:get-insertion-site}, which employs a \textsc{successor-first} strategy: locate the earliest CFG node after the edit span and determine the most local predecessor.
\end{itemize}
Both algorithms never mutate the graph and rely solely on the line--to--node index for efficient lookup.

\noindent\textbf{Algorithm~\ref{alg:get-branch-context}: Branch-Context Insertion.}
For \texttt{else}/\texttt{else if}/\texttt{catch}, we must attach the new branch to a previously created condition node. The algorithm:
\begin{itemize}
  \item \textbf{Line 1--4:} Retrieves CFG nodes at the current line \(L\) (or searches backward if \(L\) is empty). For \texttt{else\_if}/\texttt{else}, it also identifies the outer join node at \(L\), if present.
  \item \textbf{Line 9--24:} Performs BFS through CFG predecessors to find the matching condition node: for \texttt{else\_if}/\texttt{else}, it looks for a node of type \texttt{if} or \texttt{else\_if}; for \texttt{catch}, it looks for type \texttt{try}.
  \item \textbf{Line 11--12:} When the matching condition is found for \texttt{else\_if}/\texttt{else}, the algorithm returns both the condition node and the outer join (if the outer join was not found at line \(L\), a fallback uses the graph structure).
\end{itemize}

\noindent\textbf{Algorithm~\ref{alg:get-insertion-site}: Successor-First Insertion.}
For regular statements, we look ahead to determine the insertion site:
\begin{itemize}
  \item \textbf{Line 1--3:} \textsc{FirstNodeAfter}(\(L\)) scans lines strictly larger than \(L\) in the line--to--node index and returns the first node; if none is found, we default to \texttt{EXIT}.
  \item \textbf{Line 5--14 (loop-exit):} If the successor \(s\) is a loop-exit node, we search backward from \(L\) to find the previous line's nodes. If the previous line contains a condition node (the loop header), we return its TRUE branch (the loop body entry); otherwise, we return the last node of the previous line.
  \item \textbf{Line 16--23 (join):} If \(s\) is a join node (closing a selection), we apply the same backward search. If a condition node is found, we return its TRUE branch (default for \texttt{if} constructs); otherwise, return the last previous node.
  \item \textbf{Line 25--28 (basic successor):} If \(s\) is a regular basic node, we return its unique predecessor, or choose the predecessor closest to line \(L\) if multiple exist.
\end{itemize}

\noindent\textbf{Helper functions.}
\begin{itemize}
  \item \textsc{NodesAtLine}(\(L\)) / \textsc{NodesAtPreviousLine}(\(L\)): Return all CFG nodes indexed at line \(L\) or the first non-empty line before \(L\).
  \item \textsc{FirstNodeAfter}(\(L\)): Returns the first CFG node indexed at any line \(>L\).
  \item \textsc{LastCondInNodes}(\(N\)): Scans node list \(N\) in reverse to find the last condition node.
  \item \textsc{BranchBlock}(\(c,t\)): Returns the successor of condition \(c\) along the edge labeled with truth value \(t\).
  \item \textsc{OuterJoinFromGraph}(\(c\)): Walks the graph from condition \(c\) through its TRUE branch to find the join node.
  \item \textsc{NearestByLine}(\(X,\ell\)): Returns \(\arg\min_{x\in X} \lvert \textsc{LineOf}(x)-\ell \rvert\).
  \item \textsc{Predecessors}(\(s\)), \textsc{FirstPredecessor}(\(s\)): Standard CFG predecessor queries.
\end{itemize}

        
        \subsubsection{Abstract Interpretation for Incremental Analysis}

Our system handles two types of edits during interactive debugging, each triggering a different analysis strategy. Debug annotation input follows a batch-and-flush pattern: annotations are accumulated and processed together, culminating in a full interpretation of the entire function CFG from \texttt{ENTRY} to \texttt{EXIT} (Algorithm~\ref{alg:interpret-full}). This ensures that all annotated inspection points receive freshly computed abstract states. In contrast, source code edits---such as inserting \texttt{require}, assignments, or control structures---are processed immediately: dynamic CFG construction (Algorithms~\ref{alg:get-branch-context} and~\ref{alg:get-insertion-site}) splices the new nodes into the graph, and change-driven reinterpretation (Algorithm~\ref{alg:reinterpret}) propagates updates only along affected paths, providing instant feedback without re-analyzing the entire function. Both strategies invoke the same loop fixpoint subroutine (Algorithm~\ref{alg:fixpoint}) when encountering loop headers.



\begin{algorithm}[!htbp]
\caption{Initial Function Interpretation (\textsc{InterpretFunctionCFG})}
\label{alg:interpret-full}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$ with designated \texttt{ENTRY} node
\Ensure All nodes have computed abstract environments
\State $\textit{WL}\gets\langle\texttt{ENTRY}\rangle$; \quad $\textit{inQ}\gets\{\texttt{ENTRY}\}$; \quad $\textit{Out}\gets$ snapshot map

\While{$\textit{WL}\neq\langle\rangle$}
  \State $n \gets \textit{WL}.\textsf{pop}()$; \quad $\textit{inQ}\gets \textit{inQ}\setminus\{n\}$
  \State $\hat{\sigma}_{in}\gets\bot$ \Comment{compute incoming environment from all predecessors}
  \ForAll{$p\in\textsc{Predecessors}(n)$}
     \State $\sigma_p \gets \Env(p)$
     \If{$\mathsf{isCond}(p)\ \land\ \mathsf{hasTruthLabel}(p{\to}n)$}
        \State $t \gets \textsf{edgeLabel}(p{\to}n)$
        \State $\sigma_p \gets \textsc{Refine}(\sigma_p,p.\textsf{cond},t)$
        \If{$\neg\textsc{Feasible}(\sigma_p,p.\textsf{cond},t)$} \State $\sigma_p \gets \bot$ \EndIf
     \EndIf
     \State $\hat{\sigma}_{in}\gets \hat{\sigma}_{in}\ \sqcup\ \sigma_p$
  \EndFor

  \If{$\mathsf{isLoopHeader}(n)$}
     \State $\textit{exitNode} \gets \textsc{Fixpoint}(n)$ \Comment{Algorithm~\ref{alg:fixpoint}}
     \ForAll{$u\in \Succ(\textit{exitNode})$}
       \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
     \State \textbf{continue}
  \EndIf

  \State $\hat{\sigma}_{out}\gets \textsc{Transfer}(n,\hat{\sigma}_{in})$
  \If{$\hat{\sigma}_{out}\neq \textit{Out}[n]$}
     \State $\Env(n)\gets \hat{\sigma}_{out}$; \quad $\textit{Out}[n]\gets \hat{\sigma}_{out}$
     \ForAll{$u\in \Succ(n)$}
        \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
  \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!htbp]
\caption{Change-Driven Reinterpretation (\textsc{ReinterpretFrom})}
\label{alg:reinterpret}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$; seed set $S$ returned by the builder
\Ensure Environments updated along forward-reachable paths from $S$
\State $\textit{WL}\gets\langle\rangle$; \quad $\textit{inQ}\gets\emptyset$; \quad $\textit{Out}\gets$ snapshot map
\ForAll{$s\in S$} \Comment{filter and enqueue all non-sink seeds}
  \If{$\neg\mathsf{isSink}(s)\ \land\ s\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(s)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{s\}$ \EndIf
\EndFor

\While{$\textit{WL}\neq\langle\rangle$}
  \State $n \gets \textit{WL}.\textsf{pop}()$; \quad $\textit{inQ}\gets \textit{inQ}\setminus\{n\}$
  \State $\hat{\sigma}_{in}\gets\bot$ \Comment{compute incoming environment from all predecessors}
  \ForAll{$p\in\textsc{Predecessors}(n)$}
     \State $\sigma_p \gets \Env(p)$
     \If{$\mathsf{isCond}(p)\ \land\ \mathsf{hasTruthLabel}(p{\to}n)$} \Comment{refine by condition}
        \State $t \gets \textsf{edgeLabel}(p{\to}n)$
        \State $\sigma_p \gets \textsc{Refine}(\sigma_p,p.\textsf{cond},t)$ \Comment{apply path constraint}
        \If{$\neg\textsc{Feasible}(\sigma_p,p.\textsf{cond},t)$} \State $\sigma_p \gets \bot$ \EndIf \Comment{prune infeasible}
     \EndIf
     \State $\hat{\sigma}_{in}\gets \hat{\sigma}_{in}\ \sqcup\ \sigma_p$
  \EndFor

  \If{$\mathsf{isLoopHeader}(n)$} \Comment{handle loop by local fixpoint}
     \State $\textit{exitNode} \gets \textsc{Fixpoint}(n)$ \Comment{compute fixpoint; returns loop-exit node}
     \ForAll{$u\in \Succ(\textit{exitNode})$}
       \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
     \State \textbf{continue} \Comment{skip standard transfer for loop header}
  \EndIf

  \State $\hat{\sigma}_{out}\gets \textsc{Transfer}(n,\hat{\sigma}_{in})$ \Comment{apply statement effects}
  \If{$\hat{\sigma}_{out}\neq \textit{Out}[n]$} \Comment{change detected}
     \State $\Env(n)\gets \hat{\sigma}_{out}$; \quad $\textit{Out}[n]\gets \hat{\sigma}_{out}$
     \ForAll{$u\in \Succ(n)$}
        \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
  \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:interpret-full} performs initial interpretation when debug annotations are first introduced to a function. It begins with the \texttt{ENTRY} node enqueued and propagates abstract environments forward through the entire CFG using a standard worklist iteration. Algorithm~\ref{alg:reinterpret}, in contrast, handles source code edits: the dynamic CFG builder returns one or more seed nodes (never sinks) that mark the insertion points, and the algorithm propagates updates only along forward-reachable paths from these seeds. The choice of seed depends on the statement type: sequential statements (\texttt{assignment}, \texttt{function call}) seed at the newly inserted block; control-flow constructs (\texttt{if}/\texttt{while}/\texttt{for}) seed at their join or loop-exit node to capture all downstream effects; terminating statements (\texttt{return}/\texttt{revert}) seed at the original successors before rewiring; and assertions (\texttt{require}/\texttt{assert}) seed at the true-branch successor. Seeds corresponding to sink nodes (\texttt{EXIT}, \texttt{ERROR}, \texttt{RETURN}) are filtered out because they contribute nothing to downstream analysis.

Both algorithms share the same core iteration structure. Each node computes its incoming environment $\hat{\sigma}_{in}$ by joining all predecessor flows. For predecessors that are condition nodes, we apply path-sensitive refinement: the environment is updated according to the condition and the edge's truth label (true or false), and infeasible branches---where the refined environment contradicts the guard---are pruned by setting $\sigma_p$ to $\bot$. This ensures that only feasible execution paths contribute to the analysis.

Loop headers receive special treatment in both algorithms. When the worklist reaches a loop header, we invoke a dedicated fixpoint procedure (Algorithm~\ref{alg:fixpoint}) that recomputes abstract states for the entire loop body using widening and narrowing. The fixpoint returns the loop-exit node, whose successors are then enqueued for further propagation. This design localizes loop effects: in Algorithm~\ref{alg:reinterpret}, any edit inside a loop body naturally triggers a fresh fixpoint once the header is encountered, without requiring the builder to seed every loop-internal change explicitly.

The change guard mechanism is critical for efficiency. After computing the transfer function's result $\hat{\sigma}_{out}$, we compare it with the previous snapshot $\textit{Out}[n]$. Only when a change is detected do we update the node's environment, refresh the snapshot, and enqueue non-sink successors. This guarantees termination and avoids redundant work: if downstream nodes remain unaffected, propagation halts. Crucially, it does not miss any updates, because any upstream alteration that modifies a node's input will also alter its output (even for identity transfers on join or condition nodes), thus triggering further propagation.

\begin{algorithm}[!htbp]
\footnotesize
\caption{Loop Fixpoint at Header}
\label{alg:fixpoint}
\begin{algorithmic}[1]
\Require loop header (condition) node $h$
\Ensure Converged abstract environments at the loop exit and inside the loop
\State $\mathit{L} \gets \textsc{TraverseLoopNodes}(h)$ \Comment{nodes dominated by $h$ and on some back-edge to $h$}
\State $\textit{vis}[\cdot]\gets 0$;\quad $\textit{In}[\cdot],\textit{Out}[\cdot]\gets \bot$
\State $\textit{Start} \gets \bigsqcup\{\Env(p)\mid p\in\Pred(h)\setminus \mathit{L}\}$ \Comment{pre-loop env (exclude back-edges)}
\State $\textit{In}[h]\gets \textit{Start}$
\State $\tau \gets \textsc{EstimateIterations}(h,\textit{Start})$ \Comment{visit threshold for widening}
\Statex
\State \textbf{// Widening phase (ascending)}
\State $\mathit{WL}\gets \langle h\rangle$
\While{$\mathit{WL}\neq\langle\rangle$}
  \State $n\gets \mathit{WL}.\textsf{pop}()$;\quad $\textit{vis}[n]\gets \textit{vis}[n]+1$
  \State $\hat{o}\gets \textsc{Transfer}(n,\textit{In}[n])$
  \If{$\textsc{IsJoin}(n)\ \land\ \textit{vis}[n] > \tau$}
     \State $\hat{o}\gets \textsc{Widen}(\textit{Out}[n],\hat{o})$
  \Else
     \State $\hat{o}\gets \textit{Out}[n]\sqcup \hat{o}$
  \EndIf
  \If{$\textsc{IsJoin}(n)\ \land\ \textsc{CondConverged}(n)$} \Comment{optional early stop}
     \State $\textit{Out}[n]\gets \hat{o}$;\quad \textbf{break}
  \EndIf
  \If{$\hat{o}\neq \textit{Out}[n]$}
     \State $\textit{Out}[n]\gets \hat{o}$
     \ForAll{$s\in \Succ(n)\cap \mathit{L}$}
        \State $\textit{In}[s]\gets \bigsqcup\ \{\ \textsc{Flow}(p{\to}s)\mid p\in\Pred(s)\cap \mathit{L}\ \}$ \Comment{edge-pruned join}
        \State $\mathit{WL}.\textsf{push}(s)$
     \EndFor
  \EndIf
\EndWhile
\Statex
\State \textbf{// Narrowing phase (descending)}
\State $\mathit{WL}\gets$ any worklist ordering over $\mathit{L}$
\While{$\mathit{WL}\neq\langle\rangle$}
  \State $n\gets \mathit{WL}.\textsf{pop}()$
  \State $\hat{o}\gets \textsc{Transfer}(n,\textit{In}[n])$
  \If{$\textsc{IsJoin}(n)$}
     \State $\hat{o}\gets \textsc{Narrow}(\textit{Out}[n],\hat{o})$ \Comment{at least one round; cap by $k_{\max}$}
  \EndIf
  \If{$\hat{o}\neq \textit{Out}[n]$}
     \State $\textit{Out}[n]\gets \hat{o}$
     \ForAll{$s\in \Succ(n)\cap \mathit{L}$}
        \State $\mathit{WL}.\textsf{push}(s)$
     \EndFor
  \EndIf
\EndWhile
\State \Return $\textit{Out}$ \Comment{in particular $\Env(\textsc{LoopExit}(h))$ is now converged}
\end{algorithmic}
\end{algorithm}

\medskip
\noindent\textbf{Adaptive Widening via Iteration Estimation.}
Traditional fixpoint algorithms apply widening after a fixed number of visits (typically 2) to ensure termination. Algorithm~\ref{alg:fixpoint} improves precision by computing an \emph{adaptive} threshold $\tau$ tailored to each loop's expected iteration count. Line 4 invokes \textsc{EstimateIterations}, which analyzes the loop condition expression to determine $\tau$:

\begin{itemize}
  \item \textbf{Condition structure check:} If the loop condition is a binary comparison with operator $\in \{<, \le, >, \ge, \ne\}$, proceed; otherwise return the conservative default $\tau = 2$.

  \item \textbf{Operand evaluation:} Evaluate both operands (e.g., loop counter $i$ and bound $n$) in the pre-loop environment $\textit{Start}$. If either evaluates to $\bot$ or a non-interval abstract value (e.g., symbolic address, unevaluated state expression), return $\tau = 2$.

  \item \textbf{Iteration count computation:} For interval operands $[\ell_1, u_1]$ and $[\ell_2, u_2]$, compute the maximum iteration count based on the operator. For instance, $i < n$ yields $\tau = u_2 - \ell_1$; $i \le n$ yields $\tau = u_2 - \ell_1 + 1$.

  \item \textbf{Clamping:} Clamp the result to $[2, 20]$ to balance precision and efficiency. Loops with $\tau \le 2$ widen immediately; loops with $\tau \in [3, 20]$ iterate precisely up to $\tau$ visits before widening; loops exceeding 20 are capped to prevent excessive fixpoint rounds.
\end{itemize}

This mechanism is \emph{annotation-aware} without requiring special logic: when debug annotations materialize array lengths, mapping sizes, or function parameters, the evaluator naturally computes tighter intervals for condition operands, raising $\tau$ and deferring widening. Conversely, unannotated state expressions remain $\bot$, forcing the conservative default and triggering early widening (\S{}\ref{sec:eval}, RQ3).

Additionally, line 8 checks \textsc{CondConverged}, an optional early-stopping heuristic that detects when both condition operands stabilize to singleton intervals across successive iterations, signaling natural convergence and allowing the widening phase to terminate before $\tau$ is exhausted.

\medskip
\noindent\textbf{Abstract Interpretation.}
At the end of CFG construction, \textsc{SolQDebug} performs abstract interpretation
to compute sound over-approximations of variable ranges. We employ interval domains
for integer types ($\widehat{\mathbb{Z}}_N, \widehat{\mathbb{U}}_N$), set abstractions
for addresses and booleans, and on-demand materialization for composite types
(arrays, mappings, structs). Standard widening operators ensure termination in loops.
The complete formal semantics---including program syntax, concrete semantics, abstract
domains, and abstract transfer functions---are provided in Appendix~\ref{app:semantics}.

\clearpage

% SECTION 3.5 MOVED TO APPENDIX A
% (Former subsection: Design of the Abstract Interpretation Framework for Solidity)
% CONTENT MOVED TO APPENDIX A

\FloatBarrier
\section{Evaluation}
To evaluate how \textsc{SolQDebug} performs in practical debugging scenarios, we organize our study
around three research questions:

\begin{itemize}
  \item \textbf{RQ1 -- Responsiveness}:\;%
        How much edit--to--inspect latency does \textsc{SolQDebug} eliminate compared to Remix?

  \item \textbf{RQ2 -- Precision Sensitivity to Annotation Structure}:\;%
        In a common Solidity pattern where inputs are normalized by division, how does the structure
        of operand intervals---overlapping vs. distinct---impact interval growth?

  \item \textbf{RQ3 -- Loops}:\;%
        Which loop structures lead to loss of precision, and how do symbolic inputs influence the
        stability of analysis?
\end{itemize}
\subsection{Experimental Setup}
We evaluate \textsc{SolQDebug} on a controlled local setup with the following hardware and software
configuration:

\begin{itemize}
    \item \textbf{CPU}: 11th Gen Intel\textregistered{} Core\texttrademark{} i7-11390H @ 3.40GHz  
    \item \textbf{RAM}: 16.0 GB  
    \item \textbf{Operating System}: Windows 10 (64-bit)  
    \item \textbf{Implementation Language}: Python  
\end{itemize}

The dataset is derived from DAppSCAN~\cite{dappscan}, a large-scale
real-world benchmark for smart contract analysis comprising 3,345
Solidity files compiled with version \texttt{0.8.0} or higher.
From this dataset, we selected 30 representative contracts using
\emph{complexity-driven stratified sampling} to ensure comprehensive
coverage of debugging scenarios encountered in real-world Solidity
development.

Our selection criteria focused on three dimensions that directly
impact debugging complexity: (1) \textbf{computational complexity}---
diverse arithmetic operations including percentage calculations
(e.g., DapiServer, GreenHouse), time-based vesting logic
(e.g., LockupContract, ThorusBond), and conditional capping;
(2) \textbf{data structure complexity}---complex structs with 5+ fields
(10 contracts), nested mappings (e.g., BitBookStake, PercentageFeeModel),
dynamic arrays requiring iteration (7 contracts), and mapping-to-struct
patterns (12 contracts); and (3) \textbf{control flow complexity}---
multiple internal function calls (23 contracts), non-trivial loops
(5 contracts), nested conditionals with early returns
(e.g., PercentageFeeModel with 3-level override hierarchy),
and modifier-based access control (4 contracts).

The 30 contracts span multiple DeFi categories including token
economics (40\%), staking/vesting (30\%), DeFi protocols (20\%),
and utility contracts (10\%), with lines of code ranging from
8 to 59 (average: 23 LOC). This sampling strategy ensures coverage
of key Solidity idioms---structs, mappings, dynamic arrays, control
flow, and arithmetic logic---representing the diverse debugging
challenges developers face in practice.

Since Remix IDE lacks built-in automated benchmarking capabilities, we developed \texttt{
remix\_benchmark}, a Selenium-based automation framework that programmatically drives the Remix web
interface to measure edit-to-inspect latency. For each test function, \texttt{remix\_benchmark}
automates the full workflow: compilation, contract deployment, state variable initialization via
manual storage slot assignment, parameter entry, transaction execution, and step-through debugging.
We measure two latency metrics: \textit{pure debug time}, capturing only the debugger step-through
duration, and \textit{total time}, which includes compilation, deployment, and state setup overhead.
The difference between these metrics reflects the additional manual effort required in traditional
debugging workflows.

Although \textsc{SolQDebug} is designed for interactive use within a Solidity editor, all
experiments simulate this behavior in a controlled scripting environment. For each function, we
reconstruct a sequence of incremental edits and annotations that mimic realistic developer activity.
These fragments are streamed into the interpreter to measure latency and interval growth under
reproducible conditions.


\subsection{RQ1 - Responsiveness}
To evaluate responsiveness, we measure edit-to-inspect latency---defined as the time from a code
change to the appearance of updated variable information---under a single contract, single transaction
scenario.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{3d_benchmark_surface.png}
  \caption{Edit-to-inspect latency comparison between Remix and \textsc{SolQDebug} across varying test-case widths and execution passes. The x-axis represents the cost estimate, y-axis shows TestCase width (\(\Delta\)), and z-axis displays latency in seconds. While Remix maintains constant high latency regardless of iteration, \textsc{SolQDebug} demonstrates significantly lower latency that quickly reaches a floor after the initial pass.}
  \label{fig:rq1-responsiveness}
\end{figure}

We evaluated 30 functions across 4 test-case widths \(\Delta \in \{0, 2, 5, 10\}\), yielding 120
total measurements for \textsc{SolQDebug}. For Remix, we measured each function once using \texttt{
remix\_benchmark}, capturing both pure debug time (debugger step-through only) and total time (
including compilation, deployment, and state initialization).

For Remix, the pure debug time ranged from 25.1 to 124.6 seconds (median: 53.0 s), reflecting the
time required to step through bytecode operations in the debugger. The total time, however, ranged
from 71.1 to 168.3 seconds (median: 98.1 s), as it includes approximately 35 seconds for
compilation and deployment, plus 0--11.8 seconds for manual state variable initialization (median:
2.9 s). Functions requiring more state slots incur proportionally higher setup overhead, with state
initialization time growing linearly with the number of storage variables.

In contrast, \textsc{SolQDebug} completed analysis in 0.03--5.09 seconds (median: 0.15 s) across all
120 measurements, requiring no compilation, deployment, or state setup. Fig.~\ref{fig:rq1-responsiveness} visualizes this performance gap: Remix pure debug time alone exceeds \textsc{
SolQDebug}'s total latency by a median factor of \textasciitilde350$\times$, while total Remix
latency (including setup) exceeds it by \textasciitilde650$\times$. This demonstrates that \textsc{
SolQDebug} eliminates the compile--deploy--setup cycle entirely, enabling immediate feedback during
code editing.

\medskip
\noindent\fbox{%
\begin{minipage}{0.96\linewidth}
\textbf{Answer to RQ1:}
\textsc{SolQDebug} achieves sub-second edit-to-inspect latency (median: 0.15 s), eliminating 350$\times$--650$\times$ overhead from Remix's compile--deploy--debug cycle. This enables immediate, interactive feedback during code editing without transaction execution.
\end{minipage}%
}

\subsection{RQ2 - Precision Sensitivity to Annotation Structure}

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.35\linewidth]{fig_pending_f90.pdf}
  \hspace{2em}
  \includegraphics[width=0.35\linewidth]{fig_pending_convert_f90.pdf}
  \caption{
Interval growth after normalization in \texttt{pending} function from \texttt{Lock.sol}. Left:
original version with subtraction; right: modified version where subtraction is replaced with
addition}
  \label{fig:rq2-precision}
\end{figure*}

Smart contracts often normalize raw inputs via division---e.g., converting timestamps to time
units---before combining the results using addition or subtraction. To isolate the impact of the final
arithmetic operator from the shared division step, we analyze two variants of the same control-flow
structure: one using addition, the other using subtraction.

Each variant is tested under two annotation styles. In the \textsc{diff} style, each operand is
assigned a distinct input interval (e.g., \([10, 20]\) and \([30, 40]\)). In the \textsc{overlap}
style, the intervals are partially aligned (e.g., \([10, 20]\) and \([15, 25]\)), such that they
share a subrange but are not fully identical.
For each combination, we sweep the annotation width \(\Delta \in \{1, 3, 6, 10\}\) and report
\(F_{90}\), the 90th percentile of the inflation factor \(F = \textit{exit\_width} /
\textit{input\_width}\).

Results in Fig.7 show that interval growth is more sensitive to the structure of input ranges than
to the arithmetic operator. \textsc{Diff} inputs consistently trigger early widening as \(\Delta\)
increases, while \textsc{overlap} inputs maintain tighter bounds even under addition, which
typically increases output range.

This suggests that in division-normalized logic, the alignment of operand intervals---whether disjoint
or overlapping---has a stronger influence on interval growth than the choice between addition and
subtraction. Overlapping inputs consistently result in smaller output ranges, reducing the degree of
over-approximation as input width increases.

\medskip
\noindent\fbox{%
\begin{minipage}{0.96\linewidth}
\textbf{Answer to RQ2:}
In division-normalized arithmetic patterns, the structure of input interval annotations (overlapping vs.\ disjoint) has a stronger influence on precision than the choice of arithmetic operator (addition vs.\ subtraction). Overlapping intervals consistently reduce over-approximation by up to 3$\times$ compared to disjoint inputs, suggesting developers should align annotation ranges with expected input correlations to improve precision without sacrificing responsiveness.
\end{minipage}%
}

\subsection{RQ3 - Loops}

Loop precision in \textsc{SolQDebug} depends critically on the evaluability of the loop condition expression. Recall from Algorithm~\ref{alg:fixpoint} (line 4) that \textsc{EstimateIterations} analyzes the condition by evaluating both operands in the pre-loop environment $\textit{Start}$ to compute a widening threshold $\tau$. We identify three distinct patterns in our benchmark contracts, each exhibiting different precision characteristics:

\medskip
\noindent\textbf{Pattern 1: Constant-Bounded Loops.}
When loop conditions reference only constants or simple arithmetic, \textsc{EstimateIterations} computes precise thresholds without requiring annotations. For instance, \texttt{updateUserInfo} in \textsc{AOC\_BEP} contains \texttt{for (uint256 i = 1; i <= 4; i++)}, where the condition \texttt{i <= 4} evaluates to $\tau = 4$. Because the actual loop iterates at most 4 times (including early \texttt{break}), widening never triggers, and the interval for \texttt{userInfo[account].level} converges precisely to $[1,4]$. Similarly, \texttt{\_addActionBuilderAt} in \textsc{Balancer} uses \texttt{for (uint8 i = 0; i < additionalCount; i++)}, where \texttt{additionalCount} is a locally computed value. When annotations specify the function inputs (e.g., \texttt{index = 5}, \texttt{currentLength = 2}), the evaluator computes \texttt{additionalCount = 4}, yielding $\tau = 4$ and preventing premature widening.

\medskip
\noindent\textbf{Pattern 2: State-Dependent Bounds Enabled by Annotations.}
Solidity loops frequently reference dynamic array lengths or mapping sizes in their conditions. Without symbolic input, these expressions evaluate to $\bot$ or remain symbolic, forcing \textsc{EstimateIterations} to return the conservative default $\tau = 2$. For example, \texttt{getTotalDeposit} in \textsc{TimeLockPool} iterates \texttt{for (uint256 i = 0; i < depositsOf[\_account].length; i++)}. The condition operand \texttt{depositsOf[\_account].length} cannot be statically evaluated, triggering widening after just 2 iterations and causing the accumulator \texttt{total} to widen to $[0, 2^{256}-1]$.

Debug annotations directly address this: by specifying \texttt{// @audit depositsOf[\_account].length = 10}, the analyzer materializes the array with length 10, allowing \textsc{EstimateIterations} to compute $\tau = 10$. Widening is then deferred until the 10th iteration, enabling precise convergence when the actual loop count matches or falls below the annotated bound. The same mechanism applies to \texttt{\_removeFromTokens} in \textsc{AvatarArtMarketplace}, where annotating \texttt{\_tokens.length} allows the threshold to scale proportionally with the input size.

\medskip
\noindent\textbf{Pattern 3: Data-Dependent Divergence Despite Annotations.}
Even when annotations provide accurate iteration counts, precision may degrade if the loop body contains data-dependent branches or updates decoupled from the loop index. \texttt{revokeStableMaster} in \textsc{Core} illustrates this: the loop \texttt{for (uint256 i = 0; i < stablecoinListLength - 1; i++)} searches for a specific address in \texttt{\_stablecoinList} and breaks early upon finding it. Although annotating \texttt{\_stablecoinList.length} raises $\tau$ appropriately, the variable \texttt{indexMet} depends on whether the target address exists in the array---a condition orthogonal to the loop index \texttt{i}. If the array is populated via annotations but the target is absent, the loop executes the full iteration count, and \texttt{indexMet} may widen or remain imprecise due to path merging at the conditional assignment. Conversely, if annotations leave the array empty, the loop terminates immediately with precise state but misses the intended exploration.

This pattern reveals a fundamental tension: annotations that populate data structures enable deeper exploration (activating dormant branches, triggering realistic state transitions), but they also introduce variability that the interval domain cannot track precisely. Such loops require either (i) narrower annotations that materialize only the specific keys or indices the developer intends to inspect, or (ii) acceptance that widening will approximate the full range of behaviors.

\medskip
\noindent\fbox{%
\begin{minipage}{0.96\linewidth}
\textbf{Answer to RQ3:}
Loop precision in \textsc{SolQDebug} is governed by the adaptive widening threshold $\tau$, which is computed by evaluating the loop condition in the pre-loop symbolic environment. Constant-bounded loops converge precisely without annotations. State-dependent loops (e.g., iterating over \texttt{array.length}) benefit directly from debug annotations: specifying array sizes or mapping extents allows \textsc{EstimateIterations} to compute accurate thresholds, deferring widening and improving precision proportionally. However, data-dependent loops---where control flow or updates depend on array contents rather than indices---may still diverge under widening despite accurate iteration counts, as the interval domain cannot track element-specific correlations. Developers should annotate iteration bounds for state-dependent loops and use narrower, targeted annotations for data-dependent cases.
\end{minipage}%
}

\FloatBarrier
\section{Discussion}

\subsection{Why use Abstract Interpretation for Debugging}
    In this work, we use debugging to mean a developer-led, interactive exploration activity that
    happens before deployment during code authoring: the developer varies symbolic (interval) inputs
    and immediately observes branch reachability, guard validity, and value bounds at the source
    level. This edit-time feedback loop calls for a technique that (1) terminates quickly, (2)
    explains results in a way developers can inspect, and (3) scales to near-keystroke
    responsiveness.

    We chose abstract interpretation (AI) over symbolic execution and proof-based verification for
    three reasons:
    \begin{itemize}
      \item \textbf{Termination.} AI enforces convergence via widening at loops and joins at merges, avoiding the path explosion common in symbolic execution.
      \item \textbf{Explainability.} Each result is an abstract value in a well-defined lattice. With interval domains, the mapping from inputs to outputs is explicit as ranges, which makes dataflow effects easy to trace and debug at the line level.
      \item \textbf{Responsiveness.} Interval transfer functions are lightweight, enabling millisecond-scale updates that fit the edit cycle. Symbolic engines routinely explore many paths even for small edits, which can break interactivity.
    \end{itemize}
    Formal verification provides stronger guarantees, but requires fully specified properties and
    invariants, which are costly to author during early iterations. \textsc{SolQDebug} is designed
    to bridge the gap between writing code and running tests or verification---offering immediate,
    sound, conservative feedback with low annotation overhead.

    For debugging, intervals strike a practical balance between precision and speed. They (i) align
    with developers' mental model of "possible ranges," (ii) expose boundary effects (e.g., overflow
    thresholds, guard satisfaction regions) without committing to a single concrete input, and (iii)
    compose predictably through joins and widenings. In our setting, intervals are also a natural
    surface for annotations: developers can \emph{shape} symbolic inputs (e.g., make them
    overlapping or disjoint) and directly see how that affects control flow and computed ranges.

    AI's precision is conservative by design; edit-time usability depends on giving developers
    simple levers to steer precision without sacrificing responsiveness. We expose three such levers
    that proved effective in our study:
    \begin{itemize}
      \item \textbf{Annotation structure.} Overlapping operand intervals often bound output ranges more tightly than disjoint ones in division-normalized arithmetic (cf.\ RQ2). This reduces false alarms with no runtime cost.
      \item \textbf{Annotation width.} Narrower inputs shrink joins and delay widening; developers can start narrow and broaden gradually ("zoom out") to probe stability.
      \item \textbf{Guard-guided narrowing.} Making explicit the intended \texttt{require}/\texttt{if} guards in annotations tightens feasible states early and improves precision along the taken branch at negligible cost.
    \end{itemize}
    Where stricter precision is essential (e.g., inside data-driven loops), the workflow can
    temporarily fall back to concrete inputs for local inspection, then return to intervals for
    broader exploration. This "concrete when needed, symbolic by default" rhythm preserves
    interactivity while keeping results actionable.
    \vspace{0.25em}

    \subsection{Evaluation Implication}
    Traditional debuggers (e.g., Remix, Hardhat Debug) require compile--deploy--execute per iteration,
    typically taking tens of seconds. In contrast, our interpreter updates in milliseconds (median
    \(\sim\)14\,ms on the first pass and 5--35\,ms on the second), yielding \emph{orders-of-magnitude}
    lower edit-to-inspect latency. This difference is qualitative: it enables near-keystroke
    feedback, which changes how developers explore code. Because results are symbolic, a single pass
    summarizes many concrete executions; developers can see when guards always hold/fail for an
    interval, when a branch becomes unreachable, or when a value may cross a critical threshold---all
    without leaving the editor. In short, \textsc{SolQDebug} complements runtime debuggers by moving
    fast, informative checks \emph{into} the authoring loop (RQ1).

    RQ2 shows that, in division-normalized patterns common in Solidity, \emph{how} intervals are
    shaped can matter more than \emph{which} arithmetic operator is used. Overlapping inputs
    systematically produced smaller output ranges than disjoint inputs, delaying or avoiding early
    widening. When investigating arithmetic joins, start with partially overlapping intervals and
    widen only as needed; keep operands aligned where normalization is present.

    RQ3 demonstrates that loop precision is governed by the adaptive widening threshold $\tau$, which
    depends on whether the loop condition expression can be evaluated in the pre-loop symbolic
    environment. Constant-bounded loops (\texttt{for (i = 1; i <= 4; ...)}) converge precisely
    without annotations because \textsc{EstimateIterations} computes exact thresholds.
    State-dependent loops (\texttt{for (i = 0; i < arr.length; ...)}) benefit directly from
    annotations: specifying \texttt{arr.length = 10} allows the analyzer to set $\tau = 10$,
    deferring widening and enabling natural convergence. However, data-dependent loops---where the loop
    body contains branches or updates decoupled from the index---may still widen despite accurate
    iteration counts, as the interval domain cannot track element-specific correlations.

    Practical implications: (i) always annotate array lengths, mapping sizes, and iteration bounds
    for state-dependent loops to raise $\tau$ and delay widening; (ii) for data-dependent loops,
    use narrower annotations that materialize only the specific keys or elements under inspection,
    reducing the variability introduced by path merging; (iii) when widening becomes unavoidable
    (e.g., search loops over large collections), accept the over-approximation or switch to concrete
    inputs for targeted verification.

    Overall, these findings suggest a debugging workflow that starts symbolic and broad, then
    \emph{shapes} annotations to tighten precision where it matters (overlap, narrow, guard-guided),
    and finally uses concrete spot checks only for stubborn hot spots (e.g., deeply data-dependent
    loops).

    \subsection{Limitation}
    Our current scope and measurements introduce several limitations. First, we focus on
    single-contract, single-transaction functions. Inter-contract calls, multi-transaction workflows,
    proxies, and inheritance hierarchies are out of scope in the present implementation. As a result,
    we have not yet conducted a developer study in larger project settings; the usability and
    interpretability of edit-time feedback across multi-contract workflows remain unvalidated.

    Second, our latency numbers combine interpreter execution time (timed in Python) with an estimate
    for annotation effort per variable (manual input). This procedure ignores UI-event latency and
    cursor dynamics, and it assumes a consistent operator for annotation entry. Likewise, our
    precision metric (\(F_{90}\): 90th percentile of exit-/input-width inflation) captures a salient
    aspect of interval growth but does not reflect all developer notions of "useful precision."
    These choices provide a consistent basis for tool-level comparison but may under- or
    over-estimate end-to-end IDE latency or perceived precision.

    We plan to (i) extend the analysis to inter-contract calls and multi-transaction scenarios, (ii)
    instrument editor events to directly measure human-in-the-loop latency and refine the annotation
    cost model, and (iii) run a controlled developer study once multi-contract support stabilizes.
    On the analysis side, loop summarization and selective use of lightweight relational domains (e.
    g., applied on demand to hot spots) are promising avenues to improve precision while preserving
    interactivity.

\FloatBarrier
\section{Related Works}

    \subsection{Solidity IDEs and Debuggers}
        Modern Solidity development environments either embed a debugger or integrate external
        debugging plug-ins. \citet{remix} is the most widely used web IDE; it supports syntax
        highlighting, one-click compilation, and a bytecode-level debugger that lets users step
        through EVM instructions and inspect stack, memory, and storage. \citet{hardhat} is a Node.
        js--based framework that couples the Solidity compiler with an Ethereum runtime; its Hardhat
        Debug plug-in attaches a Remix-style debugger to locally broadcast transactions inside
        Visual Studio Code. \citet{forge} is a command-line toolchain oriented toward fast,
        reproducible unit testing; the command \texttt{forge test} spins up an ephemeral fork,
        deploys contracts, executes annotated test functions, and enables replay through Forge Debug.
        \citet{soldepro} is a Visual Studio Code extension that performs runtime debugging over
        concrete transactions and integrates with Hardhat; in practice, many workflows create a
        small auxiliary contract that calls the target functions so that state changes can be
        observed step by step.

        In short, these debuggers operate on compiled artifacts or post-deployment traces and rely
        on transaction replay and EVM-level stepping. They do not accept partial, in-flight source
        fragments nor provide symbolic (interval) input modeling or millisecond edit-time feedback.
        By contrast, \textsc{SolQDebug} targets pre-deployment authoring, accepts partial fragments
        and symbolic annotations, and reports line-level effects via abstract interpretation during
        editing.

    \subsection{Solidity Vulnerability Detection and Verification}
        A rich body of work analyzes smart contracts for security issues using four main families of
        techniques.
        Static analysis tools reason over source or bytecode without running the contract. 
        Representative systems include rule- or pattern--based analyzers such as Securify and Slither
        \citep{securify,slither}, symbolic-execution--assisted detectors like Mythril \citep{mythril},
        knowledge-graph--based reasoning such as Solidet \citep{solidet}, and bytecode CFG refinement
        as in Ethersolve \citep{ethersolve}.
        Dynamic testing and fuzzing exercise deployed or locally simulated contracts to uncover
        faults and security issues:
        ContractFuzzer mutates ABI-level inputs \citep{confuzz}, Echidna brings property-based
        fuzzing into developer workflows \citep{echidna}, sFuzz adapts scheduling for higher
        coverage \citep{sfuzz}, TransRacer finds transaction-ordering races \citep{transracer}, and
        Ityfuzz leverages snapshotting to decouple executions from chain nondeterminism
        \citep{ityfuzz}.
        Formal verification aims to prove safety properties or refute counterexamples at compile
        time; examples include ZEUS, VeriSmart, and SmartPulse \citep{zeus,verismart,pulse}.
        Finally, AI-based approaches train models to predict vulnerabilities or triage candidates, e.
        g., via data-flow--aware pretraining, IoT-oriented classifiers, or prompt-tuning for detector
        adaptation \citep{peculiar,tmlvd,pscvfinder}.

        These approaches have substantially advanced vulnerability detection and property checking
        for fully written contracts. However, they are not designed to provide interactive,
        edit-time feedback to developers while code is still under construction. They typically
        analyze post-compilation artifacts or deployed bytecode and expect complete program units.
        \textsc{SolQDebug} complements this line of work by focusing on pre-deployment authoring: it
        accepts partial fragments and symbolic (interval) inputs and produces line-by-line feedback
        inside the editor.
    
    \subsection{Solidity-Specific Abstract Interpretation Frameworks}
        Abstract interpretation is a well-established framework for static analysis and has been
        adapted to many programming languages. Two recent studies apply it to Solidity~\citep{flow,
        DBM}. The first uses the Pos domain to construct a theoretical model for taint
        (information-flow) analysis~\citet{flow}, while the second employs the Difference-Bound
        Matrix (DBM) domain to generate state invariants and detect re-entrancy vulnerabilities,
        including the DAO attack~\citep{DBM, dao}. However, both approaches operate on fully written
        contracts and provide no support for line-by-line interpretation or developer interaction
        within an IDE.

        \textsc{SolQDebug} adapts abstract interpretation for an interactive setting. It
        incrementally updates both the control-flow graph and the abstract state in response to each
        edit. Developer-supplied annotations serve as a first-class input mechanism, reflecting how
        debugging often involves varying symbolic inputs. These annotations are internally
        represented as linear-inequality constraints, and form an integral part of interactive
        debugging by enabling symbolic reasoning over developer-specified inputs. This design
        improves interpretability and control within the interval domain by leveraging symbolic
        constraints, while maintaining keystroke-level responsiveness. As a result,
        \textsc{SolQDebug} updates variable ranges directly in the Solidity editor, allowing
        developers to observe how values evolve in response to each edit.
    
    \subsection{Interactive Abstract Interpretation for Traditional Languages}
        In recent years, traditional languages have seen a surge of interest in making abstract
        interpretation interactive, integrating it directly into IDEs to provide live analysis
        feedback during editing \citep{daig, ds, iac, iaj, fap}.
        \citet{daig} proposed demanded abstract interpretation, which incrementally rebuilds only
        the analysis nodes touched by an edit.
        A follow-up \citet{ds} generalized this to procedure summaries, enabling inter-procedural
        reuse.
        \citet{iac} extended Goblint with incremental support for multithreaded C, selectively
        recomputing only genuinely affected facts and maintaining IDE-level responsiveness.
        \citet{iaj} introduced IntraJ, an LSP-integrated analyzer for Java 11 that computes only the
        AST and data-flow facts needed for the current view, keeping feedback under 100 ms.
        \citet{fap} achieved fast yet precise interval analysis on call graphs via one top-down and
        multiple bottom-up passes, and later introduced an incremental variant that revisits only
        the impacted functions.

        Unlike these frameworks for C or Java, \textsc{SolQDebug} is designed specifically for
        Solidity. It supports in-flight code fragments and range annotations as first-class input.
        It incrementally updates only the current basic block in the CFG while reusing previously
        computed abstract states. Finally, it combines these with an interval domain guided by
        developer-supplied annotations, which act as input to represent the exploratory nature of
        debugging. This architecture enables keystroke-level feedback without requiring
        recompilation, redeployment, or transaction execution. It bridges the gap between Solidity
        development and the interactive tooling common in traditional programming environments.

\FloatBarrier
\section{Conclusion}
    We introduced SolQDebug, a source-level interactive debugger for Solidity that provides
    millisecond feedback without requiring compilation, deployment, or transaction replay. By
    combining interactive parsing, dynamic control-flow graph updates, and interval domain based
    abstract interpretation seeded by annotations, SolQDebug enables responsive, line-by-line
    inspection directly within the Solidity editor. Our evaluation shows that it reduces debugging
    latency compared to Remix, while enabling actionable feedback in response to symbolic inputs.
    These results demonstrate that SolQDebug's design effectively bridges the interactivity gap in
    Solidity debugging and brings the development experience closer to that of modern debugging
    workflows.
    
    Future work includes extending SolQDebug to inter-contract and multi-transaction contexts,
    incorporating loop summarization for higher precision, and conducting user studies to assess its
    practical adoption and usability. We also plan to apply analysis based on the EVM Object Format
    (EOF) to support inter-contract debugging when source code is unavailable, as Ethereum moves
    toward structured bytecode formats in upcoming hard forks.

\begin{thebibliography}{99}

\bibitem[Chimdyalwar(2024)]{fap}
Chimdyalwar, B.: Fast and precise interval analysis on industry code. In: 2024 IEEE 35th
International Symposium on Software Reliability Engineering Workshops (ISSREW) (2024)

\bibitem[ConsenSys Diligence(2025)]{psp}
ConsenSys Diligence: Python Solidity Parser. \url{https://github.
com/ConsenSysDiligence/python-solidity-parser} (2025). Accessed November 2025

\bibitem[Cousot and Cousot(1977)]{cousot}
Cousot, P., Cousot, R.: Abstract interpretation: a unified lattice model for static analysis of
programs by construction or approximation of fixpoints. In: Proceedings of the 4th ACM
SIGACT-SIGPLAN Symposium on Principles of Programming Languages (POPL) (1977)

\bibitem[Erhard et~al.(2024)]{iac}
Erhard, J., et al.: Interactive abstract interpretation: reanalyzing multithreaded C programs for
cheap. International Journal on Software Tools for Technology Transfer (2024)

\bibitem[Foundry Forge(2025)]{forge}
Foundry Forge: \url{https://book.getfoundry.sh/reference/forge/forge/} (2025). Accessed November
2025

\bibitem[Grieco et~al.(2020)]{echidna}
Grieco, G., et al.: Echidna: effective, usable, and fast fuzzing for smart contracts. In:
Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA),
pp. 557--560 (2020)

\bibitem[Halder et~al.(2023)]{flow}
Halder, R., et al.: Analyzing information flow in Solidity smart contracts. In: Distributed
Computing to Blockchain, pp. 105--123. Academic Press (2023)

\bibitem[Halder(2024)]{DBM}
Halder, R.: State-based invariant property generation of Solidity smart contracts using abstract
interpretation. In: 2024 IEEE International Conference on Blockchain (2024)

\bibitem[Hardhat(2025)]{hardhat}
Hardhat: \url{https://hardhat.org/} (2025). Accessed November 2025

\bibitem[Hu et~al.(2023)]{solidet}
Hu, T., et al.: Detect defects of Solidity smart contract based on the knowledge graph. IEEE
Transactions on Reliability 73(1), 186--202 (2023)

\bibitem[JetBrains(2025)]{pycharm}
JetBrains: PyCharm. \url{https://www.jetbrains.com/pycharm/} (2025). Accessed November 2025

\bibitem[Jiang et~al.(2018)]{confuzz}
Jiang, B., Liu, Y., Chan, W.K.: ContractFuzzer: fuzzing smart contracts for vulnerability detection.
In: Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE)
, pp. 259--269 (2018)

\bibitem[Kalra et~al.(2018)]{zeus}
Kalra, S., Goel, S., Dhawan, M., Sharma, S.: ZEUS: analyzing safety of smart contracts. In:
Proceedings of the 2018 Network and Distributed System Security Symposium (NDSS) (2018)

\bibitem[Llama(2025)]{llama}
Llama: \url{https://www.llama.com/} (2025). Accessed November 2025

\bibitem[Ma et~al.(2023)]{transracer}
Ma, C., Song, W., Huang, J.: TransRacer: function dependence-guided transaction race detection for
smart contracts. In: Proceedings of the 31st ACM Joint European Software Engineering Conference and
Symposium on the Foundations of Software Engineering (ESEC/FSE), pp. 947--959 (2023)

\bibitem[Mehar et~al.(2019)]{dao}
Mehar, M.I., et al.: Understanding a revolutionary and flawed grand experiment in blockchain: the
DAO attack. Journal of Cases on Information Technology (2019)

\bibitem[Microsoft(2025)]{visual}
Microsoft Visual Studio: \url{https://visualstudio.microsoft.com/ko/} (2025). Accessed November
2025

\bibitem[Nguyen et~al.(2020)]{sfuzz}
Nguyen, T.D., et al.: sFuzz: an efficient adaptive fuzzer for Solidity smart contracts. In:
Proceedings of the 42nd ACM/IEEE International Conference on Software Engineering (ICSE), pp.
778--788 (2020)

\bibitem[Pasqua et~al.(2023)]{ethersolve}
Pasqua, M., et al.: Enhancing Ethereum smart-contracts static analysis by computing a precise
control-flow graph of Ethereum bytecode. Journal of Systems and Software 200, 111653 (2023)

\bibitem[Remix IDE(2025)]{remix}
Remix IDE: \url{https://remix.ethereum.org/} (2025). Accessed November 2025

\bibitem[Riouak et~al.(2024)]{iaj}
Riouak, I., et al.: IntraJ: an on-demand framework for intraprocedural Java code analysis.
International Journal on Software Tools for Technology Transfer (2024)

\bibitem[Rival and Yi(2020)]{yi}
Rival, X., Yi, K.: Introduction to Static Analysis: an Abstract Interpretation Perspective (2020)

\bibitem[Shou et~al.(2023)]{ityfuzz}
Shou, C., Tan, S., Sen, K.: Ityfuzz: snapshot-based fuzzer for smart contract. In: Proceedings of
the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA), pp. 322--333
(2023)

\bibitem[So et~al.(2020)]{verismart}
So, S., et al.: Verismart: a highly precise safety verifier for Ethereum smart contracts. In: 2020
IEEE Symposium on Security and Privacy (SP), pp. 1678--1694 (2020)

\bibitem[solcx(2025)]{solcx}
Solidity Compiler in Python (solcx): \url{https://solcx.readthedocs.io/en/latest/} (2025). Accessed
November 2025

\bibitem[Solidity(2025)]{solidity}
Solidity documentation: \url{https://docs.soliditylang.org/en/v0.8.30/} (2025). Accessed November
2025

\bibitem[Solidity Debugger Pro(2025)]{soldepro}
Solidity Debugger Pro: \url{https://www.soliditydbg.org/} (2025). Accessed November 2025

\bibitem[Solidity Language Grammar]{solgram}
Solidity Language Grammar: \url{https://docs.soliditylang.org/en/v0.8.30/grammar.html} (2025). Accessed November 2025

\bibitem[SolQDebug Language Grammar Rule]{solqrule} 
Solidity Language Grammar Rule of SolQDebug : \url{https://github.
com/iwwyou/SolDebug/blob/main/Parser/Solidity.g4} . Accessed November 2025

\bibitem[Stein et~al.(2021)]{daig}
Stein, B., Chang, B.-Y.E., Sridharan, M.: Demanded abstract interpretation. In: Proceedings of the
42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI)
(2021)

\bibitem[Stein et~al.(2024)]{ds}
Stein, B., Chang, B.-Y.E., Sridharan, M.: Interactive abstract interpretation with demanded
summarization. ACM Transactions on Programming Languages and Systems (2024)

\bibitem[Stephens et~al.(2021)]{pulse}
Stephens, J., et al.: SmartPulse: automated checking of temporal properties in smart contracts. In:
2021 IEEE Symposium on Security and Privacy (SP), pp. 555--571 (2021)

\bibitem[Tsankov et~al.(2018)]{securify}
Tsankov, P., et al.: Securify: practical security analysis of smart contracts. In: Proceedings of
the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 67--82 (2018)

\bibitem[Tsankov et~al.(2019)]{slither}
Tsankov, P., et al.: Slither: a static analysis framework for smart contracts. In: 2019 IEEE/ACM 2nd
International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB), pp. 8--15
(2019)

\bibitem[Wu et~al.(2021)]{peculiar}
Wu, H., et al.: Peculiar: smart contract vulnerability detection based on crucial data-flow graph
and pre-training techniques. In: 2021 IEEE 32nd International Symposium on Software Reliability
Engineering (ISSRE), pp. 378--389 (2021)

\bibitem[Yao et~al.(2022)]{mythril}
Yao, Y., et al.: An improved vulnerability detection system of smart contracts based on symbolic
execution. In: 2022 IEEE International Conference on Big Data (Big Data), pp. 3225--3234 (2022)

\bibitem[Yu et~al.(2023)]{pscvfinder}
Yu, L., et al.: PSCVFinder: a prompt-tuning based framework for smart contract vulnerability
detection. In: 2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE),
pp. 556--567 (2023)

\bibitem[Zheng et~al.(2024)]{dappscan}
Zheng, Z., et al.: Dappscan: building large-scale datasets for smart contract weaknesses in dApp
projects. IEEE Transactions on Software Engineering (2024)

\bibitem[Zhou et~al.(2022)]{tmlvd}
Zhou, Q., et al.: Vulnerability analysis of smart contract for blockchain-based IoT applications: a
machine learning approach. IEEE Internet of Things Journal 9(24), 24695--24707 (2022)

\bibitem[Zou et~al.(2019)]{interview}
Zou, W., et al.: Smart contract development: challenges and opportunities. IEEE Transactions on
Software Engineering (2019)

\end{thebibliography}

\FloatBarrier
\newpage
\appendix

\section{Interactive Parser Grammar Specification}
\label{appendix:interactive-grammar}

This appendix provides the complete grammar specification for \textsc{SolQDebug}'s interactive parser.

\subsection{Entry Rules for Solidity Program Fragments}

\subsubsection{Rule 1: \texttt{interactiveSourceUnit}}
\noindent\textbf{Purpose.} Accepts top-level declarations: functions, contracts, interfaces, libraries, state variables, pragmas, and imports.

\noindent\textbf{Grammar:}
\begin{verbatim}
interactiveSourceUnit
  : (interactiveStateVariableElement | interactiveFunctionElement
    | interfaceDefinition | libraryDefinition | contractDefinition
    | pragmaDirective | importDirective)* EOF ;
\end{verbatim}

\subsubsection{Rule 2: \texttt{interactiveEnumUnit}}
\noindent\textbf{Purpose.} Accepts enum member items added after the enum shell.

\noindent\textbf{Grammar:}
\begin{verbatim}
interactiveEnumUnit : (interactiveEnumItems)* EOF;
interactiveEnumItems : identifier (',' identifier)*;
\end{verbatim}

\subsubsection{Rule 3: \texttt{interactiveStructUnit}}
\noindent\textbf{Purpose.} Accepts struct member declarations added after the struct shell.

\noindent\textbf{Grammar:}
\begin{verbatim}
interactiveStructUnit : (structMember)* EOF;
structMember : typeName identifier ';' ;
\end{verbatim}

\subsubsection{Rule 4: \texttt{interactiveBlockUnit}}
\noindent\textbf{Purpose.} Accepts statements and control-flow skeletons inside function bodies.

\noindent\textbf{Grammar:}
\begin{verbatim}
interactiveBlockUnit
  : (interactiveBlockItem)* EOF;

interactiveBlockItem
  : interactiveStatement | uncheckedBlock;

interactiveStatement
  : interactiveSimpleStatement
  | interactiveIfStatement
  | interactiveForStatement
  | interactiveWhileStatement
  | interactiveDoWhileDoStatement
  | interactiveTryStatement
  | returnStatement
  | emitStatement
  | revertStatement
  | requireStatement
  | assertStatement
  | continueStatement
  | breakStatement
  | assemblyStatement;

interactiveIfStatement
  : 'if' '(' expression ')' '{' '}' ;

interactiveForStatement
  : 'for' '(' (simpleStatement | ';') expression? ';' expression? ')' '{' '}' ;

interactiveWhileStatement
  : 'while' '(' expression ')' '{' '}' ;

interactiveDoWhileDoStatement
  : 'do' '{' '}' ;

interactiveTryStatement
  : 'try' expression ('returns' '(' parameterList ')')? '{' '}' ;
\end{verbatim}

\noindent The \texttt{interactiveStatement} production includes skeleton rules for
control structures with empty bodies (e.g., \texttt{interactiveIfStatement}, \texttt{interactiveForStatement}),
enabling incremental construction of control flow. As developers type statements inside these
empty bodies, \texttt{interactiveBlockUnit} is recursively invoked to parse each new line.

\subsubsection{Rule 5: \texttt{interactiveDoWhileUnit}}
\noindent\textbf{Purpose.} Accepts the \texttt{while} tail of a \texttt{do\{...\}} loop.

\noindent\textbf{Grammar:}
\begin{verbatim}
interactiveDoWhileUnit : (interactiveDoWhileWhileStatement)* EOF;
interactiveDoWhileWhileStatement : 'while' '(' expression ')' ';' ;
\end{verbatim}

\subsubsection{Rule 6: \texttt{interactiveIfElseUnit}}
\noindent\textbf{Purpose.} Accepts \texttt{else} or \texttt{else if} branches.

\noindent\textbf{Grammar:}
\begin{verbatim}
interactiveIfElseUnit : (interactiveElseStatement)* EOF;
interactiveElseStatement : 'else' (interactiveIfStatement | '{' '}') ;
\end{verbatim}

\subsubsection{Rule 7: \texttt{interactiveCatchClauseUnit}}
\noindent\textbf{Purpose.} Accepts \texttt{catch} clauses following a \texttt{try}.

\noindent\textbf{Grammar:}
\begin{verbatim}
interactiveCatchClauseUnit : (interactiveCatchClause)* EOF;
interactiveCatchClause : 'catch' (identifier? '(' parameterList ')')? '{' '}' ;
\end{verbatim}

\subsection{Entry Rule for Debugging Annotations}

\subsubsection{\texttt{debugUnit}}
\noindent\textbf{Purpose.} Parses batch-annotation lines that specify initial abstract values for variables.

\noindent\textbf{Annotation types:}
\begin{itemize}
  \item \texttt{@GlobalVar}: Assigns values to global variables (e.g., \texttt{msg.sender}, \texttt{block.timestamp})
  \item \texttt{@StateVar}: Assigns values to contract state variables
  \item \texttt{@LocalVar}: Assigns values to function parameters and local variables
\end{itemize}

\noindent\textbf{Grammar:}
\begin{verbatim}
debugUnit : (debugGlobalVar | debugStateVar | debugLocalVar)* EOF;
debugGlobalVar : '//' '@GlobalVar' identifier ('.' identifier)? '=' globalValue ';' ;
debugStateVar : '//' '@StateVar' lvalue '=' value ';' ;
debugLocalVar : '//' '@LocalVar' lvalue '=' value ';' ;
\end{verbatim}

\noindent\textbf{Supported L-value patterns:} Simple variables, array/mapping access (\texttt{arr[i]}, \texttt{map[key]}), struct fields (\texttt{s.field}), and nested combinations.

\noindent\textbf{Value specification:} Integer intervals \texttt{[l,u]}, symbolic addresses \texttt{symbolicAddress n}, boolean values, and symbolic placeholders.

\section{Abstract Domain and Formal Semantics}
\label{app:semantics}

This appendix presents the abstract domain definitions and formal semantics used by \textsc{SolQDebug}'s abstract interpreter. The framework is based on interval analysis for numeric types, set domains for addresses, and lazy materialization for composite data structures.

\subsection{Abstract Domain}

\noindent\textbf{Atomic abstract values:}
\begin{itemize}[leftmargin=1.25em]
\item \textbf{Unsigned integers:} $\widehat{\mathbb{U}}_N = \{[\ell,u] \mid 0 \le \ell \le u \le 2^N{-}1\} \cup \{\bot,\top_N\}$
\item \textbf{Signed integers:} $\widehat{\mathbb{Z}}_N = \{[\ell,u] \mid -2^{N-1} \le \ell \le u \le 2^{N-1}{-}1\} \cup \{\bot,\top_N^{\pm}\}$
\item \textbf{Booleans:} $\widehat{\mathbb{B}} = \{\bot,\widehat{\mathsf{false}},\widehat{\mathsf{true}},\top\}$
\item \textbf{Addresses:} $\widehat{\mathbb{A}} = \wp_{\le K}(\mathsf{AddrID}) \cup \{\top\}$ (set domain with cap $K=8$)
\item \textbf{Bytes:} $\widehat{\mathbb{BY}}_K = \{\bot,\top_K\}$ (symbolic/opaque)
\item \textbf{Enums:} $\widehat{\mathsf{Enum}}(E) = \{[\ell,u]\mid 0\le \ell \le u \le |E|-1\}\cup\{\bot,\top_E\}$
\end{itemize}

\noindent\textbf{Composite values:}
\begin{itemize}[leftmargin=1.25em]
\item \textbf{Structs:} $\widehat{\mathsf{Struct}}(C) = \prod_{f\in\mathsf{fields}(C)} \widehat{\mathsf{Val}}_f$ (pointwise order)
\item \textbf{Arrays:} $\widehat{\mathsf{Arr}}(\tau) = (\hat{\ell},\hat{d},M)$ where $\hat{\ell}\in \widehat{\mathbb{U}}_{256}$ is length, $\hat{d}$ is default element, $M:\mathbb{N}_{\text{fin}}\rightharpoonup \widehat{\tau}$ stores observed indices
\item \textbf{Mappings:} $\widehat{\mathsf{Map}}(\kappa\Rightarrow\tau) = (\hat{d},M)$ with default $\hat{d}$ and finite map $M$ for observed keys
\end{itemize}

\noindent\textbf{Order, join, and meet:}
For intervals: $[\ell_1,u_1] \sqsubseteq [\ell_2,u_2] \iff \ell_2 \le \ell_1 \land u_1 \le u_2$,
$[\ell_1,u_1] \sqcup [\ell_2,u_2] = [\min(\ell_1,\ell_2),\max(u_1,u_2)]$,
$[\ell_1,u_1] \sqcap [\ell_2,u_2] = [\max(\ell_1,\ell_2),\min(u_1,u_2)]$ if non-empty, else $\bot$.

Widening $\nabla$ and narrowing $\Delta$ follow standard interval analysis patterns. For address sets: $S_1 \sqcup S_2 = S_1 \cup S_2$ if $|S_1 \cup S_2| \le K$, else $\top$.

\subsection{Concrete Semantics (Denotational)}

Let stores be $\sigma:\mathsf{Var}\rightharpoonup \mathsf{CVal}$.
L-value resolution $\mathrm{loc}_\sigma(\mathit{lv})=\ell$ and write $\mathrm{write}(\sigma,\ell,v)$
update the store. Expressions are pure: $\llbracket e\rrbracket_\sigma\in\mathsf{Val}$.

\noindent\textbf{Outcome domain:}
\[
\mathsf{Res} \;::=\; \Norm(\sigma) \;\mid\; \Ret(v,\sigma) \;\mid\; \Abort
\]
with sequencing
\[
\begin{aligned}
\Norm(\sigma)\ \triangleright\ K &:= K(\sigma),\\
\Ret(v,\sigma)\ \triangleright\ K &:= \Ret(v,\sigma),\\
\Abort\ \triangleright\ K &:= \Abort.
\end{aligned}
\]

\begin{table}[t]
  \caption{Concrete denotational semantics (statements)}
  \label{tab:conc-denot}
  \centering
  \small
  \setlength{\tabcolsep}{6pt}
  \renewcommand{\arraystretch}{1.12}
  \begin{tabularx}{\columnwidth}{@{}l X@{}}
    \toprule
    \textbf{Statement} & \textbf{Meaning} \\
    \midrule
    \textsf{skip} &
    $\llbracket \textsf{skip}\rrbracket(\sigma)=\Norm(\sigma)$\\

    $s_1; s_2$ &
    $\llbracket s_1; s_2\rrbracket(\sigma)=\big(\llbracket s_1\rrbracket(\sigma)\big)\ \triangleright\ (\lambda \sigma'.\,\llbracket s_2\rrbracket(\sigma'))$\\

    $\tau\ x;$ &
    $\llbracket \tau\ x;\rrbracket(\sigma)=\Norm\!\big(\sigma[x\mapsto \mathrm{zero}_\tau]\big)$\\

    $\tau\ x=e;$ &
    $\llbracket \tau\ x=e;\rrbracket(\sigma)=\Norm\!\big(\sigma[x\mapsto \llbracket e\rrbracket_\sigma]\big)$\\

    $\mathit{lv}:=e$ &
    $\llbracket \mathit{lv}:=e\rrbracket(\sigma)=\Norm\!\big(\mathrm{write}(\sigma,\,\mathrm{loc}_\sigma(\mathit{lv}),\,\llbracket e\rrbracket_\sigma)\big)$\\

    \textsf{delete}\ $\mathit{lv}$ &
    $\llbracket \textsf{delete}\ \mathit{lv}\rrbracket(\sigma)=\Norm\!\big(\mathrm{write}(\sigma,\,\mathrm{loc}_\sigma(\mathit{lv}),\,\mathrm{zero}_{\tau(\mathit{lv})})\big)$\\

    \textsf{if}\ $p$ \textsf{then}\ $s_t$ \textsf{else}\ $s_f$ &
    $\llbracket \cdot\rrbracket(\sigma)=
      \begin{cases}
        \llbracket s_t\rrbracket(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{true},\\
        \llbracket s_f\rrbracket(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{false}
      \end{cases}$\\

    \textsf{while}\ $p$ \textsf{do}\ $s$ &
    $F(H)(\sigma)=
      \begin{cases}
        \big(\llbracket s\rrbracket(\sigma)\big)\ \triangleright\ H & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{true},\\
        \Norm(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{false}
      \end{cases}$;
    $\llbracket \textsf{while}\ p\ \textsf{do}\ s\rrbracket=\mathrm{lfp}(F)$\\

    \textsf{return}\ $e$ &
    $\llbracket \textsf{return}\ e\rrbracket(\sigma)=\Ret(\llbracket e\rrbracket_\sigma,\,\sigma)$\\

    \textsf{assert}$(p)$,\ \textsf{require}$(p)$ &
    $\llbracket \cdot\rrbracket(\sigma)=
      \begin{cases}
        \Norm(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{true},\\
        \Abort & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{false}
      \end{cases}$\\

    \textsf{revert}$(\cdots)$ &
    $\llbracket \textsf{revert}(\cdots)\rrbracket(\sigma)=\Abort$\\

    \textsf{call}$(\overline{e})$ &
    Internal: parameter binding; external: unspecified\\
    \bottomrule
  \end{tabularx}
\end{table}

\noindent\textbf{Array/mapping materialization:}
$\mathrm{loc}_\sigma(a[i])$ extends $a$ up to $i$ with defaults if needed; $\mathrm{loc}_\sigma(m[k])$ creates $m[k]$ lazily if absent.

\subsection{Abstract Semantics (Denotational)}

Let $\hat{\sigma}:\mathsf{Var}\rightharpoonup \widehat{\mathsf{CVal}}$ be the abstract store. Expressions evaluate to
$\llbracket e\rrbracket^\sharp_{\hat{\sigma}}\in \widehat{\mathsf{Val}}$.

\noindent\textbf{Abstract outcomes:}
\[
\widehat{\mathsf{Res}} \;::=\; \widehat{\Norm}(\hat{\sigma}) \;\mid\; \widehat{\Ret}(\hat{v},\hat{\sigma}) \;\mid\; \widehat{\Abort},
\]
with sequencing
\[
\begin{aligned}
\widehat{\Norm}(\hat{\sigma})\ \triangleright^\sharp\ K &:= K(\hat{\sigma}),\\
\widehat{\Ret}(\hat{v},\hat{\sigma})\ \triangleright^\sharp\ K &:= \widehat{\Ret}(\hat{v},\hat{\sigma}),\\
\widehat{\Abort}\ \triangleright^\sharp\ K &:= \widehat{\Abort}.
\end{aligned}
\]

\noindent\textbf{Auxiliary functions:}
\begin{itemize}[leftmargin=1.25em]
\item $\mathrm{refine}(\hat{\sigma},p,b)$: narrows operands of $p$ by interval meets
\item $\widehat{\mathrm{write}}(\hat{\sigma},\mathit{lv},\hat{v})$: strong update if singleton index/key, weak update otherwise
\item $\mathrm{joinRes}(r_1,r_2)$: componentwise join of abstract outcomes
\end{itemize}

\begin{table}[t]
  \caption{Abstract denotational semantics (statements)}
  \label{tab:abs-denot}
  \centering
  \small
  \setlength{\tabcolsep}{6pt}
  \renewcommand{\arraystretch}{1.12}
  \begin{tabularx}{\columnwidth}{@{}l X@{}}
    \toprule
    \textbf{Statement} & \textbf{Meaning} \\
    \midrule
    \textsf{skip} &
    $\llbracket \textsf{skip}\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}(\hat{\sigma})$\\

    $s_1; s_2$ &
    $\llbracket s_1; s_2\rrbracket^\sharp(\hat{\sigma})=\big(\llbracket s_1\rrbracket^\sharp(\hat{\sigma})\big)\ \triangleright^\sharp\ (\lambda \hat{\sigma}'.\,\llbracket s_2\rrbracket^\sharp(\hat{\sigma}'))$\\

    $\tau\ x;$ &
    $\llbracket \tau\ x;\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}\!\big(\hat{\sigma}[x\mapsto \hat{\mathrm{init}}(\tau)]\big)$\\

    $\tau\ x=e;$ &
    $\llbracket \tau\ x=e;\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}\!\big(\hat{\sigma}[x\mapsto \alpha_\tau(\llbracket e\rrbracket^\sharp_{\hat{\sigma}})]\big)$\\

    $\mathit{lv}:=e$ &
    $\llbracket \mathit{lv}:=e\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}\!\big(\widehat{\mathrm{write}}(\hat{\sigma},\,\mathit{lv},\,\llbracket e\rrbracket^\sharp_{\hat{\sigma}})\big)$\\

    \textsf{delete}\ $\mathit{lv}$ &
    $\llbracket \textsf{delete}\ \mathit{lv}\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}\!\big(\widehat{\mathrm{write}}(\hat{\sigma},\,\mathit{lv},\,\hat{\mathrm{zero}}_{\tau(\mathit{lv})})\big)$\\

    \textsf{if}\ $p$ \textsf{then}\ $s_t$ \textsf{else}\ $s_f$ &
    $\hat{\sigma}_t=\mathrm{refine}(\hat{\sigma},p,\mathsf{true})$, $\hat{\sigma}_f=\mathrm{refine}(\hat{\sigma},p,\mathsf{false})$;
    $\llbracket \cdot\rrbracket^\sharp(\hat{\sigma})=\mathrm{joinRes}\!\big(\llbracket s_t\rrbracket^\sharp(\hat{\sigma}_t),\ \llbracket s_f\rrbracket^\sharp(\hat{\sigma}_f)\big)$\\

    \textsf{while}\ $p$ \textsf{do}\ $s$ &
    $G^\sharp(H)(\hat{\sigma})=\mathrm{joinRes}\big(
      \llbracket s\rrbracket^\sharp(\mathrm{refine}(\hat{\sigma},p,\mathsf{true}))\ \triangleright^\sharp\ H,\;
      \widehat{\Norm}(\mathrm{refine}(\hat{\sigma},p,\mathsf{false}))
    \big)$;
    $\llbracket \textsf{while}\ p\ \textsf{do}\ s\rrbracket^\sharp
      = \mathrm{lfp}^{\nabla}(G^\sharp) \;\triangle\; \mathrm{narrow}^{k}$\\

    \textsf{return}\ $e$ &
    $\llbracket \textsf{return}\ e\rrbracket^\sharp(\hat{\sigma})=\widehat{\Ret}(\llbracket e\rrbracket^\sharp_{\hat{\sigma}},\,\hat{\sigma})$\\

    \textsf{assert}$(p)$,\ \textsf{require}$(p)$ &
    $\widehat{\Norm}(\mathrm{refine}(\hat{\sigma},p,\mathsf{true}))$ if $p$ must-hold; $\widehat{\Abort}$ if $p$ must-fail; $\mathrm{joinRes}$ otherwise\\

    \textsf{revert}$(\cdots)$ &
    $\llbracket \textsf{revert}(\cdots)\rrbracket^\sharp(\hat{\sigma})=\widehat{\Abort}$\\

    \textsf{call}$(\overline{e})$ &
    Internal: parameter binding; external: havoc footprint or $\widehat{\Abort}$\\
    \bottomrule
  \end{tabularx}
\end{table}

\noindent\textbf{Expression semantics:}
Arithmetic ($+,-,*,/,\%$): interval arithmetic with wrapping;
comparisons ($<,\le,=,\neq,\ge,>$): abstract booleans;
logical ($\land,\lor,\neg$): three-valued logic.

\noindent\textbf{Array/mapping access:}
Singleton index/key: strong update; range/non-singleton: join of materialized cells.

\end{document}
