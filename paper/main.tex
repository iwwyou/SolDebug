\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style

% Korean language support
\usepackage[utf8]{inputenc}
%\usepackage{kotex}  % Commented out - package not found

% Math packages first
\usepackage{amsmath}%
\usepackage{amssymb}%
\usepackage{amsfonts}%
\usepackage{amsthm}%
\usepackage{amsopn}%
\usepackage{amstext}%
\usepackage{mathrsfs}%

% Graphics and tables
\usepackage{graphicx}%
\DeclareGraphicsExtensions{.png,.pdf,.jpg}% PNG first, then PDF
\usepackage{tikz}%
\usetikzlibrary{positioning,shapes,arrows.meta}%
\usepackage{multirow}%
\usepackage{booktabs}%
\usepackage{tabularx}
\usepackage{array}

% Algorithm packages
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%

% Other packages
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
% \usepackage{manyfoot}% Package not available in MiKTeX
\usepackage{listings}%
\usepackage{comment}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}

\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
\newtheorem{proposition}[theorem]{Proposition}% 
\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom

% 예: (Abbott 1991; Barakat et al. 1995) 꼴
\bibpunct{(}{)}{;}{a}{}{ } % 저자–연도 사이 쉼표 제거

% --- URL 줄바꿈 개선(긴 URL 자동 줄바꿈) ---
\usepackage[hyphens]{url}
\usepackage[colorlinks=true,allcolors=blue]{hyperref}
\Urlmuskip=0mu plus 1mu
\def\UrlBreaks{\do\/\do-\do\_\do\.\do\?\do\&}

% --- 레퍼런스(숫자 라벨 숨기고 행걸이 들여쓰기) ---
\makeatletter
\renewcommand\@biblabel[1]{} % [1] 같은 숫자 라벨 숨김
\makeatother
\setlength{\bibsep}{0.2em}   % 항목 간 간격
% natbib 계열 문서라면 \bibhang 사용 가능(행걸이 폭)
\setlength{\bibhang}{2em}


\begin{document}

\title[Article Title]{SolQDebug: Debug Solidity Quickly for Interactive Immediacy in Smart Contract
Development}

\author[1]{\fnm{Inseong} \sur{Jeon}}\email{iwwyou@korea.ac.kr}

\author[1]{\fnm{Sundeuk} \sur{Kim}}\email{sd\_kim@korea.ac.kr}

\author[1]{\fnm{Hyunwoo} \sur{Kim}}\email{khw0809@korea.ac.kr}

\author*[1]{\fnm{Hoh Peter} \sur{In}}\email{hoh\_in@korea.ac.kr}

\affil*[1]{\orgdiv{Department of Computer Science}, \orgname{Korea University},
\orgaddress{\street{145, Anam-ro}, \city{Seonbuk-gu}, \postcode{02841}, \state{Seoul},
\country{Republic of Korea}}}


\abstract{Debugging Solidity contracts remains cumbersome and slow. Even a simple inspection, such
as tracking a variable through a branch, requires full compilation, contract deployment, preparatory
transactions, and step-by-step bytecode tracing. Existing tools operate only after execution and
offer no support while code is under construction. We present \textsc{SolQDebug}, the first
interactive, source-level assistant for Solidity developers that provides millisecond feedback
before compilation or chain interaction. \textsc{SolQDebug} extends the Solidity grammar with
interactive parsing, incrementally maintains a dynamic control-flow graph, and performs
interval-based abstract interpretation guided by inline test annotations, enabling developers to
simulate symbolic inputs and inspect contract behavior as in traditional debugging environments. In
an evaluation on real-world functions, \textsc{SolQDebug} enables low-latency, statement-level
analysis during development without requiring compilation or deployment.}


\keywords{Smart Contract Development, Solidity, Debugging, Abstract Interpretation}

\maketitle

\section{Introduction}\label{sec1}

    Smart contracts are the backbone of decentralized applications, and Solidity has become the
    dominant language for writing them~\citep{smart contract evolution, solidity}. As contracts grow
    more complex and control more assets, developers must reason about correctness throughout the
    development cycle—not just at deployment. Large language models (LLMs) such as ~\citet{gpt} or
    ~\citet{llama} can assist with code generation but offer no guarantees of correctness.
    Ultimately, developers remain responsible for understanding variable interactions, control flow,
    and numeric boundaries during authoring.

    Unfortunately, the debugging workflow for Solidity lags far behind traditional programming
    environments. Even a single inspection requires full compilation, deployment, transaction-based
    state setup, and manual bytecode-level tracing. Tools like ~\citet{remix}, ~\citet{hardhat}, and
    ~\citet{forge} replicate this costly pipeline, providing no live feedback during edits. A prior
    study found that 88.8\% of Solidity developers described debugging as painful, and 69\%
    attributed this to the absence of interactive, source-level tooling~\citet{interview}. Despite
    this widely acknowledged pain point, we find no existing research or tooling that provides
    interactive feedback during Solidity code authoring—a gap that this paper aims to fill.
    
    This paper presents \textsc{SolQDebug}, a source-level interactive Solidity debugger powered by
    abstract interpretation. Rather than replacing runtime debuggers, it complements them by
    enabling symbolic, per-statement inspection during code authoring—before compilation or
    deployment. It targets the Solidity pattern of single-contract, single-transaction execution,
    where each function is isolated and stateless—ideal for static reasoning but difficult to
    simulate manually. To support this, \textsc{SolQDebug} applies interval-based abstract
    interpretation, which generalizes over symbolic inputs, exposes edge-case behaviors, and
    provides sound results with low overhead. This approach gives developers immediate feedback and
    enables them to reason efficiently about how symbolic inputs influence variable behavior.
    Although these inputs enable generalization across multiple cases, certain input configurations
    or control structures may lead to wider output ranges. We evaluate these behaviors empirically
    and propose annotation strategies that help maintain interpretability across typical Solidity
    patterns.
    
    To achieve this goal, \textsc{SolQDebug} builds on two core ideas. First, it extends the
    Solidity grammar with interactive parsing rules and dynamically updates the control-flow graph
    to reflect incremental edits, enabling keystroke-level structural changes during code authoring.
    Second, it performs abstract interpretation seeded by inline annotations. These annotations,
    written directly in the source code, allow developers to specify symbolic values for both
    parameters and storage variables, similar to how traditional debuggers let users configure
    initial states and explore control flow.
    
    We evaluate \textsc{SolQDebug} on real-world functions from ~\citet{dappscan}, demonstrating
    millisecond-scale responsiveness under symbolic input. Beyond latency, we analyze how input
    interval structure affects interpretability in common Solidity patterns, such as
    division-normalized arithmetic.
    
    This paper makes the following contributions:
    
    \begin{itemize}
      \item We identify the main barriers to interactive Solidity debugging: latency from compilation, deployment, and transaction setup, and EVM constraints that prevent lightweight re-execution.
      \item We design an interactive parser and dynamic control-flow graph (CFG) engine that supports live structural updates and syntactic recovery.
      \item We introduce an abstract interpreter that incorporates developer annotations as symbolic input, supporting fast, deployment-free debugging workflows.
      \item We implement and evaluate \textsc{SolQDebug} on real-world contracts, demonstrating its millisecond responsiveness and exploring annotation strategies that maintain interpretability under a range of symbolic input patterns.
    \end{itemize}

\section{Background}\label{sect2}
    \subsection{Structure of Solidity Smart Contract}       
        Solidity smart contracts may declare contracts, interfaces, and libraries. Executable
        business logic typically resides in contracts, and functions serve as transaction entry
        points. Variables are usefully grouped as global (EVM metadata such as msg.sender or block.
        timestamp), state (persistent storage owned by a contract), and local (scoped to a call).
        Types include fixed-width integers, address, booleans, byte arrays, and user-defined structs;
        containers include arrays and mappings. A mapping behaves like an associative array with an
        implicit zero value for unseen keys and is not directly iterable. Storage classes (storage,
        memory, calldata) indicate lifetime and mutability; we mention them only to fix terminology.
        Visibility and mutability qualifiers (public, external, internal, private; pure, view,
        payable) exist but are not central to our single-contract, single-transaction setting.
        Control flow (if/else, while/for/do-while, break/continue, return) follows C/Java
        conventions.

        \begin{lstlisting}[language=Solidity, numbers=left, basicstyle=\ttfamily\small, caption={Minimal example used to illustrate grammar elements relevant to our analysis}, label={lst:grammar-min}] 
contract Example {
    address public owner;
    uint256 public totalSupply = 1000;
    mapping(address => uint256) private balances;

    modifier onlyOwner() {
        require(msg.sender == owner, "not owner");
        _;
    }

    function burn(uint256 amount) public onlyOwner {
        uint256 bal = balances[msg.sender];
        uint256 delta;
        if (bal >= amount) {
            balances[msg.sender] = bal - amount;
            delta = amount;
        } 
        else {            
            delta = 0;
        }
        totalSupply -= delta;
    }
}
        \end{lstlisting}

        The example highlights the specific features we rely on later. State variables include
        general types (owner, totalSupply) and a mapping from addresses to balances; global
        variables appear implicitly in guards via msg.sender. The function burn introduces
        parameters and a local variable (bal). The modifier onlyOwner performs a precondition check
        before the function body executes; the placeholder underscore marks where the original body
        is inserted when the modifier is inlined. In analysis, such modifiers are expanded at their
        precise positions around the function body in the control-flow graph.
        
        These grammar elements connect directly to our semantics. Guards such as require narrow
        feasible ranges along taken branches. Modifiers are inlined so that their precondition
        checks are analyzed in sequence with the function body. Containers like mappings remain
        symbolic until a concrete key is accessed, at which point an abstract value is materialized
        for that access. This level of detail suffices for our abstract interpretation in the
        single-contract, single-transaction scope without introducing parts of the language that our
        evaluation does not exercise.

        
    \subsection{Solidity Execution Model}
        To execute a Solidity contract on the blockchain, it must first be deployed. Deployment
        occurs through a one-time transaction that stores the compiled bytecode on-chain and invokes
        the constructor exactly once. After deployment, all subsequent interactions are message-call
        transactions. In these, the caller specifies a public function along with encoded calldata.
        Once the transaction is mined into a block, the Ethereum Virtual Machine (EVM) jumps to the
        designated entry point and executes the corresponding function sequentially. At runtime,
        Solidity variables fall into three distinct storage classes~\cite{solidity}:
    
        \begin{itemize}
          \item \textbf{Global variables} represent implicit, read-only metadata provided by the EVM, such as \texttt{block.timestamp}, \texttt{msg.sender}, and \texttt{msg.value}.
          \item \textbf{State variables} store persistent data within the contract and retain their values across transactions.
          \item \textbf{Local variables} include function parameters and temporary values scoped to a single execution context.
        \end{itemize}
    
        These three classes share a unified type system comprising primitive types like \texttt{uint}
        , \texttt{int}, \texttt{bool}, and \texttt{address}, as well as composite types such as
        arrays, mappings, and structs. Composite values can be nested to arbitrary depth using field
        access (\texttt{.}) or indexing (\texttt{[\,]}). Control flow follows familiar C-style
        constructs such as \texttt{if}/\texttt{else}, \texttt{while}, \texttt{for}, and
        \texttt{return}, alongside Solidity-specific statements like \texttt{emit} and
        \texttt{revert}.
        
        As a result, debuggers must resolve potentially complex, multi-step expressions to analyze
        deeply nested elements within the contract state.

\begin{figure*}[!t]
  \centering
  \setlength{\tabcolsep}{3pt}
  \renewcommand{\arraystretch}{1}

  \begin{tabular}{cc}
    \subcaptionbox{Compile\label{fig:step-compile}}
      {\includegraphics[width=.47\textwidth]{1. Compile.png}} &
    \subcaptionbox{Deploy related contracts\label{fig:step-deploy}}
      {\includegraphics[width=.47\textwidth]{2. Deploy.png}} \\[4pt]
    \subcaptionbox{Send preparatory transactions\label{fig:step-init}}
      {\includegraphics[width=.47\textwidth]{3. Execution.png}} &
    \subcaptionbox{Bytecode-level debugging\label{fig:step-debug}}
      {\includegraphics[width=.47\textwidth]{4. Debug.png}}
  \end{tabular}

  \caption{Traditional Solidity debugging workflow}

  \label{fig:legacy-debug-grid}
\end{figure*}
       

    \subsection{Root Causes of the Solidity-Debugging Bottleneck}
        Debugging Solidity programs remains significantly slower than traditional application
        development workflows due to two orthogonal obstacles.
        
        \smallskip
        \noindent\textbf{(1) Environmental disconnect.}
        Unlike conventional IDEs such as PyCharm~\cite{pycharm} or Visual Studio~\cite{visual},
        where the source editor and execution engine run in the same process, Solidity development
        involves external coordination with a blockchain node at every stage of the workflow. Even a
        single debugging cycle must pass through four sequential stages (see Fig.1). First, the
        contract must be compiled. Then, the bytecode is deployed to a local or test chain. Next,
        developers must manually initialize the on-chain state by sending setup transactions.
        Finally, the target function is invoked, and its execution is traced step by step at the
        bytecode level.
        
        This workflow introduces several seconds to minutes of latency per iteration, fundamentally
        breaking the fast “type-and-inspect” feedback cycle expected in modern development tools. To
        mitigate this friction, developers often rely on \texttt{emit} logs or event outputs to
        observe intermediate values. However, such instrumentation provides only runtime snapshots
        and lacks the structural insight needed to understand symbolic variation or control-flow
        behavior. Moreover, modifying the expression of interest typically requires recompilation
        and redeployment, compounding latency and disrupting iteration. The final stage—tracing raw
        EVM opcodes—is particularly costly, as developers are forced to mentally reconstruct
        source-level semantics. This not only adds execution overhead but also imposes significant
        cognitive burden during fault localization and fix validation.
    
        \smallskip
        \noindent\textbf{(2) Architectural limitations of the EVM.}
        The Ethereum Virtual Machine (EVM) is a state-based execution engine in which each
        transaction mutates a globally persistent storage. Once a function executes, its side
        effects are irreversible unless external intervention is performed. Re-executing the same
        function along the same control path is nontrivial: developers must either redeploy the
        entire contract to restore the initial state, or manually reconstruct the required
        preconditions via preparatory transactions—both of which incur significant overhead.
        
        Additionally, if a function includes conditional guards that depend on the current
        state—such as account balances or counters—then any debugging session must first ensure that
        those conditions are satisfied. Fig. 2 illustrates this challenge: the debug target function
        enforces a check on \texttt{\_balances[account]}, requiring developers to manually assign a
        sufficient balance before they can observe the downstream effects on \texttt{\_totalSupply}.
        Without such setup, the function exits early, preventing inspection of the intended
        execution path.
        
        In short, these constraints make repeated debugging iterations costly and fragile. According
        to a developer study~\cite{interview}, 88.8\% of Solidity practitioners reported frustration
        with current debugging workflows, with 69\% attributing this to the lack of interactive,
        state-aware tooling.

    \subsection{Proposed Methodology and Technical Challenges}

    \textsc{SolQDebug} addresses the two root causes of Solidity’s debugging bottleneck—external
    latency from blockchain round trips, and internal opacity due to storage-based semantics—through
    a pair of lightweight but complementary techniques.
    
    \smallskip
    \noindent\textbf{(1) Eliminating blockchain latency via in-editor interpretation.}
    The traditional debugging workflow requires compilation, deployment, transaction-based state
    setup, and bytecode tracing—each incurring significant latency. \textsc{SolQDebug} replaces this
    round trip by performing both parsing and abstract interpretation directly inside the Solidity
    Editor. To support live editing, we extend the Solidity grammar with interactive parsing rules
    tailored for isolated statements, expressions, and control-flow blocks. When the developer types
    or edits code, only the affected region is reparsed using a reduced grammar.
    
    Each parsed statement is inserted into a dynamic control-flow graph (CFG), and abstract
    interpretation resumes from the edit point. The interpreter uses an interval lattice, assigning
    each variable a conservative range $[l, h]$ to expose edge conditions (e.g., overflows or
    failing guards) and to approximate groups of concrete executions that follow the same path. This
    enables millisecond-scale feedback on code structure and control flow without compilation or
    chain interaction.
    
    \smallskip
    \noindent\textbf{(2) Re-instantiating symbolic state without redeployment.}
    The EVM does not support reverting to a prior state without redeploying the contract or
    replaying transactions—both of which disrupt iteration. \textsc{SolQDebug} introduces batch
    annotations as a lightweight mechanism for symbolic state injection. In essence, this reflects a
    core debugging activity: varying inputs or contract state to observe control-flow outcomes.
    Rather than reconstructing such conditions through live transactions, developers can write
    annotations at the top of the function to define initial abstract values. These values are
    injected before analysis begins and rolled back afterward, ensuring test-case isolation.
    
    This approach brings the debugging workflow closer to the source by making state manipulation
    explicit and reproducible within the code itself. Developers can explore alternative execution
    paths by editing annotations alone—without modifying the contract logic or incurring compilation
    and deployment overhead. It effectively decouples symbolic input configuration from the analysis
    cycle, while preserving the intuitive debugging process developers already follow.

\begin{figure*}[t]
  \centering
  \includegraphics[
    width=0.95\textwidth,
    height=0.35\textheight,
    keepaspectratio
  ]{5. Architecture.png}
  \caption{\textsc{SolQDebug} architecture}
  \label{fig:solqdebug-arch}
\end{figure*}

\section{The design of SolQDebug}
    \subsection{System Architecture}
        \textsc{SolQDebug} receives incremental edits as its primary input—typically a snippet of
        Solidity code or an inline debug annotation. Rather than expecting complete programs, the
        system is designed to accept fragments ranging from full statements to partial control-flow
        constructs. These edits include partial Solidity fragments and batch annotations, which are
        processed in isolation without requiring recompilation or transaction replay. The system
        assumes that each line contains at most one statement; compound forms such as
        \texttt{if (...) return;} are not supported. The structure of these inputs is described in
        Section 3.B; here, we outline the four-stage processing pipeline.
    
        \textbf{(1) Parsing Module.}
        Each incoming edit first passes through the \textit{Context Analyzer}, which reconstructs a
        source-level snapshot surrounding the modified lines, determines the enclosing contract or
        function, and selects the appropriate interactive grammar rule. Subsequently, the
        Interactive Parser, built atop ~\citet{antlr}, applies an extended grammar that incorporates
        seven additional reduction rules to support isolated Solidity constructs such as expressions,
        statements, and definitions. A separate rule is dedicated to debug annotations, allowing
        single-line analysis directives to be parsed as valid units. To ensure syntactic integrity,
        the reconstructed source is also verified using the Solidity compiler before analysis
        proceeds. This allows the system to reject malformed fragments early and maintain
        consistency across the abstract syntax tree and control-flow graph. Debug annotations are
        parsed as valid syntactic units and forwarded for interpretation; their semantic effects are
        described in the analysis stage.

        \textbf{(2) Analysis Module.}
        Each parsed statement is enriched with contextual metadata. This includes its enclosing
        contract and function, its semantic role (e.g., declaration or condition), and its static
        type. The statement is then forwarded to the Dynamic CFG Builder, which inserts a basic
        block at the precise edit point and rewires the surrounding control edges accordingly.
        Conditional branches merge incoming states using $\sqcup$, and loop headers are updated via
        localized fixpoint computation. The Abstract Interpreter propagates abstract values using a
        classic interval lattice. Types such as uintN and intN are interpreted as $N$-bit intervals.
        Boolean values are modeled as $\{0,1\}$ intervals, and addresses as 160-bit unsigned
        intervals. Byte arrays and strings remain symbolic throughout. For composite containers such
        as structs, arrays, and mappings, the container itself is treated as symbolic until a
        specific field, element, or key is accessed. At that point, the interpreter materializes a
        fresh abstract value. If the base type is elementary, it receives the corresponding interval;
        otherwise, a new symbolic placeholder is propagated. Before each batch run, the Snapshot
        Manager saves the full abstract memory. Once execution completes, the snapshot is restored.
        This guarantees that consecutive test cases remain isolated and do not interfere with each
        other, even when global or local bindings are modified.

        \textbf{(3) Line-Level Output.}
        After interpretation, the system emits a per-statement summary of relevant variable
        intervals. This includes:

        \begin{itemize}
          \item \textbf{Variable declarations:} the initial interval of the declared variable.
          \item \textbf{Assignments:} the updated interval of the left-hand side variable after evaluation.
          \item \textbf{Return statements:} the interval of the returned value or tuple of values.
          \item \textbf{Loops:} intervals for variables that changed during loop execution, computed after fixpoint convergence (loop delta).
        \end{itemize}
        
        All outputs are mapped to source line numbers and displayed directly in the Solidity editor,
        providing immediate, deployment-free feedback to developers.
    
    \subsection{Running Example}
\begin{comment}
시스템 아키텍처에서 논의된 SolQDebug의 동작 방식을 요약하면 다음과 같다.
1) Each partial source code fragment is interpreted using abstract semantics to compute variable
intervals
2) The corresponding expression (e.g., assignment) is stored in the CFG node, which is inserted at a
semantically valid point in the control-flow graph based on context information
3) When batch annotations are present, the full function is reinterpreted using the pre-built CFG
and updated abstract states.
 아키텍처의 각 모듈의 동작의 직관적인 이해를 위해 fig.1의 예제 코드 중 burn 함수에 대해 사용자가 부분 코드를 입력할 때마다 수행되는 분석 과정, batch
 annotation을 작성했을 때의 분석 과정을 나타내었다.
\end{comment}
    To make the architecture concrete, we walk through a small running example that exercises the
    main components of SolQDebug. The system operates as follows. First, each incremental source
    fragment is interpreted under abstract semantics to compute interval for the variables it
    touches. Second, the corresponding expression is stored in a CFG node that is inserted at a
    semantically valid point, determined from the edit’s context and the existing control‑flow.
    Third, when batch annotations are present, the entire function is reinterpreted using the
    pre‑built CFG with the updated abstract state. We illustrate both modes—incremental source edits
    and batch annotations—using the burn function from Listing~\ref{lst:grammar-min}, and then refer
    back to the detailed mechanisms in §§3.3–3.5.

        \subsubsection{Source Code Analysis Example}

\begin{table}[t!]
  \caption{Incremental inputs for the running example}
  \label{tab:input_code}
  \centering
  \setlength{\tabcolsep}{4pt}
  \renewcommand{\arraystretch}{1.05}
  \ttfamily\footnotesize
  \begin{tabularx}{\columnwidth}{@{}c c X@{}}
    \toprule
    \textbf{Step} & \textbf{Lines of Input Fragment} & \textbf{Fragment} \\
    \midrule
    1 & 11--12 &
      \begin{tabular}[t]{@{}l@{}}
        function burn(uint256 amount) public onlyOwner \{\\
        \}
      \end{tabular} \\
    2 & 12 & uint256 bal = balances[msg.sender]; \\
    3 & 13 & uint256 delta; \\
    4 & 14--15 &
      \begin{tabular}[t]{@{}l@{}}
        if (bal >= amount) \{\\
        \}
      \end{tabular} \\
    5 & 15 & balances[msg.sender] = bal - amount; \\
    6 & 16 & delta = amount; \\
    7 & 18--19 &
      \begin{tabular}[t]{@{}l@{}}
        else \{\\
        \}
      \end{tabular} \\
    8 & 19 & delta = 0; \\
    9 & 21 & totalSupply -= delta; // new input \\
    \bottomrule
  \end{tabularx}
  \rmfamily
\end{table}

\begin{comment}
Table 1은 listing 1의 코드 중 함수 burn에 대해 개발자가 편집기에서 입력하는 증분 단위를 보여준다. SolQDebug가 받는 입력은 크게 두 유형이다. (i)
함수 선언이나 if/else처럼 '{' '}' 형태의 블록과 (ii) 세미콜론으로 끝나는 단일 문장 조각이다. 블록 조각은 편집기에서 “{”를 치는 순간 “}”가 자동으로 보완되기
때문에, 두 줄이 한 번에 들어온다(예: function … { / }). 이후 본문이 채워지면 자동으로 생성된 닫는 중괄호 \}는 뒤로 밀린다.
\end{comment}

Table~\ref{tab:input_code} lists the incremental fragments a developer types for the function burn
in Listing ~\ref{lst:grammar-min}. SolQDebug accepts two kinds of fragments: (i) block fragments
such as a function header or an if/else block, and (ii) single statements that end with a semicolon.
Most editors auto‑insert a closing brace when ``\{'' is typed, so a block fragment arrives as two
lines at once (e.g., function … \{ and the matching \}). As the body is filled, the auto‑inserted
closing brace is pushed downward. The line numbers shown in the table refer to the listing
~\ref{lst:grammar-min}; intermediate edits may temporarily place the closing brace earlier.

\begin{figure*}[t]
  \centering
  \begin{tikzpicture}[
    node distance=1.5cm and 2.5cm,
    block/.style={rectangle, draw, thick, minimum width=3cm, minimum height=1cm, align=center, font=\footnotesize},
    cond/.style={diamond, draw, thick, aspect=2, minimum width=2cm, minimum height=1cm, align=center, font=\footnotesize},
    join/.style={rectangle, draw, thick, fill=yellow!20, minimum width=2.5cm, minimum height=0.6cm, align=center, font=\footnotesize},
    empty/.style={circle, draw, thick, minimum size=0.8cm, font=\large}
  ]

  % Entry and declarations
  \node[block] (entry) {ENTRY};
  \node[block, below=1cm of entry] (decl) {Declarations\\bal, delta\\env: \{bal: $\top$, delta: $\top$\}};

  % Condition node
  \node[cond, below=1.2cm of decl] (cond) {$bal \geq amount$};

  % Branch paths (simplified)
  \node[block, below left=1.5cm and 2cm of cond] (true) {... intermediate nodes ...\\(Steps 5--6)};
  \node[block, below right=1.5cm and 2cm of cond] (false) {... intermediate nodes ...\\(Step 8)};

  % Leaf nodes
  \node[block, below=1cm of true] (leaf_t) {[Leaf T]\\delta = amount\\env: \{bal:[100,200],\\delta:[50,150]\}};
  \node[block, below=1cm of false] (leaf_f) {[Leaf F]\\delta = 0\\env: \{bal:[100,200],\\delta:[0,0]\}};

  % Join point (empty node)
  \node[join, below=2cm of cond, yshift=-2.5cm] (join) {$\sqcup$ Join Node\\(empty)};

  % New node with Step 9
  \node[block, below=1cm of join, fill=green!15] (step9) {[New Node]\\totalSupply -= delta\\env: \{totalSupply:[850,1000]\}};

  % Exit
  \node[block, below=1cm of step9] (exit) {EXIT};

  % Edges
  \draw[->, thick] (entry) -- (decl);
  \draw[->, thick] (decl) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {True} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {False} (false);
  \draw[->, thick] (true) -- (leaf_t);
  \draw[->, thick] (false) -- (leaf_f);
  \draw[->, thick] (leaf_t) -| (join);
  \draw[->, thick] (leaf_f) -| (join);
  \draw[->, thick] (join) -- node[right] {Step 9 inserted} (step9);
  \draw[->, thick] (step9) -- (exit);

  \end{tikzpicture}
  \caption{CFG structure showing Step 9 insertion. Each statement occupies a separate basic node; intermediate nodes along each branch are omitted, showing only the leaf nodes before the join point. The join point node is empty and serves only to merge the environments from both branches}
  \label{fig:solqdebug-cfg}
\end{figure*}

\begin{comment}
그림 3은 표 1의 1–8단계까지가 이미 CFG에 반영된 상태에서, 새로운 입력인 9단계 totalSupply -= delta;가 도착했을 때 분석이 어떤 환경에서 수행되고 결과가
어떻게 동적으로 삽입되는지를 시각적으로 보여준다. 이때, 함수 burn 안의 내용을 위주로 설명하고자 하였으며 함수 선언에서 onlyOwner와 같은 modifier에 대한 설명은
이후 3.5에서 기술하였기에 생략되었다.

먼저, SolQDebug는 각 노드를 다음처럼 유지한다.

기본 블록(Basic Block): 분기가 발생하지 않은 statement가 순차적으로 저장되는 블록으로, 블록 내부 문장이 순서대로 평가되면서 환경이 갱신되며 맨 마지막
statement까지 실행했을 때의 추상 환경(변수 별 Interval)을 저장한다. 또한 batch annotation 작성 시 재분석을 위해 블록이 담고 있는
statement를 함께 기록한다.

조건 노드(Condition Node): 술어(예: bal >= amount) 자체만 기록을하며, 이 시점에는 변수 값을 갱신하지 않는다.

분기 : 조건 노드의 후속 블록이 만들어질 때, 술어에 따라 각 경로의 환경이 프루닝된다(참 경로는 bal이 amount 이상, 거짓 경로는 그 반대가 되도록 구간이 좁혀짐).
이후 새로운 문장이 입력으로 들어올 때 프루닝된 환경을 기반으로 분석된다.

이 상태에서 9단계 입력이 들어오면 다음 순서로 처리한다.

의미 해석: totalSupply -= delta;를 인터랙티브 파서로 단일 문장으로 파싱하고 구문·의미를 확정한다(§3.3).

삽입 지점 탐색: 입력의 컨텍스트(라인·포함 구조 스택) 와 기존 CFG를 함께 사용해 유효한 삽입 지점을 찾는다. 단순히 “바로 앞 줄”이 아니라, 현재가 if의 합류 이후라는
구조 정보를 토대로 삽입 위치를 결정한다(§3.5).

합류 환경 계산: 삽입 지점의 선행 블록이 여러 개면, 각 리프의 추상 환경을 최상한(LUB; JoinBranches) 으로 합쳐 합류 블록을 만들고, 여기에 새 문장을 삽입한다.
루프가 얽혀 있으면 그 전에 루프 헤더에서 국소 고정점을 먼저 수렴시킨다(§3.5).

평가·재배선: 합류 블록의 환경에서 totalSupply -= delta를 한 번만 평가해 totalSupply의 새로운 구간을 얻고, 기존의 참/거짓 리프가 향하던 간선을 합류
블록 → Exit으로 재배선한다.

이 절에서는 순차 입력 사례로 설명했지만, else를 나중에 추가하는 등 비순차 입력에도 동일한 절차가 적용되며, 필요 시 기존 간선이 재배선된다.
\end{comment}
        Figure~\ref{fig:solqdebug-cfg} visualizes the state of the CFG after Steps 1–8 have already
        been integrated and shows how the new input in Step 9 (totalSupply -= delta;) is analyzed
        and inserted.  For clarity, we focus on the function body in this running example and ignore
        the modifier referenced in the header; modifiers and their placement are treated in §3.5.

        SolQDebug uses the following node semantics and bookkeeping rules:

\begin{itemize}
  \item \textbf{Basic nodes.} A basic node contains a straight-line sequence of statements.
        As statements are evaluated in order, the node maintains the abstract environment
        at the end of the node—i.e., the interval for each variable.
        For later re-analysis (e.g., under batch annotations), the node also records its statement
        list.
  \item \textbf{Condition nodes.} A condition node stores only the predicate 
        (e.g., \texttt{bal >= amount}) and does not update the environment at that point.
  \item \textbf{Branch refinement.} When the true/false successors of a condition are created,
        the incoming environment is pruned along each edge: the true successor refines
        intervals under the predicate, while the false successor refines them under its negation.
        Subsequent statements are analyzed under these pruned environments.
\end{itemize}

        With these rules in place, the arrival of Step~9 proceeds as follows:

\begin{itemize}
  \item[\textbf{(1)}] \textbf{Parsing and semantics.} 
        The interactive parser recognizes \texttt{totalSupply -= delta;} as a single assignment
        and constructs its abstract transfer function (§3.3).
  \item[\textbf{(2)}] \textbf{Finding the insertion point.} 
        Using the current edit context (line number and the stack of enclosing constructs) 
        together with the existing CFG, SolQDebug locates the semantically valid insertion point. 
        In this case the context indicates the join after the if/else, 
        not merely the preceding line (§3.5).
  \item[\textbf{(3)}] \textbf{Join environment (and localized fixpoint if needed).}
        If the insertion point has multiple predecessors, SolQDebug computes the least upper bound
        (\(\sqcup\), JoinBranches) of their environments to create a join point node.
        If a loop header is on the path, a localized fixpoint is computed at the header before
        joining (§3.5).
  \item[\textbf{(4)}] \textbf{Evaluation and rewiring.}
        A new basic node is created immediately after the join point node, and the assignment
        is evaluated in this new node using the joined environment to produce the new interval for
        \texttt{totalSupply}. The outgoing edges from the two branch leaves are rewired to the
        join point, which flows into the new node and then to the exit.
  \item[\textbf{(5)}] \textbf{Reinterpretation from the insertion point.}
        To maintain soundness of the abstract interpretation, SolQDebug reinterprets all nodes
        reachable from the newly inserted node. Since the insertion changes the incoming environment
        for subsequent statements, the \texttt{reinterpret\_From} function propagates the updated
        environment forward through the CFG, ensuring that all downstream intervals remain valid.
\end{itemize}

        This design allows SolQDebug to reuse all path‑local computations accumulated up to the
        leaves while maintaining semantic correctness at the insertion site. Although the narrative
        assumes sequential input, the same procedure applies to out‑of‑order edits (e.g., adding an
        else later). The insertion‑point search, leaf collection, join/fixpoint handling, and edge
        rewiring remain unchanged and safely update the existing CFG.
        
        \subsubsection{Batch Annotation Analysis Example}

\begin{lstlisting}[language=Solidity, numbers=left, basicstyle=\ttfamily\small, caption={Burn function with batch annotations}, label={lst:grammar-batch}] 
function burn(uint256 amount) public onlyOwner {
    // @Debugging BEGIN     
    // @StateVar balances[msg.sender] = [100,200]
    // @LocalVar amount = [50,150]
    // @Debugging END         
    uint256 bal = balances[msg.sender];
    uint256 delta;
    if (bal >= amount) {
        balances[msg.sender] = bal - amount;
        delta = amount;
    } 
    else {        
        delta = 0;
    }
    totalSupply -= delta;
}
    
\end{lstlisting}

\begin{comment}
배치 주석은 개발자가 초기 상태와 파라미터를 상징적(구간) 값으로 선언적으로 지정하고, 이미 구축된 CFG 위에서 단일 패스 재해석을 수행해 줄 단위 결과를 얻기 위한 장치이다.
본 연구에서의 ‘디버깅’은 배포 전 편집 단계에서 입력(및 상태) 값을 바꾸어 분기 도달성, 가드 유효성, 값 경계를 상호작용적으로 관찰하는 활동을 의미한다. 따라서 주석으로 초기
범위를 지정하지 않은 변수는 보수적으로
⊤
⊤에 머물러 결과가 공허해지기 쉬우며, 이는 디버깅의 본질상 의미 있는 초기화가 필요함을 시사한다. 배치 주석은 이러한 초기화 행위를 일관적이고 재현 가능한 형식으로 제공한다.

본 예제에서는 Listing \ref{lst:grammar-min}의 burn 함수에 다음과 같은 주석을 부여한다.
//@StateVar balances[msg.sender] = [100,200], //@LocalVar amount = [50,150].
초기 총발행량은 totalSupply = 1000으로 둔다. 이 선택은 조건 bal >= amount의 참·거짓 양 경로가 모두 실제로 도달 가능하도록 설계되어, 분기 프루닝과
합류 후 경계 변화가 어떻게 나타나는지를 명확히 보여준다.

주석 블록은 //@Debugging BEGIN … //@Debugging END 형태로 기술되며, 한 줄마다 “대상 L-값 ← 추상값(구간/심볼릭)”을 지정한다. 대상은
전역·상태·지역 변수를 포함하고, a[i].x, balances[addr]와 같은 중첩 L-값도 허용된다. 정수형은 선언된 비트폭에 맞춘 구간으로 정규화되고, 주소형은 160비트
비부호 구간, 불린은
{
0
,
1
}
{0,1}로 해석한다.

배치 주석이 주어지면 SolQDebug는 다음의 경량 파이프라인을 수행한다. (i) 각 주석 줄을 파싱해 심볼 해석과 타입 점검을 수행한다. (ii) 현재 추상 메모리를 스냅샷한
뒤, 주석으로 지정된 값들로 초기 환경을 오버레이한다. (iii) 함수 진입점에서 미리 구축된 CFG를 그대로 순회하며 한 번의 추상 해석을 수행한다. 이때 조건 노드는 술어만
기록하고 환경을 즉시 변경하지 않으며, 참/거짓 후속 블록이 생성될 때 각 경로 환경을 술어/부정 술어에 맞게 프루닝한다. 루프가 있는 경우에는 헤더에서 **국소
고정점(fixpoint)**을 계산한다. (iv) 분석이 끝나면 스냅샷을 복원하여 실행 간 격리를 보장한다. 이 일련의 과정은 Snapshot Manager가
관리한다.

이때 배치 주석은 CFG 구조를 변화시키지 않는다. 새로운 노드를 삽입하지 않고, 초기 환경만 변경한 뒤 동일 CFG를 재사용한다. 기본 블록은 자신이 담고 있는 문장 리스트와
"블록 끝 시점의 추상 환경(변수별 구간)"을 유지하므로 재평가가 빠르다. 조건 프루닝, 분기 합류 시 LUB(JoinBranches), 루프의 고정점 처리 규칙은 앞선
Source Code 예제(§3.2.1)와 동일하다. Figure \ref{fig:solqdebug-cfg}의 Pre‑built CFG 위에서, 배치 주석은 "진입 → 분기 프루닝
→ 합류 → 종료" 흐름을 그대로 따라 단일 패스로 재분석됨을 시각적으로 확인할 수 있다.


이 된다. 이와 같이, 분기별 제약을 반영한 프루닝과 합류 시의 최상한 조인을 통해, 간단한 구간 도메인만으로도 경계가 과도하게 팽창하지 않도록 억제하면서(예: 참 경로에서 bal
- amount의 음수 영역 제거), 두 경로의 효과를 보수적으로 통합할 수 있다.

컨테이너(배열·매핑·구조체)는 기본적으로 
⊤
⊤으로 유지하되, 접근 시점(on‑access) 또는 주석으로 특정 키/필드가 지정된 경우 해당 위치를 **구체화(concretize)**하여 해석한다. 본 예제의
balances[msg.sender]는 주석으로 키가 지정되었기 때문에 곧바로 구간 값이 부여되고, 이후 분기 본문과 합류에서 그 효과가 전파된다. 초기 총발행량
totalSupply와 같이 명시적 초기값이 주어진 상태변수는 고정 구간에서 출발하므로, 단일 대입만으로도 결과 경계가 직관적으로 해석된다.

정리하면, 배치 주석은 디버깅에서 필수적인 초기 상태 지정 행위를 간단한 주석 문법으로 표준화하여, 개발자가 의도한 입력 범위를 한 번에 탐색할 수 있게 한다. SolQDebug는
CFG를 재사용하고 단일 패스 재해석을 수행함으로써, 경량이면서도 의미론적으로 정합적인 결과를 제공한다. 자세한 형식적 정의와 알고리즘은 §3.3 및 §3.5에서 논의한다.
\end{comment}

Batch annotations provide a declarative way for developers to specify initial state and parameters
as symbolic (interval) values and to obtain line‑level results by reinterpreting the program in a
single pass over the already built CFG. In this work, “debugging” refers to the interactive
exploration during pre‑deployment editing in which the developer varies inputs (and state) to
observe branch reachability, guard validity, and value bounds. Consequently, variables that are not
given an initial range via annotations remain at the conservative \(\top\), which can make results
vacuous; this underscores the need for meaningful initialization in debugging. Batch annotations
supply this initialization in a consistent and reproducible form.

In the running example, we augment the function \texttt{burn} in Listing~\ref{lst:grammar-min} with
the following lines:
//@StateVar \texttt{balances[msg.sender]} = \([100,200]\) and //@LocalVar \texttt{amount} = \([50,
150]\).
We set the initial total supply to \(\textit{totalSupply} = 1000\). This choice makes the condition
\(\textit{bal} \ge \textit{amount}\) partially true, so both the then and else branches are
reachable; it thereby exposes how pruning at branches and joining after the conditional affect the
resulting bounds.

An annotation block is written between \verb|//@Debugging BEGIN| and \verb|//@Debugging END|, with
one directive per line of the form “target L‑value \(\leftarrow\) abstract value (interval or
symbolic).” Targets may be global, state, or local variables, and nested L‑values (e.g.,
\(\texttt{a[i].x}\), \(\texttt{balances[addr]}\)) are allowed. Integers are normalized to intervals
respecting their declared bit width; addresses are interpreted as 160‑bit unsigned intervals;
booleans as \(\{0,1\}\).

Given a batch block, \textsc{SolQDebug} executes a lightweight pipeline: (i) parse each line,
resolve symbols, and type‑check; (ii) snapshot the current abstract memory and overlay the initial
environment with the annotated values; (iii) traverse the existing CFG once from the function entry
and perform abstract interpretation; condition nodes record only the predicate and do not
immediately change the environment, while the true/false successor blocks refine (prune) their
incoming environments under the predicate and its negation; if loops are present, a localized
fixpoint is computed at the loop header; and (iv) restore the snapshot to guarantee isolation across
runs. This process is coordinated by the Snapshot Manager.

Importantly, batch annotations do not alter the CFG structure. No new nodes are inserted; only the
initial environment changes, and the same CFG is reused. Each basic block retains its statement list
and the abstract environment at the end of the block (interval per variable), enabling fast
reevaluation. The rules for branch pruning, least upper bound (LUB) at joins (JoinBranches), and
loop fixpoints are identical to those in the source‑code example (§3.2.1). On the pre‑built CFG in
Figure~\ref{fig:solqdebug-cfg}, a batch run proceeds "entry \(\rightarrow\) branch pruning
\(\rightarrow\) join \(\rightarrow\) exit" in a single pass.

The concrete effect of the above annotations is as follows. From the statement \(\textit{bal} =
\texttt{balances[msg.sender]}\) we obtain
\[
\textit{bal} \in [100,200], \qquad \textit{amount} \in [50,150].
\]
The guard \(\textit{bal} \ge \textit{amount}\) is only partially true, thus both branches are
reachable. After pruning, along the true branch the constraint \(\textit{bal} \ge \textit{amount}\)
raises the lower bound of \(\textit{bal} - \textit{amount}\) to \(0\), yielding
\[
\texttt{balances[msg.sender]} := \textit{bal} - \textit{amount} \;\Rightarrow\; [0,\,200-50] = [0,
150],
\qquad
\delta := \textit{amount} \;\Rightarrow\; [50,150].
\]
Along the false branch we only set \(\delta := 0\), and \(\texttt{balances[msg.sender]}\) remains at
its annotated initial range \([100,200]\). At the join we compute
\[
\delta \in [50,150] \sqcup [0,0] = [0,150], 
\qquad 
\texttt{balances[msg.sender]} \in [0,150] \sqcup [100,200] = [0,200].
\]
We then evaluate the assignment to the total supply once in the join environment. With
\(\textit{totalSupply} = [1000,1000]\) initially,
\[
\textit{totalSupply} -\!= \delta \;\Rightarrow\; [1000,1000] - [0,150] = [850,1000].
\]
Thus, by combining branch‑specific pruning with an LUB at the join, even a simple interval domain
avoids unnecessary blow‑up (e.g., the negative region of \(\textit{bal} - \textit{amount}\) is
eliminated on the true path) while conservatively aggregating the effects of both paths.

Containers (arrays, mappings, structs) are kept at \(\top\) by default and are concretized on access
or when a specific key/field is annotated. In our example, the mapping entry \(\texttt{balances[msg.
sender]}\) is concretized by the annotation, and its effects propagate through the branch body and
the join. State variables with explicit initial values, such as \(\textit{totalSupply}\), start from
a fixed interval, so a single assignment yields directly interpretable bounds.

In summary, batch annotations standardize the essential debugging act of initial state specification
via a simple comment syntax, enabling the developer to explore an intended input range in one shot.
\textsc{SolQDebug} reuses the CFG and performs a single‑pass reinterpretation, delivering
lightweight yet semantically sound results. Formal details and algorithms appear in §3.3 and §3.5.

\subsection{Interactive Parser}
The standard Solidity parser accepts only whole files (\texttt{sourceUnit} $\rightarrow$ \texttt{EOF}
) and thus rejects partial fragments produced during editing. \textsc{SolQDebug}'s interactive
parser chooses fragment-specific entry rules based on the current editing context and parses each
fragment into a syntactically well-formed subtree suitable for incremental analysis. The entry rules
fall into two groups: (A) rules for Solidity program fragments (functions, blocks, and other
constructs) and (B) rules for debugging-annotation blocks (\texttt{debugUnit}). We illustrate both
groups with representative inputs.

\subsubsection{Entry rules for Solidity program fragments}

\noindent\textbf{1) \texttt{interactiveSourceUnit} — top-level declaration fragments}
\begin{itemize}
  \item \emph{Purpose.} Accepts top-level snippets such as function headers with empty bodies, contracts, interfaces, libraries, pragmas, imports, and state variables. Editors typically auto-insert a closing brace when ``\{'' is typed, so a ``skeleton'' declaration arrives as two lines.
  \item \emph{Example (cf.\ Table~\ref{tab:input_code}, Step~1).}
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
function burn(uint256 amount) public onlyOwner {
}
\end{lstlisting}
  \emph{Selected entry:} \texttt{interactiveSourceUnit}.
  \emph{Internal match:} \texttt{interactiveFunctionElement} $\rightarrow$
  \texttt{functionDefinition}.
  \item \emph{Other top-level examples.}
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
contract Example {}
uint256 public totalSupply = 1000;
\end{lstlisting}
  \emph{Selected entry:} \texttt{interactiveSourceUnit} (matching \texttt{contractDefinition} /
  \texttt{stateVariableDeclaration}).
\end{itemize}

\noindent\textbf{2) \texttt{interactiveEnumUnit} — enum \emph{member} lists added incrementally}
\begin{itemize}
  \item \emph{Two-phase input.}
  \begin{enumerate}
    \item First, the empty enum \emph{shell} at top level:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
enum Status {}
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveSourceUnit}.
    \emph{Internal match:} \texttt{interactiveStateVariableElement} $\rightarrow$
    \texttt{interactiveEnumDefinition}.
    \item Then, members are supplied in subsequent fragments:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
Pending, Shipped
\end{lstlisting}
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
Delivered
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveEnumUnit}.
    \emph{Internal match:} \texttt{interactiveEnumItems}.
  \end{enumerate}
  \item \emph{Rationale.} The enum \emph{definition shell} and \emph{member items} are parsed by different entry rules, allowing members to be typed incrementally after the shell is present.
\end{itemize}

\noindent\textbf{3) \texttt{interactiveStructUnit} — struct \emph{member} declarations added
incrementally}
\begin{itemize}
  \item \emph{Two-phase input.}
  \begin{enumerate}
    \item First, the empty struct \emph{shell}:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
struct A {}
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveSourceUnit}.
    \emph{Internal match:} \texttt{interactiveStateVariableElement} $\rightarrow$
    \texttt{interactiveStructDefinition}.
    \item Then, members are added one line at a time:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
uint a;
address owner;
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveStructUnit}.
    \emph{Internal match:} \texttt{structMember}.
  \end{enumerate}
\end{itemize}

\noindent\textbf{4) \texttt{interactiveBlockUnit} — block-local statements and skeleton control
flow}
\begin{itemize}
  \item \emph{Purpose.} Accepts semicolon-terminated statements and fully-braced control-flow skeletons typed inside a block or function body.
  \item \emph{Examples (cf.\ Table~\ref{tab:input_code}, Steps~2,3,5,6,8,9).}
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
uint256 bal = balances[msg.sender];
uint256 delta;
balances[msg.sender] = bal - amount;
delta = amount;
delta = 0;
totalSupply -= delta;
\end{lstlisting}
  \emph{Selected entry:} \texttt{interactiveBlockUnit}.
  \emph{Internal match:} \texttt{interactiveBlockItem} $\rightarrow$ \texttt{interactiveStatement}
  $\rightarrow$ \texttt{interactiveSimpleStatement}.
  \item \emph{If-skeleton (cf.\ Table~\ref{tab:input_code}, Step~4).}
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
if (bal >= amount) {
}
\end{lstlisting}
  \emph{Selected entry:} \texttt{interactiveBlockUnit}.
  \emph{Internal match:} \texttt{interactiveBlockItem} $\rightarrow$ \texttt{interactiveIfStatement}
  .
\end{itemize}

\noindent\textbf{5) \texttt{interactiveDoWhileUnit} — the \emph{while-tail} of a \texttt{do\{...\}}
loop}
\begin{itemize}
  \item \emph{Two-phase input.}
  \begin{enumerate}
    \item First, the \texttt{do} body skeleton:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
do {
}
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveBlockUnit}.
    \emph{Internal match:} \texttt{interactiveBlockItem} $\rightarrow$
    \texttt{interactiveDoWhileDoStatement}.
    \item Then, the \texttt{while} tail is typed later:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
while (i < n);
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveDoWhileUnit}.
    \emph{Internal match:} \texttt{interactiveDoWhileWhileStatement}.
  \end{enumerate}
\end{itemize}

\noindent\textbf{6) \texttt{interactiveIfElseUnit} — \texttt{else} / \texttt{else if} tails}
\begin{itemize}
  \item \emph{Two-phase input.}
  \begin{enumerate}
    \item First, the \texttt{if} skeleton (as above, parsed by \texttt{interactiveBlockUnit}).
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
if (cond) {
}
\end{lstlisting}
    \item Then, the tail is added:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
else {
}
\end{lstlisting}
    or
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
else if (guard) {
}
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveIfElseUnit}.
    \emph{Internal match:} \texttt{interactiveElseStatement}.
  \end{enumerate}
  \item \emph{Context handling.} The parser uses the construct stack to attach the tail to the closest unmatched \texttt{if}, not merely the preceding line.
\end{itemize}

\noindent\textbf{7) \texttt{interactiveCatchClauseUnit} — \texttt{catch} clauses following a
\texttt{try}}
\begin{itemize}
  \item \emph{Two-phase input.}
  \begin{enumerate}
    \item First, the \texttt{try} skeleton:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
try doSomething() {
}
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveBlockUnit}.
    \emph{Internal match:} \texttt{interactiveTryStatement}.
    \item Then, one or more \texttt{catch} clauses:
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
catch {
}
\end{lstlisting}
    or
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
catch Error(string memory) {
}
\end{lstlisting}
    \emph{Selected entry:} \texttt{interactiveCatchClauseUnit}.
    \emph{Internal match:} \texttt{interactiveCatchClause}.
  \end{enumerate}
\end{itemize}

\noindent\textbf{Context-aware entry-rule selection}
\begin{itemize}
  \item \emph{Construct stack.} The context analyzer maintains a lightweight stack tracking:
    \begin{itemize}
      \item Current nesting: contract $\rightarrow$ function $\rightarrow$ block depth
      \item Unmatched constructs: open \texttt{if}, \texttt{do}, \texttt{try} awaiting their tails
    \end{itemize}
  \item \emph{Selection algorithm.}
    \begin{enumerate}
      \item Inspect stack top to determine enclosing context
      \item Match fragment's first token against candidate entry rules
      \item For two-phase constructs (enum/struct members, \texttt{else}, \texttt{catch}), check if corresponding shell exists
      \item Select the most specific rule; fall back to \texttt{interactiveSourceUnit} for top-level
    \end{enumerate}
  \item \emph{Consistency guarantee.}
    Each selected rule produces a syntactically well-formed subtree that can be spliced into the global AST/CFG without invalidating existing structure.
\end{itemize}

\subsubsection{Entry rules for debugging-annotation fragments}

\noindent\textbf{\texttt{debugUnit} — batch-annotation lines inside \texttt{//@Debugging} blocks}
\begin{itemize}
  \item \emph{Purpose.} Parses annotation lines that assign abstract values (intervals or symbolic tags) to designated variables, independent of Solidity AST completeness. Enables developers to specify initial states for interactive exploration without deploying contracts.

  \item \emph{Annotation types.}
    \begin{itemize}
      \item \texttt{@StateVar}: Assigns values to contract state variables and their nested elements (mappings, arrays, structs)
      \item \texttt{@LocalVar}: Assigns values to function parameters and local variables
    \end{itemize}

  \item \emph{Supported L-value patterns.}
    \begin{itemize}
      \item Simple variables: \texttt{amount}, \texttt{totalSupply}
      \item Array/mapping access: \texttt{balances[msg.sender]}, \texttt{arr[0]}
      \item Struct fields: \texttt{user.balance}, \texttt{data[key].field}
      \item Nested combinations: \texttt{a[i].x}, \texttt{m[addr].arr[j]}
    \end{itemize}

  \item \emph{Value specification syntax.}
    \begin{itemize}
      \item Integer intervals: \texttt{[100,200]} (normalized to declared bit width: \texttt{uint8} $\rightarrow$ \texttt{[0,255]}, \texttt{int256} $\rightarrow$ \texttt{[$-2^{255}$,$2^{255}$-1]})
      \item Address intervals: \texttt{[0x0,0xFFFF...FFFF]} (160-bit unsigned, clamped to valid range)
      \item Boolean intervals: \texttt{[0,1]} representing $\{\mathsf{true},\mathsf{false}\}$, or explicit \texttt{true}/\texttt{false}
      \item Symbolic values: \texttt{TOP} or omitted (defaults to $\top$, representing all possible values)
    \end{itemize}

  \item \emph{Block structure and examples.}
\begin{lstlisting}[language=Solidity,basicstyle=\ttfamily\small]
// @Debugging BEGIN
// @StateVar balances[msg.sender] = [100,200]
// @LocalVar amount = [50,150]
// @StateVar totalSupply = [1000,1000]
// @Debugging END
\end{lstlisting}
    Each directive occupies one line. Multiple directives are processed sequentially, building up the initial abstract environment before function reinterpretation begins.

  \item \emph{Selected entry:} \texttt{debugUnit}.

  \item \emph{Internal match:} \texttt{debugStateVar} / \texttt{debugLocalVar}.

  \item \emph{Error handling.}
    \begin{itemize}
      \item Type mismatches: Rejected with diagnostic (e.g., assigning string interval to \texttt{uint256})
      \item Undefined variables: Reported as parse errors referencing the annotation line
      \item Out-of-bounds intervals: Clamped to type's valid range with warning (e.g., \texttt{uint8} interval \texttt{[0,300]} $\rightarrow$ \texttt{[0,255]})
      \item Invalid L-values: Rejected if base container type does not support the access pattern
    \end{itemize}

  \item \emph{Integration with analysis pipeline.}
    The parsed annotations are consumed by the Snapshot Manager (§3.4.3) to overlay the initial abstract environment. The Abstract Interpreter (§3.5) then re-executes the function on the pre-built CFG without recompilation or deployment, producing line-level interval results under the specified initial conditions.
\end{itemize}

    \subsection{Dynamic CFG Construction}

This section explains how we dynamically extend the control‑flow graph while a user edits code. We
proceed in three steps. First, we construct and splice a CFG fragment for each statement form and
rewire only the neighborhood of the current node. Second, we locate the insertion site (the current
block) using a successor‑first, line‑aware selection strategy. Third, we re‑interpret only the
affected region after splicing to update abstract environments.

\subsubsection{Statement-Local, Incremental Construction}

We introduce the node kinds that make up the CFG, then show how each major statement is translated into a small CFG fragment and spliced locally. Every edit operates at an \textsc{insertion site}—the block immediately preceding the new fragment—without restructuring the rest of the graph.

\noindent\textbf{Node kinds.}
\begin{itemize}
  \item \textsc{basic node}: Holds exactly one statement (e.g., a variable declaration, an assignment, or a function call).
  \item \textsc{condition node}: Represents branching constructs such as \texttt{if}, \texttt{else if}, \texttt{while}, \texttt{require}/\texttt{assert}, and \texttt{try}.
  \item \textsc{return node}: A statement node whose outgoing edge is immediately rewired to the function's unique \textsc{return exit}.
  \item \textsc{error node}: The function's unique \textsc{error exit} (targets the exceptional path).
  \item \textsc{fixpoint evaluation node} (\(\phi\)): The loop join used for widening and narrowing.
  \item \textsc{loop exit node}: The false branch that leaves a loop.
\end{itemize}

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1cm,
  block/.style={rectangle, draw, thick, minimum width=2.5cm, minimum height=0.8cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[block, below=of current, fill=green!15] (new) {New Statement\\Node};
  \node[dots, below=of new] (succ) {...};

  \draw[->, thick] (current) -- node[right] {splice} (new);
  \draw[->, thick] (new) -- node[right] {reconnect} (succ);

  % Before state (left side)
  \node[block, left=3cm of current] (before_cur) {Current Node};
  \node[dots, below=of before_cur] (before_succ) {...};
  \draw[->, thick] (before_cur) -- (before_succ);

  \node[above=0.3cm of before_cur, font=\footnotesize\bfseries] {Before};
  \node[above=0.3cm of current, font=\footnotesize\bfseries] {After};
\end{tikzpicture}
\caption{Simple statement insertion. The builder creates one node and splices it between the current node and the original successors}
\label{fig:new-simple-statement}
\end{figure}

Figure~\ref{fig:new-simple-statement} shows a simple statement. The builder creates one
\textsc{basic node} and splices it between the current node and the original successors. Incoming
environment is copied from the current node; all outgoing edges of the current node are reattached
to the new basic node. We deliberately store \emph{exactly one} statement per basic node so that
mid‑line insertions become \(O(1)\) splices via the editor‑to‑CFG line map, without scanning or
splitting multi‑statement blocks.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1.2cm and 1.5cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  join/.style={rectangle, draw, thick, fill=yellow!20, minimum width=2cm, minimum height=0.6cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=of current, fill=green!15] (cond) {guard};
  \node[block, below left=of cond, fill=green!15] (true) {True\\Node};
  \node[block, below right=of cond, fill=green!15] (false) {False\\Node};
  \node[join, below=1.5cm of cond, fill=green!15] (join) {If Join};
  \node[dots, below=of join] (succ) {...};

  \draw[->, thick] (current) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (false);
  \draw[->, thick] (true) |- (join);
  \draw[->, thick] (false) |- (join);
  \draw[->, thick] (join) -- (succ);
\end{tikzpicture}
\caption{If statement insertion. The builder creates a \textsc{condition node}, two nodes for true/false arms, and an \textsc{if join}}
\label{fig:new-if}
\end{figure}

Figure~\ref{fig:new-if} shows an \texttt{if}. The builder inserts a \textsc{condition node} for the
guard, two \textsc{basic nodes} for the true/false arms, and an \textsc{if join}. Edges: current
\(\rightarrow\) condition; condition \(\rightarrow\) true basic (true edge) and \(\rightarrow\)
false basic (false edge); both basics \(\rightarrow\) if join; the if join reconnects to the
original successors. Environments on the two edges are refined by the truth value of the guard.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1.2cm and 2cm,
  block/.style={rectangle, draw, thick, minimum width=1.8cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.3cm, align=center, font=\footnotesize},
  join/.style={rectangle, draw, thick, fill=yellow!20, minimum width=1.8cm, minimum height=0.6cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=1cm of current] (if_cond) {if guard};
  \node[block, below left=1.2cm and 2.2cm of if_cond] (if_true) {If True\\Node};
  \node[dots, below=0.6cm of if_true] (if_dots) {...};

  % else-if branch (highlighted)
  \node[cond, below right=1.2cm and 2.2cm of if_cond, fill=green!15] (elif_cond) {else-if\\guard};
  \node[block, below left=1cm and 1.5cm of elif_cond, fill=green!15] (elif_true) {Else-If\\True Node};
  \node[block, below right=1cm and 1.5cm of elif_cond, fill=green!15] (elif_false) {Else-If\\False Node};

  \node[join, below=2.5cm of elif_cond, fill=green!15] (elif_join) {Else-If Join};
  \node[join, below=4.5cm of if_cond] (if_join) {If Join};
  \node[dots, below=0.6cm of if_join] (succ) {...};

  \draw[->, thick] (current) -- (if_cond);
  \draw[->, thick] (if_cond) -- ++(-2.2,-0.8) -- node[above left, pos=0.1] {T} (if_true);
  \draw[->, thick] (if_cond) -- ++(2.2,-0.8) -- node[above right, pos=0.1] {F} (elif_cond);
  \draw[->, thick] (elif_cond) -| node[above left, pos=0.25] {T} (elif_true);
  \draw[->, thick] (elif_cond) -| node[above right, pos=0.25] {F} (elif_false);
  \draw[->, thick] (if_dots) -- ++(0,-1.5) -| (if_join);
  \draw[->, thick] (elif_true) |- (elif_join);
  \draw[->, thick] (elif_false) |- (elif_join);
  \draw[->, thick] (elif_join) |- (if_join);
  \draw[->, thick] (if_join) -- (succ);
\end{tikzpicture}
\caption{Else-if statement insertion. The builder replaces the false arm with a new \textsc{condition node}, two nodes, and an \textsc{else-if join}}
\label{fig:new-else-if}
\end{figure}

Figure~\ref{fig:new-else-if} shows an \texttt{else if}. The builder removes the previously created
false arm of the nearest preceding \texttt{if}/\texttt{else if} at the same nesting depth and
splices a fragment consisting of a new \textsc{condition node}, two \textsc{basic nodes}, and an
\textsc{else‑if join}. The else‑if join is connected to the existing \textsc{if join} so the overall
shape remains a single diamond toward the if join.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1.2cm and 2cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  join/.style={rectangle, draw, thick, fill=yellow!20, minimum width=2cm, minimum height=0.6cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=1cm of current] (cond) {guard};
  \node[block, below left=1.2cm and 2cm of cond] (true) {True\\Node};
  \node[dots, below=0.6cm of true] (true_dots) {...};
  \node[block, below right=1.2cm and 2cm of cond, fill=green!15] (else) {Else\\Node};
  \node[dots, below=0.6cm of else] (else_dots) {...};
  \node[join, below=3.5cm of cond] (join) {If Join};
  \node[dots, below=0.6cm of join] (succ) {...};

  \draw[->, thick] (current) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (else);
  \draw[->, thick] (true) -- (true_dots);
  \draw[->, thick] (else) -- (else_dots);
  \draw[->, thick] (true_dots) -- ++(0,-0.5) -| (join);
  \draw[->, thick] (else_dots) -- ++(0,-0.5) -| (join);
  \draw[->, thick] (join) -- (succ);
\end{tikzpicture}
\caption{Else statement insertion. The builder attaches a node to the false branch of the corresponding \texttt{if}/\texttt{else if}, connecting to the \textsc{if join}}
\label{fig:new-else}
\end{figure}

Figure~\ref{fig:new-else} shows an \texttt{else}. No new condition is created; the builder attaches
a \textsc{basic node} to the false branch of the corresponding \texttt{if}/\texttt{else if} and
connects it to the same \textsc{if join} as the true branch. The figure assumes a canonical
\texttt{if}/\texttt{else if}/\texttt{else} chain. For nested patterns (e.g., \texttt{if \{ if \{\}
else \{\} \}}), the else attaches to the false arm of its matching guard according to standard block
matching.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1cm and 2.2cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  phi/.style={circle, draw, thick, fill=blue!15, minimum size=1cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[phi, below=1cm of current, fill=green!15] (phi) {$\phi$};
  \node[cond, below=1cm of phi, fill=green!15] (cond) {guard};
  \node[block, below left=1.2cm and 2.2cm of cond, fill=green!15] (body) {Body\\Entry Node};
  \node[dots, below=0.6cm of body] (body_dots) {...};
  \node[block, below right=1.2cm and 2.2cm of cond, fill=green!15] (exit) {Loop\\Exit Node};
  \node[dots, below=0.6cm of exit] (succ) {...};

  \draw[->, thick] (current) -- (phi);
  \draw[->, thick] (phi) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (body);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (exit);
  \draw[->, thick, dashed] (body_dots) -- ++(-1.5,0) |- node[left, pos=0.85] {back edge} (phi);
  \draw[->, thick] (exit) -- (succ);
\end{tikzpicture}
\caption{While loop insertion. The builder creates a \textsc{fixpoint evaluation node} $\phi$, a \textsc{condition node}, a loop body node, and a \textsc{loop exit node}}
\label{fig:new-while}
\end{figure}

Figure~\ref{fig:new-while} shows a \texttt{while}. The builder creates a \textsc{fixpoint evaluation
node} \(\phi\), a \textsc{condition node}, a true‑arm \textsc{basic node} as the loop‑body entry,
and a \textsc{loop exit node} (false arm). Rewiring: current \(\rightarrow \phi \rightarrow\)
condition; condition(true) \(\rightarrow\) body; body \(\rightarrow \phi\) (back edge);
condition(false) \(\rightarrow\) loop exit; the loop exit reconnects to the original successors. The
\(\phi\) node stores both the pre‑loop baseline and the running snapshot for widening/narrowing.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1cm and 2.5cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.3cm, align=center, font=\footnotesize},
  phi/.style={circle, draw, thick, fill=blue!15, minimum size=0.8cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[phi] (phi) {$\phi$};
  \node[cond, below=0.8cm of phi] (cond) {guard};
  \node[block, below left=1cm and 2cm of cond] (body) {Body Node};
  \node[dots, below=0.5cm of body] (body_dots) {...};
  \node[block, below=0.5cm of body_dots, fill=green!15] (break) {\texttt{break}};
  \node[block, below right=1cm and 2cm of cond] (exit) {Loop\\Exit Node};
  \node[dots, below=0.5cm of exit] (succ) {...};

  \draw[->, thick] (phi) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.2] {T} (body);
  \draw[->, thick] (cond) -| node[above right, pos=0.2] {F} (exit);
  \draw[->, thick] (body) -- (body_dots);
  \draw[->, thick] (body_dots) -- (break);
  \draw[->, thick, dashed] (body_dots) -- ++(-1.2,0) |- node[left, pos=0.8] {back} (phi);
  \draw[->, thick] (break) -| node[above right, pos=0.6] {redirect} (exit);
  \draw[->, thick] (exit) -- (succ);
\end{tikzpicture}
\caption{Break statement insertion. The \texttt{break} node's outgoing edge is redirected to the \textsc{loop exit node}}
\label{fig:new-break}
\end{figure}

Figure~\ref{fig:new-break} shows a \texttt{break}. The statement becomes a \textsc{basic node} whose
outgoing edge is redirected to the \textsc{loop exit node}. The loop exit's environment is
conservatively joined with the environment at the break site.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1cm and 2.5cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.3cm, align=center, font=\footnotesize},
  phi/.style={circle, draw, thick, fill=blue!15, minimum size=0.8cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[phi] (phi) {$\phi$};
  \node[cond, below=0.8cm of phi] (cond) {guard};
  \node[block, below left=1cm and 2cm of cond] (body) {Body Node};
  \node[dots, below=0.5cm of body] (body_dots) {...};
  \node[block, below=0.5cm of body_dots, fill=green!15] (continue) {\texttt{continue}};
  \node[dots, below=0.5cm of continue, gray] (unreachable) {...};
  \node[block, below right=1cm and 2cm of cond] (exit) {Loop\\Exit Node};

  \draw[->, thick] (phi) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.2] {T} (body);
  \draw[->, thick] (cond) -| node[above right, pos=0.2] {F} (exit);
  \draw[->, thick] (body) -- (body_dots);
  \draw[->, thick] (body_dots) -- (continue);
  \draw[->, thick, dashed, gray] (continue) -- (unreachable);
  \draw[->, thick, dashed] (continue) -| ++(2,0) |- node[right, pos=0.3] {redirect} (phi);
\end{tikzpicture}
\caption{Continue statement insertion. The \texttt{continue} node's outgoing edge is redirected to the loop's \textsc{fixpoint evaluation node} $\phi$}
\label{fig:new-continue}
\end{figure}

Figure~\ref{fig:new-continue} shows a \texttt{continue}. The statement becomes a \textsc{basic node}
whose outgoing edge is redirected to the loop's \textsc{fixpoint evaluation node} \(\phi\).
Operationally, this keeps the back‑edge shape and joins the current environment into the loop's join
state.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  exit/.style={rectangle, draw, thick, rounded corners, fill=red!15, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[block, below=of current, fill=green!15] (return) {\texttt{return}\\Node};
  \node[exit, below right=0.5cm and 2cm of return] (exit) {RETURN\\EXIT};
  \node[dots, below left=0.5cm and 0.5cm of return] (detached) {...};

  \draw[->, thick] (current) -- (return);
  \draw[->, thick, bend left=15] (return) to node[above right] {rewire} (exit);
  \draw[->, thick, dashed, gray] (return) -- node[left, gray] {detached} (detached);
\end{tikzpicture}
\caption{Return statement insertion. The \texttt{return} node is rewired to the function's unique \textsc{return exit}}
\label{fig:new-return}
\end{figure}

Figure~\ref{fig:new-return} shows a \texttt{return}. The statement becomes a \textsc{return node}
and is immediately rewired to the function's unique \textsc{return exit}; the return value is
recorded there and the original successors of the current node are detached.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
  node distance=1cm and 2cm,
  block/.style={rectangle, draw, thick, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  cond/.style={diamond, draw, thick, aspect=2, minimum width=1.5cm, align=center, font=\footnotesize},
  exit/.style={rectangle, draw, thick, rounded corners, fill=red!15, minimum width=2cm, minimum height=0.7cm, align=center, font=\footnotesize},
  dots/.style={circle, draw=none, minimum size=0.3cm}
]
  \node[block] (current) {Current Node};
  \node[cond, below=of current, fill=green!15] (cond) {predicate};
  \node[block, below left=of cond, fill=green!15] (true) {True\\Node};
  \node[exit, below right=of cond] (error) {ERROR\\EXIT};
  \node[dots, below=of true] (succ) {...};

  \draw[->, thick] (current) -- (cond);
  \draw[->, thick] (cond) -| node[above left, pos=0.3] {T} (true);
  \draw[->, thick] (cond) -| node[above right, pos=0.3] {F} (error);
  \draw[->, thick] (true) -- (succ);
\end{tikzpicture}
\caption{Require/assert statement insertion. The builder creates a \textsc{condition node} with true edge to a node and false edge to the \textsc{error exit}}
\label{fig:new-require}
\end{figure}

Figure~\ref{fig:new-require} shows \texttt{require}/\texttt{assert}. The builder inserts a
\textsc{condition node} for the predicate, makes the true edge point to a \textsc{basic node}, and
connects the false edge directly to the function's \textsc{error exit}. The true basic then
reconnects to the original successors, forming a one‑sided diamond.

\noindent\textbf{Other constructs.} Similar patterns apply to the remaining control-flow constructs:
\begin{itemize}
  \item \texttt{for} loops: Handled as a \(\phi\) node and condition like \texttt{while}, optionally preceded by an initialization node and followed by an increment node on the back edge.
  \item \texttt{do\{\} while}: Built in two steps. First, a body pair is created and closed. Later, the trailing \texttt{while} line attaches a \(\phi\), condition, and loop exit, and wires the back edge to the existing body.
  \item \texttt{try\{\} catch\{\}}: Represented by a \textsc{condition node} tagged as \texttt{try} whose true edge goes to the success block and whose false edge is replaced by a catch entry/end pair when a matching \texttt{catch} appears.
\end{itemize}


        \subsubsection{Line-Aware Successor-First Insertion-Site Selection}

We keep a lightweight line–to–node index to make insertion local. Each newly created node is
attached to one or two source lines depending on whether the construct is single‑line (terminated by
";") or brace‑delimited. This index is used only to locate the insertion site; the algorithm below does not mutate the graph.

\noindent\textbf{Line-to-node index mapping.}
We attach each CFG node to source lines based on the statement type:
\begin{itemize}
  \item \textbf{Sequential statements} (variable declaration, assignment, function call, unary operations): Index the statement block at its source line.
  \item \textbf{Conditional branches} (\texttt{if}/\texttt{else if}): Index the condition node at the guard line and the join node at the closing brace line.
  \item \textbf{Else branches}: Index the else block at the \texttt{else} line and reuse the preceding guard's join node.
  \item \textbf{Loops} (\texttt{while}/\texttt{for}): Index the condition node at the guard line and the loop-exit node at the closing brace line.
  \item \textbf{Loop control} (\texttt{continue}/\texttt{break}): Index the statement block at its source line.
  \item \textbf{Terminating statements} (\texttt{return}/\texttt{revert}): \texttt{return} creates a new block; \texttt{revert} uses the current block directly.
  \item \textbf{Assertions} (\texttt{require}/\texttt{assert}): Index the condition node at the statement line.
  \item \textbf{Exception handling} (\texttt{try}/\texttt{catch}): Index the try condition at the \texttt{try} line and catch entry at the \texttt{catch} line.
\end{itemize}


\begin{algorithm}[!t]
\caption{Branch-Context Insertion-Site Selection (\textsc{GetBranchContext})}
\label{alg:get-branch-context}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$, edit context $\mathit{ctx}\in\{\texttt{else\_if},\texttt{else},\texttt{catch}\}$, current line $L$
\Ensure Condition node $c\in V$ (and optionally outer join $j\in V$ for \texttt{else\_if}/\texttt{else})
\State $N \gets \textsc{NodesAtLine}(L)$ \Comment{all CFG nodes indexed at line $L$}
\If{$N=\emptyset$} \State $N \gets \textsc{NodesAtPreviousLine}(L)$ \Comment{search backward if $L$ is empty} \EndIf
\State $j_{\mathit{outer}} \gets \bot$
\If{$\mathit{ctx}\in\{\texttt{else\_if},\texttt{else}\}$}
  \For{$n\in N$}
    \If{$\mathsf{isJoin}(n)$} \State $j_{\mathit{outer}} \gets n$ \textbf{ break} \Comment{outer join at current line} \EndIf
  \EndFor
\EndIf

\State $\mathit{Queue} \gets N$; $\mathit{Visited} \gets \emptyset$ \Comment{BFS through predecessors}
\While{$\mathit{Queue}\neq\emptyset$}
  \State $n \gets \textsc{Dequeue}(\mathit{Queue})$
  \If{$n\in\mathit{Visited}$} \textbf{continue} \EndIf
  \State $\mathit{Visited} \gets \mathit{Visited}\cup\{n\}$

  \If{$\mathsf{isCond}(n)$}
    \State $\tau \gets \textsc{CondType}(n)$ \Comment{type: \texttt{if}, \texttt{else\_if}, \texttt{try}, etc.}
    \If{$\mathit{ctx}\in\{\texttt{else\_if},\texttt{else}\}$ \textbf{and} $\tau\in\{\texttt{if},\texttt{else\_if}\}$}
      \If{$j_{\mathit{outer}}=\bot$} \State $j_{\mathit{outer}} \gets \textsc{OuterJoinFromGraph}(n)$ \Comment{fallback} \EndIf
      \State \Return $(n,\, j_{\mathit{outer}})$
    \ElsIf{$\mathit{ctx}=\texttt{catch}$ \textbf{and} $\tau=\texttt{try}$}
      \State \Return $n$
    \EndIf
  \EndIf

  \For{$p\in\textsc{Predecessors}(n)$}
    \If{$p\notin\mathit{Visited}$} \State $\textsc{Enqueue}(\mathit{Queue},p)$ \EndIf
  \EndFor
\EndWhile

\State \textbf{error} ``No matching condition node found for context $\mathit{ctx}$''
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!t]
\caption{Successor-First Insertion-Site Selection (\textsc{GetInsertionSite})}
\label{alg:get-insertion-site}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$, edit span ending at line $L$
\Ensure Insertion-site node $A\in V$ (no graph mutation here)
\State $s \gets \textsc{FirstNodeAfter}(L)$ \Comment{scan lines $>L$ until the first indexed node}
\If{$s=\bot$} \State $s\gets \textsf{EXIT}$ \EndIf
\State $\ell \gets \textsc{LineOf}(s)$

\If{$\mathsf{isLoopExit}(s)$} \Comment{closing a loop}
  \State $N_{\mathit{prev}} \gets \textsc{NodesAtPreviousLine}(L)$ \Comment{search backward from $L$ to find previous nodes}
  \If{$N_{\mathit{prev}}\neq\emptyset$}
    \State $c \gets \textsc{LastCondInNodes}(N_{\mathit{prev}})$ \Comment{check if previous line has a condition}
    \If{$c\neq\bot$}
       \State \Return $\textsc{BranchBlock}(c,\mathsf{true})$ \Comment{insert in TRUE branch (loop body)}
    \Else
       \State \Return $\textsc{Last}(N_{\mathit{prev}})$ \Comment{last node of previous line}
    \EndIf
  \Else
    \State \Return $\textsc{FirstPredecessor}(s)$ \Comment{fallback}
  \EndIf

\ElsIf{$\mathsf{isJoin}(s)$} \Comment{closing a selection}
  \State $N_{\mathit{prev}} \gets \textsc{NodesAtPreviousLine}(L)$
  \If{$N_{\mathit{prev}}\neq\emptyset$}
    \State $c \gets \textsc{LastCondInNodes}(N_{\mathit{prev}})$
    \If{$c\neq\bot$}
       \State \Return $\textsc{BranchBlock}(c,\mathsf{true})$ \Comment{default to TRUE branch for \texttt{if}}
    \Else
       \State \Return $\textsc{Last}(N_{\mathit{prev}})$
    \EndIf
  \Else
    \State \Return $\textsc{FirstPredecessor}(s)$
  \EndIf

\Else \Comment{basic successor}
  \State $\mathit{Pred} \gets \textsc{Predecessors}(s)$
  \If{$|\mathit{Pred}|=1$} \State \Return the unique element of $\mathit{Pred}$
  \Else \State \Return $\textsc{NearestByLine}(\mathit{Pred},\,L)$ \Comment{choose closest to current line $L$}
  \EndIf
\EndIf
\end{algorithmic}
\end{algorithm}

We dispatch insertion-site selection based on the edit context:
\begin{itemize}
  \item \textbf{Branch contexts} (\texttt{else}/\texttt{else if}/\texttt{catch}) use Algorithm~\ref{alg:get-branch-context} to find the preceding condition node by traversing predecessors.
  \item \textbf{Regular statements} use Algorithm~\ref{alg:get-insertion-site}, which employs a \textsc{successor-first} strategy: locate the earliest CFG node after the edit span and determine the most local predecessor.
\end{itemize}
Both algorithms never mutate the graph and rely solely on the line--to--node index for efficient lookup.

\noindent\textbf{Algorithm~\ref{alg:get-branch-context}: Branch-Context Insertion.}
For \texttt{else}/\texttt{else if}/\texttt{catch}, we must attach the new branch to a previously created condition node. The algorithm:
\begin{itemize}
  \item \textbf{Line 1--4:} Retrieves CFG nodes at the current line \(L\) (or searches backward if \(L\) is empty). For \texttt{else\_if}/\texttt{else}, it also identifies the outer join node at \(L\), if present.
  \item \textbf{Line 9--24:} Performs BFS through CFG predecessors to find the matching condition node: for \texttt{else\_if}/\texttt{else}, it looks for a node of type \texttt{if} or \texttt{else\_if}; for \texttt{catch}, it looks for type \texttt{try}.
  \item \textbf{Line 11--12:} When the matching condition is found for \texttt{else\_if}/\texttt{else}, the algorithm returns both the condition node and the outer join (if the outer join was not found at line \(L\), a fallback uses the graph structure).
\end{itemize}

\noindent\textbf{Algorithm~\ref{alg:get-insertion-site}: Successor-First Insertion.}
For regular statements, we look ahead to determine the insertion site:
\begin{itemize}
  \item \textbf{Line 1--3:} \textsc{FirstNodeAfter}(\(L\)) scans lines strictly larger than \(L\) in the line--to--node index and returns the first node; if none is found, we default to \texttt{EXIT}.
  \item \textbf{Line 5--14 (loop-exit):} If the successor \(s\) is a loop-exit node, we search backward from \(L\) to find the previous line's nodes. If the previous line contains a condition node (the loop header), we return its TRUE branch (the loop body entry); otherwise, we return the last node of the previous line.
  \item \textbf{Line 16--23 (join):} If \(s\) is a join node (closing a selection), we apply the same backward search. If a condition node is found, we return its TRUE branch (default for \texttt{if} constructs); otherwise, return the last previous node.
  \item \textbf{Line 25--28 (basic successor):} If \(s\) is a regular basic node, we return its unique predecessor, or choose the predecessor closest to line \(L\) if multiple exist.
\end{itemize}

\noindent\textbf{Helper functions.}
\begin{itemize}
  \item \textsc{NodesAtLine}(\(L\)) / \textsc{NodesAtPreviousLine}(\(L\)): Return all CFG nodes indexed at line \(L\) or the first non-empty line before \(L\).
  \item \textsc{FirstNodeAfter}(\(L\)): Returns the first CFG node indexed at any line \(>L\).
  \item \textsc{LastCondInNodes}(\(N\)): Scans node list \(N\) in reverse to find the last condition node.
  \item \textsc{BranchBlock}(\(c,t\)): Returns the successor of condition \(c\) along the edge labeled with truth value \(t\).
  \item \textsc{OuterJoinFromGraph}(\(c\)): Walks the graph from condition \(c\) through its TRUE branch to find the join node.
  \item \textsc{NearestByLine}(\(X,\ell\)): Returns \(\arg\min_{x\in X} \lvert \textsc{LineOf}(x)-\ell \rvert\).
  \item \textsc{Predecessors}(\(s\)), \textsc{FirstPredecessor}(\(s\)): Standard CFG predecessor queries.
\end{itemize}

        
        \subsubsection{Abstract Interpretation for Incremental Analysis}

Our system handles two types of edits during interactive debugging, each triggering a different analysis strategy. Debug annotation input follows a batch-and-flush pattern: annotations are accumulated and processed together, culminating in a full interpretation of the entire function CFG from \texttt{ENTRY} to \texttt{EXIT} (Algorithm~\ref{alg:interpret-full}). This ensures that all annotated inspection points receive freshly computed abstract states. In contrast, source code edits---such as inserting \texttt{require}, assignments, or control structures---are processed immediately: dynamic CFG construction (Algorithms~\ref{alg:get-branch-context} and~\ref{alg:get-insertion-site}) splices the new nodes into the graph, and change-driven reinterpretation (Algorithm~\ref{alg:reinterpret}) propagates updates only along affected paths, providing instant feedback without re-analyzing the entire function. Both strategies invoke the same loop fixpoint subroutine (Algorithm~\ref{alg:fixpoint}) when encountering loop headers.



\begin{algorithm}[!htbp]
\caption{Initial Function Interpretation (\textsc{InterpretFunctionCFG})}
\label{alg:interpret-full}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$ with designated \texttt{ENTRY} node
\Ensure All nodes have computed abstract environments
\State $\textit{WL}\gets\langle\texttt{ENTRY}\rangle$; \quad $\textit{inQ}\gets\{\texttt{ENTRY}\}$; \quad $\textit{Out}\gets$ snapshot map

\While{$\textit{WL}\neq\langle\rangle$}
  \State $n \gets \textit{WL}.\textsf{pop}()$; \quad $\textit{inQ}\gets \textit{inQ}\setminus\{n\}$
  \State $\hat{\sigma}_{in}\gets\bot$ \Comment{compute incoming environment from all predecessors}
  \ForAll{$p\in\textsc{Predecessors}(n)$}
     \State $\sigma_p \gets \Env(p)$
     \If{$\mathsf{isCond}(p)\ \land\ \mathsf{hasTruthLabel}(p{\to}n)$}
        \State $t \gets \textsf{edgeLabel}(p{\to}n)$
        \State $\sigma_p \gets \textsc{Refine}(\sigma_p,p.\textsf{cond},t)$
        \If{$\neg\textsc{Feasible}(\sigma_p,p.\textsf{cond},t)$} \State $\sigma_p \gets \bot$ \EndIf
     \EndIf
     \State $\hat{\sigma}_{in}\gets \hat{\sigma}_{in}\ \sqcup\ \sigma_p$
  \EndFor

  \If{$\mathsf{isLoopHeader}(n)$}
     \State $\textit{exitNode} \gets \textsc{Fixpoint}(n)$ \Comment{Algorithm~\ref{alg:fixpoint}}
     \ForAll{$u\in \Succ(\textit{exitNode})$}
       \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
     \State \textbf{continue}
  \EndIf

  \State $\hat{\sigma}_{out}\gets \textsc{Transfer}(n,\hat{\sigma}_{in})$
  \If{$\hat{\sigma}_{out}\neq \textit{Out}[n]$}
     \State $\Env(n)\gets \hat{\sigma}_{out}$; \quad $\textit{Out}[n]\gets \hat{\sigma}_{out}$
     \ForAll{$u\in \Succ(n)$}
        \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
  \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!htbp]
\caption{Change-Driven Reinterpretation (\textsc{ReinterpretFrom})}
\label{alg:reinterpret}
\begin{algorithmic}[1]
\Require CFG $G=(V,E)$; seed set $S$ returned by the builder
\Ensure Environments updated along forward-reachable paths from $S$
\State $\textit{WL}\gets\langle\rangle$; \quad $\textit{inQ}\gets\emptyset$; \quad $\textit{Out}\gets$ snapshot map
\ForAll{$s\in S$} \Comment{filter and enqueue all non-sink seeds}
  \If{$\neg\mathsf{isSink}(s)\ \land\ s\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(s)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{s\}$ \EndIf
\EndFor

\While{$\textit{WL}\neq\langle\rangle$}
  \State $n \gets \textit{WL}.\textsf{pop}()$; \quad $\textit{inQ}\gets \textit{inQ}\setminus\{n\}$
  \State $\hat{\sigma}_{in}\gets\bot$ \Comment{compute incoming environment from all predecessors}
  \ForAll{$p\in\textsc{Predecessors}(n)$}
     \State $\sigma_p \gets \Env(p)$
     \If{$\mathsf{isCond}(p)\ \land\ \mathsf{hasTruthLabel}(p{\to}n)$} \Comment{refine by condition}
        \State $t \gets \textsf{edgeLabel}(p{\to}n)$
        \State $\sigma_p \gets \textsc{Refine}(\sigma_p,p.\textsf{cond},t)$ \Comment{apply path constraint}
        \If{$\neg\textsc{Feasible}(\sigma_p,p.\textsf{cond},t)$} \State $\sigma_p \gets \bot$ \EndIf \Comment{prune infeasible}
     \EndIf
     \State $\hat{\sigma}_{in}\gets \hat{\sigma}_{in}\ \sqcup\ \sigma_p$
  \EndFor

  \If{$\mathsf{isLoopHeader}(n)$} \Comment{handle loop by local fixpoint}
     \State $\textit{exitNode} \gets \textsc{Fixpoint}(n)$ \Comment{compute fixpoint; returns loop-exit node}
     \ForAll{$u\in \Succ(\textit{exitNode})$}
       \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
     \State \textbf{continue} \Comment{skip standard transfer for loop header}
  \EndIf

  \State $\hat{\sigma}_{out}\gets \textsc{Transfer}(n,\hat{\sigma}_{in})$ \Comment{apply statement effects}
  \If{$\hat{\sigma}_{out}\neq \textit{Out}[n]$} \Comment{change detected}
     \State $\Env(n)\gets \hat{\sigma}_{out}$; \quad $\textit{Out}[n]\gets \hat{\sigma}_{out}$
     \ForAll{$u\in \Succ(n)$}
        \If{$\neg\mathsf{isSink}(u)\ \land\ u\notin \textit{inQ}$} \State $\textit{WL}.\textsf{enqueue}(u)$; \quad $\textit{inQ}\gets\textit{inQ}\cup\{u\}$ \EndIf
     \EndFor
  \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:interpret-full} performs initial interpretation when debug annotations are first introduced to a function. It begins with the \texttt{ENTRY} node enqueued and propagates abstract environments forward through the entire CFG using a standard worklist iteration. Algorithm~\ref{alg:reinterpret}, in contrast, handles source code edits: the dynamic CFG builder returns one or more seed nodes (never sinks) that mark the insertion points, and the algorithm propagates updates only along forward-reachable paths from these seeds. The choice of seed depends on the statement type: sequential statements (\texttt{assignment}, \texttt{function call}) seed at the newly inserted block; control-flow constructs (\texttt{if}/\texttt{while}/\texttt{for}) seed at their join or loop-exit node to capture all downstream effects; terminating statements (\texttt{return}/\texttt{revert}) seed at the original successors before rewiring; and assertions (\texttt{require}/\texttt{assert}) seed at the true-branch successor. Seeds corresponding to sink nodes (\texttt{EXIT}, \texttt{ERROR}, \texttt{RETURN}) are filtered out because they contribute nothing to downstream analysis.

Both algorithms share the same core iteration structure. Each node computes its incoming environment $\hat{\sigma}_{in}$ by joining all predecessor flows. For predecessors that are condition nodes, we apply path-sensitive refinement: the environment is updated according to the condition and the edge's truth label (true or false), and infeasible branches---where the refined environment contradicts the guard---are pruned by setting $\sigma_p$ to $\bot$. This ensures that only feasible execution paths contribute to the analysis.

Loop headers receive special treatment in both algorithms. When the worklist reaches a loop header, we invoke a dedicated fixpoint procedure (Algorithm~\ref{alg:fixpoint}) that recomputes abstract states for the entire loop body using widening and narrowing. The fixpoint returns the loop-exit node, whose successors are then enqueued for further propagation. This design localizes loop effects: in Algorithm~\ref{alg:reinterpret}, any edit inside a loop body naturally triggers a fresh fixpoint once the header is encountered, without requiring the builder to seed every loop-internal change explicitly.

The change guard mechanism is critical for efficiency. After computing the transfer function's result $\hat{\sigma}_{out}$, we compare it with the previous snapshot $\textit{Out}[n]$. Only when a change is detected do we update the node's environment, refresh the snapshot, and enqueue non-sink successors. This guarantees termination and avoids redundant work: if downstream nodes remain unaffected, propagation halts. Crucially, it does not miss any updates, because any upstream alteration that modifies a node's input will also alter its output (even for identity transfers on join or condition nodes), thus triggering further propagation.

\begin{algorithm}[!htbp]
\footnotesize
\caption{Loop Fixpoint at Header}
\label{alg:fixpoint}
\begin{algorithmic}[1]
\Require loop header (condition) node $h$
\Ensure Converged abstract environments at the loop exit and inside the loop
\State $\mathit{L} \gets \textsc{TraverseLoopNodes}(h)$ \Comment{nodes dominated by $h$ and on some back-edge to $h$}
\State $\textit{vis}[\cdot]\gets 0$;\quad $\textit{In}[\cdot],\textit{Out}[\cdot]\gets \bot$
\State $\textit{Start} \gets \bigsqcup\{\Env(p)\mid p\in\Pred(h)\setminus \mathit{L}\}$ \Comment{pre-loop env (exclude back-edges)}
\State $\textit{In}[h]\gets \textit{Start}$
\State $\tau \gets \textsc{EstimateIterations}(h,\textit{Start})$ \Comment{visit threshold for widening}
\Statex
\State \textbf{// Widening phase (ascending)}
\State $\mathit{WL}\gets \langle h\rangle$
\While{$\mathit{WL}\neq\langle\rangle$}
  \State $n\gets \mathit{WL}.\textsf{pop}()$;\quad $\textit{vis}[n]\gets \textit{vis}[n]+1$
  \State $\hat{o}\gets \textsc{Transfer}(n,\textit{In}[n])$
  \If{$\textsc{IsJoin}(n)\ \land\ \textit{vis}[n] > \tau$}
     \State $\hat{o}\gets \textsc{Widen}(\textit{Out}[n],\hat{o})$
  \Else
     \State $\hat{o}\gets \textit{Out}[n]\sqcup \hat{o}$
  \EndIf
  \If{$\textsc{IsJoin}(n)\ \land\ \textsc{CondConverged}(n)$} \Comment{optional early stop}
     \State $\textit{Out}[n]\gets \hat{o}$;\quad \textbf{break}
  \EndIf
  \If{$\hat{o}\neq \textit{Out}[n]$}
     \State $\textit{Out}[n]\gets \hat{o}$
     \ForAll{$s\in \Succ(n)\cap \mathit{L}$}
        \State $\textit{In}[s]\gets \bigsqcup\ \{\ \textsc{Flow}(p{\to}s)\mid p\in\Pred(s)\cap \mathit{L}\ \}$ \Comment{edge-pruned join}
        \State $\mathit{WL}.\textsf{push}(s)$
     \EndFor
  \EndIf
\EndWhile
\Statex
\State \textbf{// Narrowing phase (descending)}
\State $\mathit{WL}\gets$ any worklist ordering over $\mathit{L}$
\While{$\mathit{WL}\neq\langle\rangle$}
  \State $n\gets \mathit{WL}.\textsf{pop}()$
  \State $\hat{o}\gets \textsc{Transfer}(n,\textit{In}[n])$
  \If{$\textsc{IsJoin}(n)$}
     \State $\hat{o}\gets \textsc{Narrow}(\textit{Out}[n],\hat{o})$ \Comment{at least one round; cap by $k_{\max}$}
  \EndIf
  \If{$\hat{o}\neq \textit{Out}[n]$}
     \State $\textit{Out}[n]\gets \hat{o}$
     \ForAll{$s\in \Succ(n)\cap \mathit{L}$}
        \State $\mathit{WL}.\textsf{push}(s)$
     \EndFor
  \EndIf
\EndWhile
\State \Return $\textit{Out}$ \Comment{in particular $\Env(\textsc{LoopExit}(h))$ is now converged}
\end{algorithmic}
\end{algorithm}

\begin{comment}
 3. 적응적 확대 연산을 이용한 고정점 알고리즘

  본 연구에서 제안하는 고정점 알고리즘은 반복문 분석을 위한    
   정적 분석 기법으로, 적응적 확대 연산(adaptive
  widening)과 조기 종료(early termination) 기법을 결합하여
  정밀도와 효율성을 동시에 향상시킨다.

 
 3.5.1 적응적 반복 횟수 추정

  기존의 고정점 알고리즘이 고정된 임계값(예: 2회)을
  사용하는 것과 달리, 본 알고리즘은 반복문 조건식을
  분석하여 동적으로 임계값을 결정한다:

  - 조건식의 연산자가 <, ≤, >, ≥, ≠ 중 하나인지 확인한다.      
  - 양측 피연산자를 초기 환경에서 평가하여 구간(interval)을    
   얻는다.
  - 연산자 종류에 따라 예상 반복 횟수를 계산한다. 예를
  들어, i < n의 경우 n.max - i.min을 계산한다.
  - 계산된 값을 [2, 20] 범위로 제한하여 안정성을 보장한다.     

  이를 통해 반복 횟수가 적은 루프에서는 더 많은 정밀
  반복을, 반복 횟수가 많은 루프에서는 조기에 확대 연산을       
  적용하여 효율성을 높인다.

  3.5.2 조건 수렴 검사

  반복문 조건식의 양측 피연산자가 모두
  단일값(singleton)으로 수렴하고 이전 상태와 동일한 경우,      
  더 이상의 반복이 불필요함을 감지하여 확대 단계를 조기        
  종료한다. 이는 불필요한 반복을 방지하여 분석 효율을
  향상시킨다.

   1. 반복문 노드 추출: 반복문에 속한 모든 노드 집합
  loop_nodes를 순회를 통해 추출한다.
  2. 방문 횟수 초기화: 각 노드의 방문 횟수를 기록할 맵
  visit_count를 초기화한다.
  3. 입출력 환경 초기화: 각 노드의 입력 환경 in_vars와 출력    
   환경 out_vars를 초기화한다.
  4. 초기 환경 계산: 반복문 외부에서 반복문 헤드로 진입하는    
   선행 노드들의 환경을 합병(join)하여 초기 환경
  start_env를 계산한다.
  5. 임계값 추정: 반복문 조건식을 분석하여 예상 반복 횟수를    
   추정하고, 이를 확대 연산 적용 임계값 threshold로
  설정한다.


\end{comment}

\clearpage

    \subsection{Design of the Abstract Interpretation Framework for Solidity}

This section presents the formal framework for our abstract interpretation-based debugger. We begin with the program syntax covering the subset of Solidity we analyze, then define the concrete semantics as a baseline, introduce the abstract domains we use for scalable approximation, and finally describe the abstract semantics that power our incremental debugging analysis.

        \subsubsection{Program Syntax}

% ================= Table: Syntax (meta, literals, types) =================
\begin{table}[t]
  \caption{Abstract syntax (subset of Solidity) used by our analysis — meta, literals, and types}
  \label{tab:syntax-a}
  \centering
  \small
  \setlength{\tabcolsep}{5pt}
  \renewcommand{\arraystretch}{1.05}
  \begin{tabularx}{\columnwidth}{@{}l l >{\raggedright\arraybackslash}X@{}}
    \toprule
    \textbf{Symbol} & \textbf{Set} & \textbf{Definition / Forms} \\
    \midrule
    \multicolumn{3}{@{}l}{\emph{Meta and identifiers}}\\
    $N$ & $\mathsf{BitW}$   & Integer bit width, $N \in \{8,16,\ldots,256\}$. \\
    $x$ & $\mathsf{Var}$    & Program variables (state or local). \\
    $f$ & $\mathsf{Field}$  & Struct fields. \\
    $C$ & $\mathsf{Struct}$ & Struct identifiers. \\
    $E$ & $\mathsf{Enum}$   & Enum identifiers. \\
    \midrule
    \multicolumn{3}{@{}l}{\emph{Literals}}\\
    $n$ & $\mathbb{Z}_{2^N}$ & Integer numeral typed by $N$ (signed via unary $-$ when needed). \\
    $b$ & $\mathbb{B}$       & $\{\mathsf{true},\mathsf{false}\}$. \\
    $\mathit{addr}$ & $\mathbb{A}$  & Address literal ($0 \ldots 2^{160}\!-\!1$). \\
    \midrule
    \multicolumn{3}{@{}l}{\emph{Types}}\\
    $\tau_b$ & $\mathsf{ValType}$ &
      $\mathsf{uint}N \mid \mathsf{int}N \mid \mathsf{bool} \mid \mathsf{address}$. \\
    $\kappa$ & $\mathsf{Key}$ &
      $\mathsf{uint}N \mid \mathsf{int}N \mid \mathsf{address} \mid
      \mathsf{enum}\ E$. \\
    $\mu$    & $\mathsf{CType}$ &
      $\mathsf{mapping}(\kappa \Rightarrow \tau) \mid \tau[] \mid \mathsf{struct}\ C \mid
      \mathsf{enum}\ E$, \\
      & & where $\tau ::= \tau_b \mid \mu$. \\
    \bottomrule
  \end{tabularx}
\end{table}

% ================= Table: Syntax (l-values, expressions, statements) =================
\begin{table}[t]
  \caption{Abstract syntax (subset) — l-values, expressions, statements, programs}
  \label{tab:syntax-b}
  \centering
  \small
  \setlength{\tabcolsep}{5pt}
  \renewcommand{\arraystretch}{1.05}
  \begin{tabularx}{\columnwidth}{@{}l l >{\raggedright\arraybackslash}X@{}}
    \toprule
    \textbf{Symbol} & \textbf{Set} & \textbf{Definition / Forms} \\
    \midrule
    \multicolumn{3}{@{}l}{\emph{L-values and expressions}}\\
    $\mathit{lv}$ & $\mathsf{LVal}$ &
      $x \mid \mathit{lv}.f \mid \mathit{lv}[\mathit{idx}] \mid \mathit{lv}[\mathit{key}]$. \\
    $\mathit{idx}$ & $\mathsf{IdxExp}$ & Numeric index expression (int/uint). \\
    $\mathit{key}$ & $\mathsf{KeyExp}$ & Mapping key expression of type $\kappa$. \\
    $a$ & $\mathsf{AExp}$ &
      $n \mid \mathit{addr} \mid \mathit{lv} \mid -a \mid \sim a \mid a \,\oplus\, a$,\\
      & &
      $\oplus \in \{+,-,*,/, \%, \ll, \gg, \&,\;|\;,\wedge\}$. \\
    $p$ & $\mathsf{BExp}$ &
      $b \mid a \;\bowtie\; a \mid \neg p \mid p \land p \mid p \lor p$,\\
      & & $\bowtie \in \{=,\neq,<,\le,>,\ge\}$. \\
    \midrule
    \multicolumn{3}{@{}l}{\emph{Statements}}\\
    $s$ & $\mathsf{Stmt}$ &
      \begin{tabular}[t]{@{}l@{}}
      \textsf{skip} \mid $s; s$ \mid $\{\overline{s}\}$ \\
      $\tau_b\ x;$ \mid $\tau_b\ x = a;$ \mid $\mathit{lv} := a$ \mid \textsf{delete}\; $\mathit{lv}
      $ \\
      \textsf{if}\ $p$ \ \textsf{then}\ $s$ \ \textsf{else}\ $s$ \\
      \textsf{while}\ $p$\ \textsf{do}\ $s$ \mid \textsf{do}\ $s$ \ \textsf{while}\ $p$ \\
      \textsf{for}($s_0$; $p$?; $u$?)\ $s$ \ (\,$u$ is an update as an assignment/compound\,) \\
      \textsf{return}\; $a$? \mid \textsf{assert}($p$) \mid \textsf{require}($p$) \\
      \textsf{call}(\overline{a}) \ (\textit{external or unknown call, as a statement}) \\
      \end{tabular} \\
    \midrule
    \multicolumn{3}{@{}l}{\emph{Programs}}\\
    $f$ & $\mathsf{Fun}$ &
      \textsf{function}\ $id(\overline{x:\tau_b})\ s$\quad(\emph{single‑contract, single‑tx};
      modifiers desugared). \\
    \bottomrule
  \end{tabularx}
\end{table}

Our analysis focuses on standard structured constructs including variable declarations, assignments, \textsf{if},
\textsf{while}, \textsf{do–while}, \textsf{for}, \textsf{return}, \textsf{assert}/\textsf{require},
\textsf{delete}, and calls as statements. Low‑level features such as inline assembly and unchecked arithmetic are out of scope for this section;
modifiers are assumed to be desugared into the control flow.

    
\subsubsection{Concrete Semantics (Denotational)}

We define the concrete semantics denotationally to establish a baseline for correctness. Let stores be $\sigma:\mathsf{Var}\rightharpoonup \mathsf{CVal}$.
L-value resolution $\mathrm{loc}_\sigma(\mathit{lv})=\ell$ and write $\mathrm{write}(\sigma,\ell,v)$
update the store, where arrays and mappings lazily materialize missing cells on access.
Expressions are pure and evaluate to values: $\llbracket e\rrbracket_\sigma\in\mathsf{Val}$.
To model control effects such as early returns and assertion failures, we introduce an outcome domain
\[
\mathsf{Res} \;::=\; \Norm(\sigma) \;\mid\; \Ret(v,\sigma) \;\mid\; \Abort
\]
with a sequencing (Kleisli) operator
\[
\begin{aligned}
\Norm(\sigma)\ \triangleright\ K &:= K(\sigma),\\
\Ret(v,\sigma)\ \triangleright\ K &:= \Ret(v,\sigma),\\
\Abort\ \triangleright\ K &:= \Abort.
\end{aligned}
\]
We write $\llbracket s\rrbracket:\sigma\mapsto \mathsf{Res}$ for the denotation of statements. Table~\ref{tab:conc-denot} defines the concrete semantics for each statement form.
\begin{table}[t]
  \caption{Concrete denotational semantics (statements)}
  \label{tab:conc-denot}
  \centering
  \small
  \setlength{\tabcolsep}{6pt}
  \renewcommand{\arraystretch}{1.12}
  \begin{tabularx}{\columnwidth}{@{}l X@{}}
    \toprule
    \textbf{Statement} & \textbf{Meaning} \\
    \midrule
    \textsf{skip} &
    $\llbracket \textsf{skip}\rrbracket(\sigma)=\Norm(\sigma)$.\\

    $s_1; s_2$ &
    $\llbracket s_1; s_2\rrbracket(\sigma)=\big(\llbracket s_1\rrbracket(\sigma)\big)
    \ \triangleright\ (\lambda \sigma'.\,\llbracket s_2\rrbracket(\sigma'))$.\\

    $\{\overline{s}\}$ &
    Right-associative fold of sequencing over $\overline{s}$.\\

    $\tau\ x;$ &
    $\llbracket \tau\ x;\rrbracket(\sigma)=\Norm\!\big(\sigma[x\mapsto \mathrm{zero}_\tau]\big)$.\\

    $\tau\ x=e;$ &
    $\llbracket \tau\ x=e;\rrbracket(\sigma)=\Norm\!\big(\sigma[x\mapsto \llbracket
    e\rrbracket_\sigma]\big)$.\\

    $\mathit{lv}:=e$ &
    $\llbracket \mathit{lv}:=e\rrbracket(\sigma)=\Norm\!\big(\mathrm{write}(\sigma,\,\mathrm{loc}
    _\sigma(\mathit{lv}),\,\llbracket e\rrbracket_\sigma)\big)$.\\

    \textsf{delete}\ $\mathit{lv}$ &
    $\llbracket \textsf{delete}\ \mathit{lv}\rrbracket(\sigma)=\Norm\!\big(\mathrm{write}(\sigma,\,
    \mathrm{loc}_\sigma(\mathit{lv}),\,\mathrm{zero}_{\tau(\mathit{lv})})\big)$.\\

    \textsf{if}\ $p$ \textsf{then}\ $s_t$ \textsf{else}\ $s_f$ &
    $\llbracket \cdot\rrbracket(\sigma)=
      \begin{cases}
        \llbracket s_t\rrbracket(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{true},\\
        \llbracket s_f\rrbracket(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{false}.
      \end{cases}$\\

    \textsf{while}\ $p$ \textsf{do}\ $s$ &
    Let $F(H)(\sigma)=
      \begin{cases}
        \big(\llbracket s\rrbracket(\sigma)\big)\ \triangleright\ H & \text{if }\llbracket
        p\rrbracket_\sigma=\mathsf{true},\\
        \Norm(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{false}.
      \end{cases}$ Then $\llbracket \textsf{while}\ p\ \textsf{do}\ s\rrbracket=\mathrm{lfp}(F)$.\\

    \textsf{return}\ $e$ &
    $\llbracket \textsf{return}\ e\rrbracket(\sigma)=\Ret(\llbracket e\rrbracket_\sigma,\,\sigma)$.
    \\

    \textsf{assert}$(p)$,\ \textsf{require}$(p)$ &
    $\llbracket \cdot\rrbracket(\sigma)=
      \begin{cases}
        \Norm(\sigma) & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{true},\\
        \Abort & \text{if }\llbracket p\rrbracket_\sigma=\mathsf{false}.
      \end{cases}$\\

    \textsf{revert}$(\cdots)$ &
    $\llbracket \textsf{revert}(\cdots)\rrbracket(\sigma)=\Abort$.\\

    \textsf{call}$(\overline{e})$ &
    Internal calls evaluate the callee's body with parameter binding; external/unknown calls are
    left unspecified here (treated in the abstract setting by a conservative effect).\\
    \bottomrule
  \end{tabularx}
\end{table}

For arrays and mappings, $\mathrm{loc}_\sigma(a[i])$ extends dynamic array $a$ up to index $i$ with default cells if needed,
and $\mathrm{loc}_\sigma(m[k])$ creates mapping entry $m[k]$ lazily if absent. These conventions apply to both
reads and writes. Note that \textsf{for} and \textsf{do-while} loops are desugared to \textsf{while} in our framework, and we
treat \textsf{require} identically to \textsf{assert} at the level of control effects since both abort on failure.

        \subsubsection{Abstract Domain}

% ---------- Macros for atomic abstract values ----------
\newcommand{\Uhat}[1]{\widehat{\mathbb{U}}_{#1}}
\newcommand{\Zhat}[1]{\widehat{\mathbb{Z}}_{#1}}

\noindent\textbf{Atomic abstract values.}
We use interval domains for integer types and a specialized set domain for address types:
\begin{align*}
\Uhat{N} &:= \{[\ell,u] \mid 0 \le \ell \le u \le 2^N{-}1\} \ \cup\ \{\bot,\top_N\},\\
\Zhat{N} &:= \{[\ell,u] \mid -2^{N-1} \le \ell \le u \le 2^{N-1}{-}1\} \ \cup\ \{\bot,\top_N^{\pm}\},
\\
\widehat{\mathbb{B}} &:= \{\bot,\widehat{\mathsf{false}},\widehat{\mathsf{true}},\top\},\qquad
\widehat{\mathbb{A}} := \wp_{\le K}(\mathbb{A}) \cup \{\top\},\\
\widehat{\mathsf{Enum}}(E) &:= \{[\ell,u]\mid 0\le \ell \le u \le |E|-1\}\cup\{\bot,[0,|E|-1]\}.
\end{align*}
Here $\widehat{\mathbb{A}}$ represents the address domain as a set abstraction with at most $K$ concrete address identifiers,
generalizing to $\top$ when capacity is exceeded. This enables precise tracking of contract addresses in debugging scenarios
while maintaining scalability.

\noindent\textbf{Order/Join/Meet.}\;
For intervals,
\[
[\ell_1,u_1] \sqsubseteq [\ell_2,u_2] \iff \ell_2 \le \ell_1 \ \wedge\ u_1 \le u_2,\quad
[\ell_1,u_1] \sqcup [\ell_2,u_2] = [\min(\ell_1,\ell_2),\max(u_1,u_2)],
\]
\[
[\ell_1,u_1] \sqcap [\ell_2,u_2] =
\begin{cases}
[\max(\ell_1,\ell_2),\min(u_1,u_2)] & \text{if }\max(\ell_1,\ell_2)\le \min(u_1,u_2),\\
\bot & \text{otherwise.}
\end{cases}
\]
Widening $\nabla$ is the standard interval widening (per bit width); narrowing $\Delta$ follows the
dual pattern.

\medskip
\noindent\textbf{Composite values.}
Our framework supports Solidity's composite data structures through careful abstraction:
\begin{itemize}[leftmargin=1.25em]
  \item \emph{Structs}:\;
  $\widehat{\mathsf{Struct}}(C) = \prod_{f\in\mathsf{fields}(C)} \widehat{\mathsf{Val}}_f$
  represents structs as products over their fields with pointwise order, enabling field-sensitive analysis.
  \item \emph{Arrays (on‑access materialization)}:\;
  $\widehat{\mathsf{Arr}}(\tau) = (\hat{\ell},\hat{d},M)$ where
  $\hat{\ell}\in \Uhat{256}$ is an abstract length,
  $\hat{d}\in \widehat{\tau}$ is a default element value,
  and $M:\mathbb{N}_{\text{fin}}\rightharpoonup \widehat{\tau}$ is a finite map tracking observed indices.
  This design enables strong updates for known indices while maintaining soundness for unknown accesses.
  \item \emph{Mappings (on‑access materialization)}:\;
  $\widehat{\mathsf{Map}}(\kappa\Rightarrow\tau) = (\hat{d},M)$ with default $\hat{d}
  \in\widehat{\tau}$ and finite $M:\widehat{\kappa}_{\text{fin}}\rightharpoonup \widehat{\tau}$.
  Mappings materialize entries on first access, supporting both concrete keys (for strong updates) and symbolic keys (for weak updates).
  \item \emph{Enums}:\; represented as bounded unsigned intervals over $[0,|E|-1]$.
\end{itemize}

\medskip
\noindent\textbf{Value domains and store.}
The complete abstract value hierarchy is:
\[
\widehat{\mathsf{Val}} \;::=\; \bigcup_{N}(\Uhat{N}\cup\Zhat{N})\ \cup\ \widehat{\mathbb{B}}
\ \cup\ \widehat{\mathbb{A}}\ \cup\ \widehat{\mathsf{Enum}}(E),
\]
\[
\widehat{\mathsf{CVal}} \;::=\; \widehat{\mathsf{Val}} \;\mid\; \widehat{\mathsf{Struct}}(C) \;\mid\;
\widehat{\mathsf{Arr}}(\tau) \;\mid\; \widehat{\mathsf{Map}}(\kappa\Rightarrow\tau),
\qquad
\hat{\sigma}:\mathsf{Var}\rightharpoonup \widehat{\mathsf{CVal}} \ (\text{pointwise order/join}).
\]
The abstract store $\hat{\sigma}$ maps variables to abstract values with pointwise ordering and join operations,
providing the foundation for our flow-sensitive analysis.

% ================= Table: Type-to-domain mapping (compact) =================
\begin{table}[t]
  \caption{Type $\to$ abstract domain mapping (summary)}
  \label{tab:type2domain}
  \centering
  \small
  \setlength{\tabcolsep}{6pt}
  \renewcommand{\arraystretch}{1.05}
  \begin{tabular}{@{}l l@{}}
    \toprule
    \textbf{Solidity type} & \textbf{Abstract domain} \\
    \midrule
    $\mathsf{uint}N$ & $\Uhat{N}$ \quad($N\!\in\!\{8,\dots,256\}$) \\
    $\mathsf{int}N$  & $\Zhat{N}$ \\
    $\mathsf{bool}$  & $\widehat{\mathbb{B}}$ \\
    $\mathsf{address}$ & $\widehat{\mathbb{A}}$ (set domain) \\
    $\mathsf{enum}\ E$ & $\widehat{\mathsf{Enum}}(E)$ \\
    $\tau[]$ & $\widehat{\mathsf{Arr}}(\tau)$ \\
    $\mathsf{mapping}(\kappa\Rightarrow\tau)$ & $\widehat{\mathsf{Map}}(\kappa\Rightarrow\tau)$ \\
    $\mathsf{struct}\ C$ & $\widehat{\mathsf{Struct}}(C)$ \\
    \bottomrule
  \end{tabular}
\end{table}

Table~\ref{tab:type2domain} summarizes the mapping from Solidity types to abstract domains.
Addresses use a set domain that tracks up to $K$ concrete identifiers before generalizing to $\top$,
providing precise aliasing information for contract addresses commonly encountered in debugging.
Arrays and mappings employ finite observed maps with default values, ensuring soundness under unknown
indices or keys while enabling strong updates for observed accesses.

        % 3.5.x  Abstract Semantics (Denotational)
% =====================================================================
\subsubsection{Abstract Semantics (Denotational)}

We lift the concrete semantics to abstract domains systematically. Let $\hat{\sigma}:\mathsf{Var}\rightharpoonup \widehat{\mathsf{CVal}}$ be the abstract store. Expressions evaluate to abstract values
$\llbracket e\rrbracket^\sharp_{\hat{\sigma}}\in \widehat{\mathsf{Val}}$
using bit-width–aware interval arithmetic for integers, set operations for addresses, and standard operations for booleans and composites.
Abstract outcomes mirror the concrete case:
\[
\widehat{\mathsf{Res}} \;::=\; \widehat{\Norm}(\hat{\sigma}) \;\mid\; \widehat{\Ret}(\hat{v},
\hat{\sigma}) \;\mid\; \widehat{\Abort},
\]
ordered componentwise, with sequencing
\[
\begin{aligned}
\widehat{\Norm}(\hat{\sigma})\ \triangleright^\sharp\ K &:= K(\hat{\sigma}),\\
\widehat{\Ret}(\hat{v},\hat{\sigma})\ \triangleright^\sharp\ K &:= \widehat{\Ret}(\hat{v},
\hat{\sigma}),\\
\widehat{\Abort}\ \triangleright^\sharp\ K &:= \widehat{\Abort}.
\end{aligned}
\]
Branch refinement $\mathrm{refine}(\hat{\sigma},p,b)$ narrows operands of condition $p$ using interval meets to improve precision along branches.
Abstract writes distinguish between \emph{strong} updates when the target is unique (e.g., singleton index or concrete key)
and \emph{weak} updates that join the new value with the existing value when the target is uncertain.
For joining branch outcomes we use
\[
\mathrm{joinRes}(r_1,r_2)=
\begin{cases}
\widehat{\Norm}(\hat{\sigma}_1\sqcup \hat{\sigma}_2) & r_i=\widehat{\Norm}(\hat{\sigma}_i),\\
\widehat{\Ret}(\hat{v}_1\sqcup \hat{v}_2,\ \hat{\sigma}_1\sqcup \hat{\sigma}_2) & r_i=\widehat{\Ret}
(\hat{v}_i,\hat{\sigma}_i),\\
\text{the obvious mixed cases: componentwise join and/or carry }\widehat{\Abort}.
\end{cases}
\]
Table~\ref{tab:abs-denot} defines the abstract semantics for each statement form.
\begin{table}[t]
  \caption{Abstract denotational semantics (statements)}
  \label{tab:abs-denot}
  \centering
  \small
  \setlength{\tabcolsep}{6pt}
  \renewcommand{\arraystretch}{1.12}
  \begin{tabularx}{\columnwidth}{@{}l X@{}}
    \toprule
    \textbf{Statement} & \textbf{Meaning} \\
    \midrule
    \textsf{skip} &
    $\llbracket \textsf{skip}\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}(\hat{\sigma})$.\\

    $s_1; s_2$ &
    $\llbracket s_1; s_2\rrbracket^\sharp(\hat{\sigma})=\big(\llbracket
    s_1\rrbracket^\sharp(\hat{\sigma})\big)\ \triangleright^\sharp\ (\lambda \hat{\sigma}'.\,
    \llbracket s_2\rrbracket^\sharp(\hat{\sigma}'))$.\\

    $\tau\ x;$ &
    $\llbracket \tau\ x;\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}\!\big(\hat{\sigma}[x\mapsto
    \hat{\mathrm{init}}(\tau)]\big)$,\quad
    where $\hat{\mathrm{init}}$ sets \textsf{int/uint/bool}$\mapsto\bot$, \textsf{address}
    $\mapsto\top_{160}$, composites to empty summaries.\\

    $\tau\ x=e;$ &
    $\llbracket \tau\ x=e;\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}\!\big(\hat{\sigma}
    [x\mapsto \alpha_\tau(\llbracket e\rrbracket^\sharp_{\hat{\sigma}})]\big)$.\\

    $\mathit{lv}:=e$ &
    $\llbracket \mathit{lv}:=e\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}
    \!\big(\widehat{\mathrm{write}}(\hat{\sigma},\,\mathit{lv},\,\llbracket
    e\rrbracket^\sharp_{\hat{\sigma}})\big)$;\,
    non-singleton index/key $\Rightarrow$ weak update (join).\\

    \textsf{delete}\ $\mathit{lv}$ &
    $\llbracket \textsf{delete}\ \mathit{lv}\rrbracket^\sharp(\hat{\sigma})=\widehat{\Norm}
    \!\big(\widehat{\mathrm{write}}(\hat{\sigma},\,\mathit{lv},\,\hat{\mathrm{zero}}
    _{\tau(\mathit{lv})})\big)$;\,
    arrays/maps/structs wiped recursively.\\

    \textsf{if}\ $p$ \textsf{then}\ $s_t$ \textsf{else}\ $s_f$ &
    Let $\hat{\sigma}_t=\mathrm{refine}(\hat{\sigma},p,\mathsf{true})$ and $\hat{\sigma}
    _f=\mathrm{refine}(\hat{\sigma},p,\mathsf{false})$. Then
    $\llbracket \cdot\rrbracket^\sharp(\hat{\sigma})=\mathrm{joinRes}\!\big(\llbracket
    s_t\rrbracket^\sharp(\hat{\sigma}_t),\ \llbracket s_f\rrbracket^\sharp(\hat{\sigma}_f)\big)$.\\

    \textsf{while}\ $p$ \textsf{do}\ $s$ &
    Define $G^\sharp(H)(\hat{\sigma})=\mathrm{joinRes}\big(
      \llbracket s\rrbracket^\sharp(\mathrm{refine}(\hat{\sigma},p,\mathsf{true}))
      \ \triangleright^\sharp\ H,\;
      \widehat{\Norm}(\mathrm{refine}(\hat{\sigma},p,\mathsf{false}))
    \big)$.
    Then
    \[
      \llbracket \textsf{while}\ p\ \textsf{do}\ s\rrbracket^\sharp
      \;=\;
      \underbrace{\mathrm{lfp}^{\nabla}(G^\sharp)}_{\text{widening pass}}
      \;\triangle\; \underbrace{\mathrm{narrow}^{k}}_{\textbf{mandatory},\ k\ge 1},
    \]
    i.e., compute the widening-based post-fixpoint and then apply at least one narrowing round to
    regain precision.\\

    \textsf{return}\ $e$ &
    $\llbracket \textsf{return}\ e\rrbracket^\sharp(\hat{\sigma})=\widehat{\Ret}(\llbracket
    e\rrbracket^\sharp_{\hat{\sigma}},\,\hat{\sigma})$.\\

    \textsf{assert}$(p)$,\ \textsf{require}$(p)$ &
    As guards: if $p$ must-hold $\Rightarrow\ \widehat{\Norm}(\mathrm{refine}(\hat{\sigma},p,
    \mathsf{true}))$; if $p$ must-fail $\Rightarrow\ \widehat{\Abort}$; otherwise both may happen
    and $\mathrm{joinRes}$ carries the possibilities.\\

    \textsf{revert}$(\cdots)$ &
    $\llbracket \textsf{revert}(\cdots)\rrbracket^\sharp(\hat{\sigma})=\widehat{\Abort}$.\\

    \textsf{call}$(\overline{e})$ &
    Internal calls analyze the callee body under parameter binding (same abstract machinery);
    external/unknown calls conservatively havoc their footprint or are modeled by $\widehat{\Abort}$
    per analysis policy.\\
    \bottomrule
  \end{tabularx}
\end{table}

For array and mapping accesses, reading with a singleton index or concrete key returns the corresponding cell,
while reading with a range or symbolic key returns the join of all materialized cells, or the element type's $\top$ if none exist.
Dynamic array \texttt{length} is tracked as a singleton interval when observed; otherwise it is conservatively approximated as $\top_{\mathsf{uint256}}$.
Writes follow the same singleton versus non-singleton criterion: concrete indices and keys enable strong updates that precisely overwrite values,
while symbolic or range indices trigger weak updates that join new values with existing ones to maintain soundness.

\section{Evaluation}
To evaluate how \textsc{SolQDebug} performs in practical debugging scenarios, we organize our study
around three research questions:

\begin{itemize}
  \item \textbf{RQ1 – Responsiveness}:\;%
        How much edit–to–inspect latency does \textsc{SolQDebug} eliminate compared to Remix?

  \item \textbf{RQ2 – Precision Sensitivity to Annotation Structure}:\;%
        In a common Solidity pattern where inputs are normalized by division, how does the structure
        of operand intervals—overlapping vs. distinct—impact interval growth?

  \item \textbf{RQ3 – Loops}:\;%
        Which loop structures lead to loss of precision, and how do symbolic inputs influence the
        stability of analysis?
\end{itemize}
\subsection{Experimental Setup}
We evaluate \textsc{SolQDebug} on a controlled local setup with the following hardware and software
configuration:

\begin{itemize}
    \item \textbf{CPU}: 11th Gen Intel® Core™ i7-11390H @ 3.40GHz  
    \item \textbf{RAM}: 16.0 GB  
    \item \textbf{Operating System}: Windows 10 (64-bit)  
    \item \textbf{Implementation Language}: Python  
\end{itemize}

The dataset is derived from DAppSCAN~\cite{dappscan}, a large-scale real-world benchmark for smart
contract analysis. From 3,345 Solidity files using \texttt{>=0.8.0}, we sample 128 contracts across
three size brackets (1–10 KB, 11–20 KB, and over 20 KB). After filtering out logic-free functions (e.
g., those containing only assignments or return statements), we retain 242 single-transaction
handlers. From these, we select 30 representative examples covering key Solidity idioms, including
structs, mappings, dynamic arrays, control flow, and arithmetic logic.

Since Remix IDE lacks built-in automated benchmarking capabilities, we developed \texttt{
remix\_benchmark}, a Selenium-based automation framework that programmatically drives the Remix web
interface to measure edit-to-inspect latency. For each test function, \texttt{remix\_benchmark}
automates the full workflow: compilation, contract deployment, state variable initialization via
manual storage slot assignment, parameter entry, transaction execution, and step-through debugging.
We measure two latency metrics: \textit{pure debug time}, capturing only the debugger step-through
duration, and \textit{total time}, which includes compilation, deployment, and state setup overhead.
The difference between these metrics reflects the additional manual effort required in traditional
debugging workflows.

Although \textsc{SolQDebug} is designed for interactive use within a Solidity editor, all
experiments simulate this behavior in a controlled scripting environment. For each function, we
reconstruct a sequence of incremental edits and annotations that mimic realistic developer activity.
These fragments are streamed into the interpreter to measure latency and interval growth under
reproducible conditions.


\subsection{RQ1 - Responsiveness}
To evaluate responsiveness, we measure edit-to-inspect latency—defined as the time from a code
change to the appearance of updated variable information—under a single contract, single transaction
scenario.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{3d_benchmark_surface.png}
  \caption{Edit-to-inspect latency comparison between Remix and \textsc{SolQDebug} across varying test-case widths and execution passes. The x-axis represents the cost estimate, y-axis shows TestCase width (\(\Delta\)), and z-axis displays latency in seconds. While Remix maintains constant high latency regardless of iteration, \textsc{SolQDebug} demonstrates significantly lower latency that quickly reaches a floor after the initial pass.}
  \label{fig:rq1-responsiveness}
\end{figure}

We evaluated 30 functions across 4 test-case widths \(\Delta \in \{0, 2, 5, 10\}\), yielding 120
total measurements for \textsc{SolQDebug}. For Remix, we measured each function once using \texttt{
remix\_benchmark}, capturing both pure debug time (debugger step-through only) and total time (
including compilation, deployment, and state initialization).

For Remix, the pure debug time ranged from 25.1 to 124.6 seconds (median: 53.0 s), reflecting the
time required to step through bytecode operations in the debugger. The total time, however, ranged
from 71.1 to 168.3 seconds (median: 98.1 s), as it includes approximately 35 seconds for
compilation and deployment, plus 0–11.8 seconds for manual state variable initialization (median:
2.9 s). Functions requiring more state slots incur proportionally higher setup overhead, with state
initialization time growing linearly with the number of storage variables.

In contrast, \textsc{SolQDebug} completed analysis in 0.03–5.09 seconds (median: 0.15 s) across all
120 measurements, requiring no compilation, deployment, or state setup. Fig.~\ref{fig:rq1-
responsiveness} visualizes this performance gap: Remix pure debug time alone exceeds \textsc{
SolQDebug}'s total latency by a median factor of \textasciitilde350$\times$, while total Remix
latency (including setup) exceeds it by \textasciitilde650$\times$. This demonstrates that \textsc{
SolQDebug} eliminates the compile–deploy–setup cycle entirely, enabling immediate feedback during
code editing.

\medskip
\noindent\fbox{%
\begin{minipage}{0.96\linewidth}
\textbf{Answer to RQ1:}
\textsc{SolQDebug} achieves sub-second edit-to-inspect latency (median: 0.15 s), eliminating 350$\times$–650$\times$ overhead from Remix's compile–deploy–debug cycle. This enables immediate, interactive feedback during code editing without transaction execution.
\end{minipage}%
}

\subsection{RQ2 - Precision Sensitivity to Annotation Structure}

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.35\linewidth]{fig_pending_f90.pdf}
  \hspace{2em}
  \includegraphics[width=0.35\linewidth]{fig_pending_convert_f90.pdf}
  \caption{
Interval growth after normalization in \texttt{pending} function from \texttt{Lock.sol}. Left:
original version with subtraction; right: modified version where subtraction is replaced with
addition}
  \label{fig:rq2-precision}
\end{figure*}

Smart contracts often normalize raw inputs via division—e.g., converting timestamps to time
units—before combining the results using addition or subtraction. To isolate the impact of the final
arithmetic operator from the shared division step, we analyze two variants of the same control-flow
structure: one using addition, the other using subtraction.

Each variant is tested under two annotation styles. In the \textsc{diff} style, each operand is
assigned a distinct input interval (e.g., \([10, 20]\) and \([30, 40]\)). In the \textsc{overlap}
style, the intervals are partially aligned (e.g., \([10, 20]\) and \([15, 25]\)), such that they
share a subrange but are not fully identical.
For each combination, we sweep the annotation width \(\Delta \in \{1, 3, 6, 10\}\) and report
\(F_{90}\), the 90th percentile of the inflation factor \(F = \textit{exit\_width} /
\textit{input\_width}\).

Results in Fig.7 show that interval growth is more sensitive to the structure of input ranges than
to the arithmetic operator. \textsc{Diff} inputs consistently trigger early widening as \(\Delta\)
increases, while \textsc{overlap} inputs maintain tighter bounds even under addition, which
typically increases output range.

This suggests that in division-normalized logic, the alignment of operand intervals—whether disjoint
or overlapping—has a stronger influence on interval growth than the choice between addition and
subtraction. Overlapping inputs consistently result in smaller output ranges, reducing the degree of
over-approximation as input width increases.

\medskip
\noindent\fbox{%
\begin{minipage}{0.96\linewidth}
\textbf{Answer to RQ2:}
In division-normalized arithmetic patterns, the structure of input interval annotations (overlapping vs.\ disjoint) has a stronger influence on precision than the choice of arithmetic operator (addition vs.\ subtraction). Overlapping intervals consistently reduce over-approximation by up to 3$\times$ compared to disjoint inputs, suggesting developers should align annotation ranges with expected input correlations to improve precision without sacrificing responsiveness.
\end{minipage}%
}

\subsection{RQ3 - Loops}
Two loop patterns emerge from the benchmarks. In the first, the loop condition itself bounds the
updated variable, and the loop body performs only direct assignments. In such cases, abstract
interpretation converges naturally. For example, \texttt{updateUserInfo} in \textsc{AOC\_BEP}
iterates from 1 to 4, and the interval for \texttt{level} stabilizes at \([1,4]\).
    
    In contrast, loops that interact with external or conditionally populated state tend to diverge
    under widening. For instance, \texttt{revokeStableMaster} in \textsc{Core} terminates
    immediately under the contract's default state, but diverges once annotations populate the
    relevant lists. These lists trigger cascading updates, and their interactions produce
    imprecision even though the loop count is implicit.
    
    In short, loop precision tends to hold when updates are tightly coupled to bounded loop indices,
    but approximation still arises due to joins at merge points. Precision degrades further when
    variables are updated independently of the loop condition. This includes dormant paths activated
    by symbolic input, or loops that iterate over data-driven structures such as mappings or dynamic
    lists.

\medskip
\noindent\fbox{%
\begin{minipage}{0.96\linewidth}
\textbf{Answer to RQ3:}
\textsc{SolQDebug} achieves precise analysis for loops with bounded indices and direct assignments, where abstract interpretation converges naturally. However, precision degrades for loops interacting with external state, conditionally populated data structures, or data-driven iteration (mappings, dynamic arrays), where widening-based approximation becomes unavoidable. Developers should annotate state dependencies carefully to help the analyzer distinguish between statically bounded and potentially unbounded iterations.
\end{minipage}%
}

\section{Discussion}

\subsection{Why use Abstract Interpretation for Debugging}
    In this work, we use debugging to mean a developer-led, interactive exploration activity that
    happens before deployment during code authoring: the developer varies symbolic (interval) inputs
    and immediately observes branch reachability, guard validity, and value bounds at the source
    level. This edit-time feedback loop calls for a technique that (1) terminates quickly, (2)
    explains results in a way developers can inspect, and (3) scales to near-keystroke
    responsiveness.

    We chose abstract interpretation (AI) over symbolic execution and proof-based verification for
    three reasons:
    \begin{itemize}
      \item \textbf{Termination.} AI enforces convergence via widening at loops and joins at merges, avoiding the path explosion common in symbolic execution.
      \item \textbf{Explainability.} Each result is an abstract value in a well-defined lattice. With interval domains, the mapping from inputs to outputs is explicit as ranges, which makes dataflow effects easy to trace and debug at the line level.
      \item \textbf{Responsiveness.} Interval transfer functions are lightweight, enabling millisecond-scale updates that fit the edit cycle. Symbolic engines routinely explore many paths even for small edits, which can break interactivity.
    \end{itemize}
    Formal verification provides stronger guarantees, but requires fully specified properties and
    invariants, which are costly to author during early iterations. \textsc{SolQDebug} is designed
    to bridge the gap between writing code and running tests or verification—offering immediate,
    sound, conservative feedback with low annotation overhead.

    For debugging, intervals strike a practical balance between precision and speed. They (i) align
    with developers' mental model of "possible ranges," (ii) expose boundary effects (e.g., overflow
    thresholds, guard satisfaction regions) without committing to a single concrete input, and (iii)
    compose predictably through joins and widenings. In our setting, intervals are also a natural
    surface for annotations: developers can \emph{shape} symbolic inputs (e.g., make them
    overlapping or disjoint) and directly see how that affects control flow and computed ranges.

    AI's precision is conservative by design; edit-time usability depends on giving developers
    simple levers to steer precision without sacrificing responsiveness. We expose three such levers
    that proved effective in our study:
    \begin{itemize}
      \item \textbf{Annotation structure.} Overlapping operand intervals often bound output ranges more tightly than disjoint ones in division-normalized arithmetic (cf.\ RQ2). This reduces false alarms with no runtime cost.
      \item \textbf{Annotation width.} Narrower inputs shrink joins and delay widening; developers can start narrow and broaden gradually ("zoom out") to probe stability.
      \item \textbf{Guard-guided narrowing.} Making explicit the intended \texttt{require}/\texttt{if} guards in annotations tightens feasible states early and improves precision along the taken branch at negligible cost.
    \end{itemize}
    Where stricter precision is essential (e.g., inside data-driven loops), the workflow can
    temporarily fall back to concrete inputs for local inspection, then return to intervals for
    broader exploration. This "concrete when needed, symbolic by default" rhythm preserves
    interactivity while keeping results actionable.
    \vspace{0.25em}

    \subsection{Evaluation Implication}
    Traditional debuggers (e.g., Remix, Hardhat Debug) require compile–deploy–execute per iteration,
    typically taking tens of seconds. In contrast, our interpreter updates in milliseconds (median
    \(\sim\)14\,ms on the first pass and 5–35\,ms on the second), yielding \emph{orders-of-magnitude}
    lower edit-to-inspect latency. This difference is qualitative: it enables near-keystroke
    feedback, which changes how developers explore code. Because results are symbolic, a single pass
    summarizes many concrete executions; developers can see when guards always hold/fail for an
    interval, when a branch becomes unreachable, or when a value may cross a critical threshold—all
    without leaving the editor. In short, \textsc{SolQDebug} complements runtime debuggers by moving
    fast, informative checks \emph{into} the authoring loop (RQ1).

    RQ2 shows that, in division-normalized patterns common in Solidity, \emph{how} intervals are
    shaped can matter more than \emph{which} arithmetic operator is used. Overlapping inputs
    systematically produced smaller output ranges than disjoint inputs, delaying or avoiding early
    widening. When investigating arithmetic joins, start with partially overlapping intervals and
    widen only as needed; keep operands aligned where normalization is present.

    Widening can degrade precision in loops, but RQ3 highlights that not all loop updates lead to
    divergence. Loops whose updated variables are bounded by the loop index (or by monotone guards)
    often converge to tight ranges quickly; data-driven loops over symbolic containers tend to widen
    early. Practical implications include: (i) prefer index-bounded annotations (e.g., bound the
    iteration count or accessed keys) for loop-local exploration, (ii) materialize only the keys or
    indices the loop actually touches, and (iii) where necessary, switch to concrete inputs for a
    small slice of the loop to confirm behavior, then return to symbolic exploration.

    Overall, these findings suggest a debugging workflow that starts symbolic and broad, then
    \emph{shapes} annotations to tighten precision where it matters (overlap, narrow, guard-guided),
    and finally uses concrete spot checks only for stubborn hot spots (e.g., deeply data-dependent
    loops).

    \subsection{Limitation}
    Our current scope and measurements introduce several limitations. First, we focus on
    single-contract, single-transaction functions. Inter-contract calls, multi-transaction workflows,
    proxies, and inheritance hierarchies are out of scope in the present implementation. As a result,
    we have not yet conducted a developer study in larger project settings; the usability and
    interpretability of edit-time feedback across multi-contract workflows remain unvalidated.

    Second, our latency numbers combine interpreter execution time (timed in Python) with an estimate
    for annotation effort per variable (manual input). This procedure ignores UI-event latency and
    cursor dynamics, and it assumes a consistent operator for annotation entry. Likewise, our
    precision metric (\(F_{90}\): 90th percentile of exit-/input-width inflation) captures a salient
    aspect of interval growth but does not reflect all developer notions of "useful precision."
    These choices provide a consistent basis for tool-level comparison but may under- or
    over-estimate end-to-end IDE latency or perceived precision.

    We plan to (i) extend the analysis to inter-contract calls and multi-transaction scenarios, (ii)
    instrument editor events to directly measure human-in-the-loop latency and refine the annotation
    cost model, and (iii) run a controlled developer study once multi-contract support stabilizes.
    On the analysis side, loop summarization and selective use of lightweight relational domains (e.
    g., applied on demand to hot spots) are promising avenues to improve precision while preserving
    interactivity.


\section{Related Works}

    \subsection{Solidity IDEs and Debuggers}
        Modern Solidity development environments either embed a debugger or integrate external
        debugging plug-ins. \citet{remix} is the most widely used web IDE; it supports syntax
        highlighting, one-click compilation, and a bytecode-level debugger that lets users step
        through EVM instructions and inspect stack, memory, and storage. \citet{hardhat} is a Node.
        js–based framework that couples the Solidity compiler with an Ethereum runtime; its Hardhat
        Debug plug-in attaches a Remix-style debugger to locally broadcast transactions inside
        Visual Studio Code. \citet{forge} is a command-line toolchain oriented toward fast,
        reproducible unit testing; the command \texttt{forge test} spins up an ephemeral fork,
        deploys contracts, executes annotated test functions, and enables replay through Forge Debug.
        \citet{soldepro} is a Visual Studio Code extension that performs runtime debugging over
        concrete transactions and integrates with Hardhat; in practice, many workflows create a
        small auxiliary contract that calls the target functions so that state changes can be
        observed step by step.

        In short, these debuggers operate on compiled artifacts or post-deployment traces and rely
        on transaction replay and EVM-level stepping. They do not accept partial, in-flight source
        fragments nor provide symbolic (interval) input modeling or millisecond edit-time feedback.
        By contrast, \textsc{SolQDebug} targets pre-deployment authoring, accepts partial fragments
        and symbolic annotations, and reports line-level effects via abstract interpretation during
        editing.

    \subsection{Solidity Vulnerability Detection and Verification}
        A rich body of work analyzes smart contracts for security issues using four main families of
        techniques.
        Static analysis tools reason over source or bytecode without running the contract. 
        Representative systems include rule- or pattern–based analyzers such as Securify and Slither
        \citep{securify,slither}, symbolic-execution–assisted detectors like Mythril \citep{mythril},
        knowledge-graph–based reasoning such as Solidet \citep{solidet}, and bytecode CFG refinement
        as in Ethersolve \citep{ethersolve}.
        Dynamic testing and fuzzing exercise deployed or locally simulated contracts to uncover
        faults and security issues:
        ContractFuzzer mutates ABI-level inputs \citep{confuzz}, Echidna brings property-based
        fuzzing into developer workflows \citep{echidna}, sFuzz adapts scheduling for higher
        coverage \citep{sfuzz}, TransRacer finds transaction-ordering races \citep{transracer}, and
        Ityfuzz leverages snapshotting to decouple executions from chain nondeterminism
        \citep{ityfuzz}.
        Formal verification aims to prove safety properties or refute counterexamples at compile
        time; examples include ZEUS, VeriSmart, and SmartPulse \citep{zeus,verismart,pulse}.
        Finally, AI-based approaches train models to predict vulnerabilities or triage candidates, e.
        g., via data-flow–aware pretraining, IoT-oriented classifiers, or prompt-tuning for detector
        adaptation \citep{peculiar,tmlvd,pscvfinder}.

        These approaches have substantially advanced vulnerability detection and property checking
        for fully written contracts. However, they are not designed to provide interactive,
        edit-time feedback to developers while code is still under construction. They typically
        analyze post-compilation artifacts or deployed bytecode and expect complete program units.
        \textsc{SolQDebug} complements this line of work by focusing on pre-deployment authoring: it
        accepts partial fragments and symbolic (interval) inputs and produces line-by-line feedback
        inside the editor.
    
    \subsection{Solidity-Specific Abstract Interpretation Frameworks}
        Abstract interpretation is a well-established framework for static analysis and has been
        adapted to many programming languages. Two recent studies apply it to Solidity~\citep{flow,
        DBM}. The first uses the Pos domain to construct a theoretical model for taint
        (information-flow) analysis~\citet{flow}, while the second employs the Difference-Bound
        Matrix (DBM) domain to generate state invariants and detect re-entrancy vulnerabilities,
        including the DAO attack~\citep{DBM, dao}. However, both approaches operate on fully written
        contracts and provide no support for line-by-line interpretation or developer interaction
        within an IDE.

        \textsc{SolQDebug} adapts abstract interpretation for an interactive setting. It
        incrementally updates both the control-flow graph and the abstract state in response to each
        edit. Developer-supplied annotations serve as a first-class input mechanism, reflecting how
        debugging often involves varying symbolic inputs. These annotations are internally
        represented as linear-inequality constraints, and form an integral part of interactive
        debugging by enabling symbolic reasoning over developer-specified inputs. This design
        improves interpretability and control within the interval domain by leveraging symbolic
        constraints, while maintaining keystroke-level responsiveness. As a result,
        \textsc{SolQDebug} updates variable ranges directly in the Solidity editor, allowing
        developers to observe how values evolve in response to each edit.
    
    \subsection{Interactive Abstract Interpretation for Traditional Languages}
        In recent years, traditional languages have seen a surge of interest in making abstract
        interpretation interactive, integrating it directly into IDEs to provide live analysis
        feedback during editing \citep{daig, ds, iac, iaj, fap}.
        \citet{daig} proposed demanded abstract interpretation, which incrementally rebuilds only
        the analysis nodes touched by an edit.
        A follow-up \citet{ds} generalized this to procedure summaries, enabling inter-procedural
        reuse.
        \citet{iac} extended Goblint with incremental support for multithreaded C, selectively
        recomputing only genuinely affected facts and maintaining IDE-level responsiveness.
        \citet{iaj} introduced IntraJ, an LSP-integrated analyzer for Java 11 that computes only the
        AST and data-flow facts needed for the current view, keeping feedback under 100 ms.
        \citet{fap} achieved fast yet precise interval analysis on call graphs via one top-down and
        multiple bottom-up passes, and later introduced an incremental variant that revisits only
        the impacted functions.

        Unlike these frameworks for C or Java, \textsc{SolQDebug} is designed specifically for
        Solidity. It supports in-flight code fragments and range annotations as first-class input.
        It incrementally updates only the current basic block in the CFG while reusing previously
        computed abstract states. Finally, it combines these with an interval domain guided by
        developer-supplied annotations, which act as input to represent the exploratory nature of
        debugging. This architecture enables keystroke-level feedback without requiring
        recompilation, redeployment, or transaction execution. It bridges the gap between Solidity
        development and the interactive tooling common in traditional programming environments.


\section{Conclusion}
    We introduced SolQDebug, a source-level interactive debugger for Solidity that provides
    millisecond feedback without requiring compilation, deployment, or transaction replay. By
    combining interactive parsing, dynamic control-flow graph updates, and interval domain based
    abstract interpretation seeded by annotations, SolQDebug enables responsive, line-by-line
    inspection directly within the Solidity editor. Our evaluation shows that it reduces debugging
    latency compared to Remix, while enabling actionable feedback in response to symbolic inputs.
    These results demonstrate that SolQDebug’s design effectively bridges the interactivity gap in
    Solidity debugging and brings the development experience closer to that of modern debugging
    workflows.
    
    Future work includes extending SolQDebug to inter-contract and multi-transaction contexts,
    incorporating loop summarization for higher precision, and conducting user studies to assess its
    practical adoption and usability. We also plan to apply analysis based on the EVM Object Format
    (EOF) to support inter-contract debugging when source code is unavailable, as Ethereum moves
    toward structured bytecode formats in upcoming hard forks.

\begin{thebibliography}{1}

\bibitem[ANTLR(2025)]{antlr}
ANTLR: \url{https://www.antlr.org/} (2025). Accessed September 2025

\bibitem[ChatGPT(2025)]{gpt}
ChatGPT: \url{https://chatgpt.com/} (2025). Accessed September 2025

\bibitem[Chen et~al.(2025)]{smart contract evolution}
Chen, X., et al.: Characterizing smart contract evolution. ACM Transactions on Software Engineering
and Methodology (2025)

\bibitem[Chimdyalwar(2024)]{fap}
Chimdyalwar, B.: Fast and precise interval analysis on industry code. In: 2024 IEEE 35th
International Symposium on Software Reliability Engineering Workshops (ISSREW) (2024)

\bibitem[ConsenSys Diligence(2025)]{psp}
ConsenSys Diligence: Python Solidity Parser. \url{https://github.
com/ConsenSysDiligence/python-solidity-parser} (2025). Accessed September 2025

\bibitem[Cousot and Cousot(1977)]{cousot}
Cousot, P., Cousot, R.: Abstract interpretation: a unified lattice model for static analysis of
programs by construction or approximation of fixpoints. In: Proceedings of the 4th ACM
SIGACT-SIGPLAN Symposium on Principles of Programming Languages (POPL) (1977)

\bibitem[Erhard et~al.(2024)]{iac}
Erhard, J., et al.: Interactive abstract interpretation: reanalyzing multithreaded C programs for
cheap. International Journal on Software Tools for Technology Transfer (2024)

\bibitem[Foundry Forge(2025)]{forge}
Foundry Forge: \url{https://book.getfoundry.sh/reference/forge/forge/} (2025). Accessed September
2025

\bibitem[Grieco et~al.(2020)]{echidna}
Grieco, G., et al.: Echidna: effective, usable, and fast fuzzing for smart contracts. In:
Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA),
pp. 557–560 (2020)

\bibitem[Halder et~al.(2023)]{flow}
Halder, R., et al.: Analyzing information flow in Solidity smart contracts. In: Distributed
Computing to Blockchain, pp. 105–123. Academic Press (2023)

\bibitem[Halder(2024)]{DBM}
Halder, R.: State-based invariant property generation of Solidity smart contracts using abstract
interpretation. In: 2024 IEEE International Conference on Blockchain (2024)

\bibitem[Hardhat(2025)]{hardhat}
Hardhat: \url{https://hardhat.org/} (2025). Accessed September 2025

\bibitem[Hu et~al.(2023)]{solidet}
Hu, T., et al.: Detect defects of Solidity smart contract based on the knowledge graph. IEEE
Transactions on Reliability 73(1), 186–202 (2023)

\bibitem[JetBrains(2025)]{pycharm}
JetBrains: PyCharm. \url{https://www.jetbrains.com/pycharm/} (2025). Accessed September 2025

\bibitem[Jiang et~al.(2018)]{confuzz}
Jiang, B., Liu, Y., Chan, W.K.: ContractFuzzer: fuzzing smart contracts for vulnerability detection.
In: Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE)
, pp. 259–269 (2018)

\bibitem[Kalra et~al.(2018)]{zeus}
Kalra, S., Goel, S., Dhawan, M., Sharma, S.: ZEUS: analyzing safety of smart contracts. In:
Proceedings of the 2018 Network and Distributed System Security Symposium (NDSS) (2018)

\bibitem[Llama(2025)]{llama}
Llama: \url{https://www.llama.com/} (2025). Accessed September 2025

\bibitem[Ma et~al.(2023)]{transracer}
Ma, C., Song, W., Huang, J.: TransRacer: function dependence-guided transaction race detection for
smart contracts. In: Proceedings of the 31st ACM Joint European Software Engineering Conference and
Symposium on the Foundations of Software Engineering (ESEC/FSE), pp. 947–959 (2023)

\bibitem[Mehar et~al.(2019)]{dao}
Mehar, M.I., et al.: Understanding a revolutionary and flawed grand experiment in blockchain: the
DAO attack. Journal of Cases on Information Technology (2019)

\bibitem[Microsoft(2025)]{visual}
Microsoft Visual Studio: \url{https://visualstudio.microsoft.com/ko/} (2025). Accessed September
2025

\bibitem[Nguyen et~al.(2020)]{sfuzz}
Nguyen, T.D., et al.: sFuzz: an efficient adaptive fuzzer for Solidity smart contracts. In:
Proceedings of the 42nd ACM/IEEE International Conference on Software Engineering (ICSE), pp.
778–788 (2020)

\bibitem[Pasqua et~al.(2023)]{ethersolve}
Pasqua, M., et al.: Enhancing Ethereum smart-contracts static analysis by computing a precise
control-flow graph of Ethereum bytecode. Journal of Systems and Software 200, 111653 (2023)

\bibitem[Remix IDE(2025)]{remix}
Remix IDE: \url{https://remix.ethereum.org/} (2025). Accessed September 2025

\bibitem[Riouak et~al.(2024)]{iaj}
Riouak, I., et al.: IntraJ: an on-demand framework for intraprocedural Java code analysis.
International Journal on Software Tools for Technology Transfer (2024)

\bibitem[Rival and Yi(2020)]{yi}
Rival, X., Yi, K.: Introduction to Static Analysis: an Abstract Interpretation Perspective (2020)

\bibitem[Shou et~al.(2023)]{ityfuzz}
Shou, C., Tan, S., Sen, K.: Ityfuzz: snapshot-based fuzzer for smart contract. In: Proceedings of
the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA), pp. 322–333
(2023)

\bibitem[So et~al.(2020)]{verismart}
So, S., et al.: Verismart: a highly precise safety verifier for Ethereum smart contracts. In: 2020
IEEE Symposium on Security and Privacy (SP), pp. 1678–1694 (2020)

\bibitem[solcx(2025)]{solcx}
Solidity Compiler in Python (solcx): \url{https://solcx.readthedocs.io/en/latest/} (2025). Accessed
September 2025

\bibitem[Solidity(2025)]{solidity}
Solidity documentation: \url{https://docs.soliditylang.org/en/v0.8.29/} (2025). Accessed September
2025

\bibitem[Solidity Debugger Pro(2025)]{soldepro}
Solidity Debugger Pro: \url{https://www.soliditydbg.org/} (2025). Accessed September 2025

\bibitem[SolQDebug Language Grammar Rule]{solqrule} 
Solidity Language Grammar Rule of SolQDebug : \url{https://github.
com/iwwyou/SolDebug/blob/main/Parser/Solidity.g4} . Accessed September 2025

\bibitem[Stein et~al.(2021)]{daig}
Stein, B., Chang, B.-Y.E., Sridharan, M.: Demanded abstract interpretation. In: Proceedings of the
42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI)
(2021)

\bibitem[Stein et~al.(2024)]{ds}
Stein, B., Chang, B.-Y.E., Sridharan, M.: Interactive abstract interpretation with demanded
summarization. ACM Transactions on Programming Languages and Systems (2024)

\bibitem[Stephens et~al.(2021)]{pulse}
Stephens, J., et al.: SmartPulse: automated checking of temporal properties in smart contracts. In:
2021 IEEE Symposium on Security and Privacy (SP), pp. 555–571 (2021)

\bibitem[Tsankov et~al.(2018)]{securify}
Tsankov, P., et al.: Securify: practical security analysis of smart contracts. In: Proceedings of
the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 67–82 (2018)

\bibitem[Tsankov et~al.(2019)]{slither}
Tsankov, P., et al.: Slither: a static analysis framework for smart contracts. In: 2019 IEEE/ACM 2nd
International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB), pp. 8–15
(2019)

\bibitem[Wu et~al.(2021)]{peculiar}
Wu, H., et al.: Peculiar: smart contract vulnerability detection based on crucial data-flow graph
and pre-training techniques. In: 2021 IEEE 32nd International Symposium on Software Reliability
Engineering (ISSRE), pp. 378–389 (2021)

\bibitem[Yao et~al.(2022)]{mythril}
Yao, Y., et al.: An improved vulnerability detection system of smart contracts based on symbolic
execution. In: 2022 IEEE International Conference on Big Data (Big Data), pp. 3225–3234 (2022)

\bibitem[Yu et~al.(2023)]{pscvfinder}
Yu, L., et al.: PSCVFinder: a prompt-tuning based framework for smart contract vulnerability
detection. In: 2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE),
pp. 556–567 (2023)

\bibitem[Zheng et~al.(2024)]{dappscan}
Zheng, Z., et al.: Dappscan: building large-scale datasets for smart contract weaknesses in dApp
projects. IEEE Transactions on Software Engineering (2024)

\bibitem[Zhou et~al.(2022)]{tmlvd}
Zhou, Q., et al.: Vulnerability analysis of smart contract for blockchain-based IoT applications: a
machine learning approach. IEEE Internet of Things Journal 9(24), 24695–24707 (2022)

\bibitem[Zou et~al.(2019)]{interview}
Zou, W., et al.: Smart contract development: challenges and opportunities. IEEE Transactions on
Software Engineering (2019)

\end{thebibliography}

\end{document}
